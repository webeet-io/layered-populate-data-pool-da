{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf57fa1",
   "metadata": {},
   "source": [
    "# ğŸ—„ï¸ **AWS Database Investigation & Neighborhoods Table Creation**\n",
    "\n",
    "## ğŸ¯ **Learning Objectives**\n",
    "By the end of this notebook, students will understand:\n",
    "1. **Database Connection**: How to connect to AWS RDS PostgreSQL\n",
    "2. **Schema Investigation**: How to explore existing database structure\n",
    "3. **PostGIS Setup**: Understanding spatial database extensions\n",
    "4. **GeoJSON Import**: How to create PostGIS tables from GeoJSON files\n",
    "5. **Data Validation**: How to verify successful data import\n",
    "\n",
    "## ğŸ“‹ **Prerequisites**\n",
    "- âœ… Enhanced GeoJSON file (`neighborhoods_enhanced.geojson`)\n",
    "- âœ… AWS database credentials\n",
    "- âœ… Basic understanding of PostgreSQL and spatial data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b143c6",
   "metadata": {},
   "source": [
    "## ğŸ“¦ **Step 1: Import Required Libraries**\n",
    "\n",
    "**Learning Point**: We need specific libraries for spatial data and database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c370f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n",
      "ğŸ“š Ready for spatial database operations\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Import required libraries for spatial database operations\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"ğŸ“š Ready for spatial database operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfd4f7",
   "metadata": {},
   "source": [
    "## ğŸ”Œ **Step 2: AWS Database Connection**\n",
    "\n",
    "**Learning Point**: Connection strings contain all necessary information to connect to a database.\n",
    "\n",
    "**Format**: `postgresql+psycopg2://username:password@host:port/database`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8742098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ **CONNECTING TO AWS DATABASE**\n",
      "========================================\n",
      "1ï¸âƒ£ Creating database engine...\n",
      "2ï¸âƒ£ Testing connection...\n",
      "   âœ… Connected successfully!\n",
      "   ğŸ—„ï¸  Database: berlin_project_db\n",
      "   ğŸ‘¤ User: postgres\n",
      "   ğŸ“Š PostgreSQL Version: PostgreSQL 17.4 on aarch64-unknown-linux-gnu, comp...\n",
      "   âœ… Connected successfully!\n",
      "   ğŸ—„ï¸  Database: berlin_project_db\n",
      "   ğŸ‘¤ User: postgres\n",
      "   ğŸ“Š PostgreSQL Version: PostgreSQL 17.4 on aarch64-unknown-linux-gnu, comp...\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Clean and professional database connection using python-dotenv\n",
    "print(\"ğŸ”Œ **CONNECTING TO AWS DATABASE**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Load environment variables from .env file (no string functions needed!)\n",
    "load_dotenv('../ignored_files/.env')\n",
    "PASSWORD = os.getenv('PASSWORD')\n",
    "\n",
    "# Build connection URL with secure password from .env\n",
    "DATABASE_URL = f'postgresql+psycopg2://postgres:{PASSWORD}@layered-data-warehouse.cdg2ok68acsn.eu-central-1.rds.amazonaws.com:5432/berlin_project_db'\n",
    "\n",
    "try:\n",
    "    print(\"1ï¸âƒ£ Creating database engine...\")\n",
    "    engine = create_engine(DATABASE_URL, connect_args={'connect_timeout': 10})\n",
    "    \n",
    "    print(\"2ï¸âƒ£ Testing connection...\")\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    # Test query\n",
    "    test_result = conn.execute(text(\"SELECT current_database(), current_user, version()\"))\n",
    "    db_info = test_result.fetchone()\n",
    "    \n",
    "    print(f\"   âœ… Connected successfully!\")\n",
    "    print(f\"   ğŸ—„ï¸  Database: {db_info[0]}\")\n",
    "    print(f\"   ğŸ‘¤ User: {db_info[1]}\")\n",
    "    print(f\"   ğŸ“Š PostgreSQL Version: {db_info[2][:50]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection failed: {e}\")\n",
    "    print(\"ğŸ’¡ Check network connection and credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd607c9",
   "metadata": {},
   "source": [
    "## ğŸ” **Step 3: Database Schema Investigation**\n",
    "\n",
    "**Learning Point**: Before creating new tables, always investigate existing database structure to avoid conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6bf9338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” **DATABASE SCHEMA INVESTIGATION**\n",
      "========================================\n",
      "1ï¸âƒ£ Available schemas:\n",
      "   ğŸ“ berlin_data\n",
      "   ğŸ“ public\n",
      "\n",
      "2ï¸âƒ£ Target schema 'berlin_data' exists: âœ… YES\n",
      "   ğŸ“‹ Search path set to: berlin_data, public\n",
      "\n",
      "3ï¸âƒ£ Existing tables in berlin_data schema:\n",
      "   ğŸ—„ï¸  districts (BASE TABLE)\n",
      "   ğŸ—„ï¸  districts_pop_stat (BASE TABLE)\n",
      "   ğŸ—„ï¸  geography_columns (VIEW)\n",
      "   ğŸ—„ï¸  geometry_columns (VIEW)\n",
      "   ğŸ—„ï¸  green_spaces (BASE TABLE)\n",
      "   ğŸ—„ï¸  hospitals (BASE TABLE)\n",
      "   ğŸ—„ï¸  neighborhoods (BASE TABLE)\n",
      "   ğŸ—„ï¸  regional_statistics (BASE TABLE)\n",
      "   ğŸ—„ï¸  schools_kai (BASE TABLE)\n",
      "   ğŸ—„ï¸  short_time_listings (BASE TABLE)\n",
      "   ğŸ—„ï¸  spatial_ref_sys (BASE TABLE)\n",
      "   ğŸ—„ï¸  ubahn (BASE TABLE)\n",
      "\n",
      "   ğŸ“Š Total tables found: 12\n",
      "\n",
      "âœ… Schema investigation complete!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Investigate existing database structure\n",
    "print(\"ğŸ” **DATABASE SCHEMA INVESTIGATION**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Check available schemas\n",
    "    print(\"1ï¸âƒ£ Available schemas:\")\n",
    "    schemas_result = conn.execute(text(\"\"\"\n",
    "        SELECT schema_name \n",
    "        FROM information_schema.schemata \n",
    "        WHERE schema_name NOT IN ('information_schema', 'pg_catalog', 'pg_toast')\n",
    "        ORDER BY schema_name\n",
    "    \"\"\"))\n",
    "    schemas = [row[0] for row in schemas_result.fetchall()]\n",
    "    \n",
    "    for schema in schemas:\n",
    "        print(f\"   ğŸ“ {schema}\")\n",
    "    \n",
    "    # Check if berlin_data schema exists\n",
    "    berlin_data_exists = 'berlin_data' in schemas\n",
    "    print(f\"\\n2ï¸âƒ£ Target schema 'berlin_data' exists: {'âœ… YES' if berlin_data_exists else 'âŒ NO'}\")\n",
    "    \n",
    "    if berlin_data_exists:\n",
    "        # Set search path to berlin_data\n",
    "        conn.execute(text(\"SET search_path = berlin_data, public;\"))\n",
    "        conn.commit()\n",
    "        print(\"   ğŸ“‹ Search path set to: berlin_data, public\")\n",
    "        \n",
    "        # Check existing tables in berlin_data\n",
    "        print(\"\\n3ï¸âƒ£ Existing tables in berlin_data schema:\")\n",
    "        tables_result = conn.execute(text(\"\"\"\n",
    "            SELECT table_name, table_type \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = 'berlin_data'\n",
    "            ORDER BY table_name\n",
    "        \"\"\"))\n",
    "        tables = tables_result.fetchall()\n",
    "        \n",
    "        for table in tables:\n",
    "            print(f\"   ğŸ—„ï¸  {table.table_name} ({table.table_type})\")\n",
    "        \n",
    "        print(f\"\\n   ğŸ“Š Total tables found: {len(tables)}\")\n",
    "    \n",
    "    print(\"\\nâœ… Schema investigation complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Schema investigation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055cdaff",
   "metadata": {},
   "source": [
    "## ğŸ—ºï¸ **Step 4: PostGIS Extension Check**\n",
    "\n",
    "**Learning Point**: PostGIS is essential for spatial data operations in PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e8d5729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ºï¸ **POSTGIS EXTENSION CHECK**\n",
      "========================================\n",
      "âœ… PostGIS is installed!\n",
      "   ğŸ“¦ Extension: postgis\n",
      "   ğŸ”¢ Version: 3.5.1\n",
      "   ğŸ“‹ Schema: berlin_data\n",
      "\n",
      "âœ… PostGIS check complete!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—ºï¸ Check PostGIS extension status\n",
    "print(\"ğŸ—ºï¸ **POSTGIS EXTENSION CHECK**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Check if PostGIS is installed\n",
    "    postgis_check = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            extname as extension_name,\n",
    "            extversion as version,\n",
    "            nspname as schema\n",
    "        FROM pg_extension e\n",
    "        JOIN pg_namespace n ON e.extnamespace = n.oid\n",
    "        WHERE extname = 'postgis'\n",
    "    \"\"\"))\n",
    "    \n",
    "    postgis_info = postgis_check.fetchone()\n",
    "    \n",
    "    if postgis_info:\n",
    "        print(f\"âœ… PostGIS is installed!\")\n",
    "        print(f\"   ğŸ“¦ Extension: {postgis_info.extension_name}\")\n",
    "        print(f\"   ğŸ”¢ Version: {postgis_info.version}\")\n",
    "        print(f\"   ğŸ“‹ Schema: {postgis_info.schema}\")\n",
    "    else:\n",
    "        print(\"âŒ PostGIS not found\")\n",
    "        print(\"ğŸ’¡ PostGIS extension may need to be enabled\")\n",
    "    \n",
    "    print(\"\\nâœ… PostGIS check complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ PostGIS check failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7e412",
   "metadata": {},
   "source": [
    "## ğŸ“‚ **Step 5: Load Enhanced Neighborhoods GeoJSON**\n",
    "\n",
    "**Learning Point**: GeoJSON is a standard format for geographic data that can be easily imported into PostGIS.\n",
    "\n",
    "**About Neighborhoods Data**:\n",
    "- **Hierarchical Structure**: Neighborhoods belong to districts (many-to-one relationship)\n",
    "- **Enhanced Data**: Our GeoJSON includes district_id for foreign key relationships\n",
    "- **Spatial Precision**: Neighborhoods provide finer geographic granularity than districts\n",
    "- **Berlin Context**: 96 neighborhoods across 12 districts\n",
    "\n",
    "**Educational Value**: This step demonstrates loading hierarchical spatial data with relationship fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "578a7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ **LOADING ENHANCED NEIGHBORHOODS GEOJSON**\n",
      "========================================\n",
      "1ï¸âƒ£ Checking file existence...\n",
      "   âœ… File found: neighborhoods_enhanced.geojson\n",
      "2ï¸âƒ£ Loading GeoJSON with GeoPandas...\n",
      "   âœ… Loaded 96 neighborhoods\n",
      "   ğŸ“Š Columns: ['district_id', 'district', 'neighborhood', 'geometry']\n",
      "   ğŸŒ Coordinate Reference System: EPSG:4326\n",
      "   ğŸ“ Geometry types: ['Polygon' 'MultiPolygon']\n",
      "\n",
      "3ï¸âƒ£ Sample data preview:\n",
      "   ğŸ˜ï¸ 01: Mitte - Mitte\n",
      "   ğŸ˜ï¸ 01: Mitte - Moabit\n",
      "   ğŸ˜ï¸ 01: Mitte - Hansaviertel\n",
      "\n",
      "4ï¸âƒ£ CRS verification: âœ… Already EPSG:4326\n",
      "\n",
      "âœ… GeoJSON loaded and ready for database import!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‚ Load the enhanced neighborhoods GeoJSON file\n",
    "print(\"ğŸ“‚ **LOADING ENHANCED NEIGHBORHOODS GEOJSON**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Path to the enhanced GeoJSON file\n",
    "geojson_path = \"/Users/zeal.v/Desktop/Webeet-Internship/districts-neighborhoods-populating-db/layered-populate-data-pool-da/districts-neighborhoods-populating-db/sources/neighborhoods_enhanced.geojson\"\n",
    "\n",
    "try:\n",
    "    print(\"1ï¸âƒ£ Checking file existence...\")\n",
    "    if os.path.exists(geojson_path):\n",
    "        print(f\"   âœ… File found: {os.path.basename(geojson_path)}\")\n",
    "        \n",
    "        print(\"2ï¸âƒ£ Loading GeoJSON with GeoPandas...\")\n",
    "        neighborhoods_gdf = gpd.read_file(geojson_path)\n",
    "        \n",
    "        print(f\"   âœ… Loaded {len(neighborhoods_gdf)} neighborhoods\")\n",
    "        print(f\"   ğŸ“Š Columns: {list(neighborhoods_gdf.columns)}\")\n",
    "        print(f\"   ğŸŒ Coordinate Reference System: {neighborhoods_gdf.crs}\")\n",
    "        print(f\"   ğŸ“ Geometry types: {neighborhoods_gdf.geometry.geom_type.unique()}\")\n",
    "        \n",
    "        print(\"\\n3ï¸âƒ£ Sample data preview:\")\n",
    "        sample_data = neighborhoods_gdf[['district_id', 'district', 'neighborhood']].head(3)\n",
    "        for idx, row in sample_data.iterrows():\n",
    "            print(f\"   ğŸ˜ï¸ {row['district_id']}: {row['district']} - {row['neighborhood']}\")\n",
    "        \n",
    "        # Ensure correct CRS (EPSG:4326 for WGS84)\n",
    "        if neighborhoods_gdf.crs != 'EPSG:4326':\n",
    "            print(f\"\\n4ï¸âƒ£ Converting CRS to EPSG:4326...\")\n",
    "            neighborhoods_gdf = neighborhoods_gdf.to_crs('EPSG:4326')\n",
    "            print(\"   âœ… CRS converted to EPSG:4326\")\n",
    "        else:\n",
    "            print(\"\\n4ï¸âƒ£ CRS verification: âœ… Already EPSG:4326\")\n",
    "        \n",
    "        print(\"\\nâœ… GeoJSON loaded and ready for database import!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   âŒ File not found: {geojson_path}\")\n",
    "        print(\"   ğŸ’¡ Make sure to run the main notebook first to create enhanced files\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading GeoJSON: {e}\")\n",
    "    print(f\"ğŸ” Details: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c46eb",
   "metadata": {},
   "source": [
    "## ğŸ”§ **Step 6: Enable PostGIS for Table Creation**\n",
    "\n",
    "**Learning Point**: PostGIS extension must be enabled before creating spatial tables.\n",
    "\n",
    "**Simple approach**: Enable PostGIS and set proper search path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e16bf371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ **COMPREHENSIVE POSTGIS SETUP & DIAGNOSTICS**\n",
      "=======================================================\n",
      "1ï¸âƒ£ Checking PostGIS installation status...\n",
      "   âœ… PostGIS extension found: v3.5.1 in berlin_data schema\n",
      "\n",
      "2ï¸âƒ£ Checking available PostGIS types...\n",
      "   ğŸ“‹ Available spatial types:\n",
      "      â€¢ geography in berlin_data schema\n",
      "      â€¢ geometry in berlin_data schema\n",
      "\n",
      "3ï¸âƒ£ Ensuring PostGIS is properly enabled...\n",
      "   âœ… PostGIS extension command executed\n",
      "\n",
      "4ï¸âƒ£ Testing PostGIS functionality...\n",
      "   âœ… PostGIS is working! Version: 3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\n",
      "   âœ… Geometry functions work: True\n",
      "\n",
      "5ï¸âƒ£ Setting search path...\n",
      "   âœ… Search path: berlin_data, public\n",
      "\n",
      "6ï¸âƒ£ Final spatial type availability check...\n",
      "   ğŸ“‹ Available types now: ['geography', 'geometry']\n",
      "\n",
      "ğŸ‰ **PostGIS setup complete! Geography type is available.**\n",
      "   âœ… PostGIS is working! Version: 3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\n",
      "   âœ… Geometry functions work: True\n",
      "\n",
      "5ï¸âƒ£ Setting search path...\n",
      "   âœ… Search path: berlin_data, public\n",
      "\n",
      "6ï¸âƒ£ Final spatial type availability check...\n",
      "   ğŸ“‹ Available types now: ['geography', 'geometry']\n",
      "\n",
      "ğŸ‰ **PostGIS setup complete! Geography type is available.**\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ COMPREHENSIVE PostGIS Setup and Diagnostics\n",
    "print(\"ğŸ”§ **COMPREHENSIVE POSTGIS SETUP & DIAGNOSTICS**\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "try:\n",
    "    # Step 1: Check current PostGIS status\n",
    "    print(\"1ï¸âƒ£ Checking PostGIS installation status...\")\n",
    "    \n",
    "    # Check if PostGIS extension exists\n",
    "    ext_check = conn.execute(text(\"\"\"\n",
    "        SELECT extname, extversion, nspname as schema_name\n",
    "        FROM pg_extension e\n",
    "        JOIN pg_namespace n ON e.extnamespace = n.oid\n",
    "        WHERE extname = 'postgis'\n",
    "    \"\"\"))\n",
    "    \n",
    "    postgis_ext = ext_check.fetchone()\n",
    "    if postgis_ext:\n",
    "        print(f\"   âœ… PostGIS extension found: v{postgis_ext.extversion} in {postgis_ext.schema_name} schema\")\n",
    "    else:\n",
    "        print(\"   âŒ PostGIS extension not found\")\n",
    "    \n",
    "    # Step 2: Check available PostGIS types\n",
    "    print(\"\\n2ï¸âƒ£ Checking available PostGIS types...\")\n",
    "    \n",
    "    types_check = conn.execute(text(\"\"\"\n",
    "        SELECT typname, nspname \n",
    "        FROM pg_type t \n",
    "        JOIN pg_namespace n ON t.typnamespace = n.oid \n",
    "        WHERE typname IN ('geometry', 'geography')\n",
    "        ORDER BY typname, nspname\n",
    "    \"\"\"))\n",
    "    \n",
    "    types_found = types_check.fetchall()\n",
    "    if types_found:\n",
    "        print(\"   ğŸ“‹ Available spatial types:\")\n",
    "        for type_info in types_found:\n",
    "            print(f\"      â€¢ {type_info.typname} in {type_info.nspname} schema\")\n",
    "    else:\n",
    "        print(\"   âŒ No spatial types found\")\n",
    "    \n",
    "    # Step 3: Enable PostGIS properly\n",
    "    print(\"\\n3ï¸âƒ£ Ensuring PostGIS is properly enabled...\")\n",
    "    \n",
    "    # Try to enable PostGIS extension\n",
    "    conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS postgis;\"))\n",
    "    conn.commit()\n",
    "    print(\"   âœ… PostGIS extension command executed\")\n",
    "    \n",
    "    # Check if it worked by testing PostGIS function\n",
    "    print(\"\\n4ï¸âƒ£ Testing PostGIS functionality...\")\n",
    "    try:\n",
    "        test_result = conn.execute(text(\"SELECT PostGIS_Version();\"))\n",
    "        version = test_result.fetchone()[0]\n",
    "        print(f\"   âœ… PostGIS is working! Version: {version}\")\n",
    "        \n",
    "        # Test geometry creation\n",
    "        geom_test = conn.execute(text(\"\"\"\n",
    "            SELECT ST_GeomFromText('POINT(13.4050 52.5200)', 4326) IS NOT NULL as geom_works\n",
    "        \"\"\"))\n",
    "        geom_works = geom_test.fetchone()[0]\n",
    "        print(f\"   âœ… Geometry functions work: {geom_works}\")\n",
    "        \n",
    "    except Exception as test_error:\n",
    "        print(f\"   âŒ PostGIS function test failed: {test_error}\")\n",
    "    \n",
    "    # Step 5: Set search path\n",
    "    print(\"\\n5ï¸âƒ£ Setting search path...\")\n",
    "    conn.execute(text(\"SET search_path = berlin_data, public;\"))\n",
    "    conn.commit()\n",
    "    print(\"   âœ… Search path: berlin_data, public\")\n",
    "    \n",
    "    # Step 6: Final type check\n",
    "    print(\"\\n6ï¸âƒ£ Final spatial type availability check...\")\n",
    "    final_check = conn.execute(text(\"\"\"\n",
    "        SELECT typname \n",
    "        FROM pg_type \n",
    "        WHERE typname IN ('geometry', 'geography')\n",
    "    \"\"\"))\n",
    "    \n",
    "    final_types = [row[0] for row in final_check.fetchall()]\n",
    "    print(f\"   ğŸ“‹ Available types now: {final_types}\")\n",
    "    \n",
    "    if 'geography' in final_types:\n",
    "        print(\"\\nğŸ‰ **PostGIS setup complete! Geography type is available.**\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ **Geography type still not available. Will use alternative approach.**\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ PostGIS setup failed: {e}\")\n",
    "    import traceback\n",
    "    print(f\"ï¿½ Details: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de63580",
   "metadata": {},
   "source": [
    "## ğŸ˜ï¸ **Step 7: Create Neighborhoods Table with Foreign Key Relationships**\n",
    "\n",
    "**Learning Point**: When creating related tables, design must support referential integrity.\n",
    "\n",
    "**Neighborhoods Table Design**:\n",
    "- **district_id**: Foreign key to districts table (VARCHAR(2))\n",
    "- **district**: District name for readability (VARCHAR(100)) \n",
    "- **neighborhood**: Neighborhood name (VARCHAR(100))\n",
    "- **geometry**: PostGIS spatial column (MULTIPOLYGON, SRID 4326)\n",
    "\n",
    "**Relational Database Concepts**:\n",
    "- **Foreign Keys**: district_id links to districts.district_id\n",
    "- **Normalization**: District info stored in both tables for query efficiency\n",
    "- **Spatial Hierarchy**: Geographic containment (neighborhoods âŠ‚ districts)\n",
    "\n",
    "**Why This Structure**: Enables spatial queries while maintaining relational integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "712ae038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ **STEP 7.5: CLEARING TRANSACTION ERROR**\n",
      "=============================================\n",
      "âœ… Transaction rolled back successfully!\n",
      "ğŸš€ Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ **STEP 7.0: TRANSACTION ROLLBACK** (if there was an error)\n",
    "# =======================================\n",
    "print(\"ğŸ”§ **STEP 7.5: CLEARING TRANSACTION ERROR**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    # Rollback any failed transaction\n",
    "    conn.rollback()\n",
    "    print(\"âœ… Transaction rolled back successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"â„¹ï¸  Rollback note: {e}\")\n",
    "\n",
    "print(\"ğŸš€ Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75ecfd",
   "metadata": {},
   "source": [
    "## ğŸ”§ **Step 7A: Connection Check & Transaction Reset**\n",
    "\n",
    "**Learning Point**: Before creating tables, always verify your connection is working and clear any pending transactions.\n",
    "\n",
    "**Why this matters**: \n",
    "- Database connections can have \"dirty\" transaction states\n",
    "- Rolling back ensures we start with a clean slate\n",
    "- Connection tests verify we can communicate with the database\n",
    "\n",
    "**Best Practice**: Always check connection health before major operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "111e648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¿½ **STEP 7A: CONNECTION CHECK & ROLLBACK**\n",
      "=============================================\n",
      "âœ… Connection working: 1\n",
      "âœ… Transaction state cleared\n",
      "ï¿½ Ready for table creation!\n"
     ]
    }
   ],
   "source": [
    "# ï¿½ **STEP 7A: CONNECTION CHECK & ROLLBACK**\n",
    "# ============================================\n",
    "print(\"ï¿½ **STEP 7A: CONNECTION CHECK & ROLLBACK**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    # Check connection status\n",
    "    test_result = conn.execute(text(\"SELECT 1 as test\"))\n",
    "    test_value = test_result.fetchone()[0]\n",
    "    print(f\"âœ… Connection working: {test_value}\")\n",
    "    \n",
    "    # Rollback any pending transactions\n",
    "    conn.rollback()\n",
    "    print(\"âœ… Transaction state cleared\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection issue: {e}\")\n",
    "    print(\"ï¿½ Try reconnecting if needed\")\n",
    "\n",
    "print(\"ï¿½ Ready for table creation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a556a3",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ **Step 7B: Create Basic Table Structure**\n",
    "\n",
    "**Learning Point**: Start with simple table structure before adding complex spatial columns.\n",
    "\n",
    "**Why this approach**:\n",
    "- Creates the basic columns first (district_id, district)\n",
    "- Uses `CREATE TABLE IF NOT EXISTS` to avoid errors if table exists\n",
    "- Establishes primary structure before spatial additions\n",
    "\n",
    "**SQL Concepts**:\n",
    "- `VARCHAR(2)` for district_id (Berlin has 2-digit district codes)\n",
    "- `UNIQUE NOT NULL` ensures no duplicate district IDs\n",
    "- `VARCHAR(100)` for district names\n",
    "\n",
    "**Best Practice**: Build tables incrementally - structure first, then spatial features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be825e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ **STEP 7B: CREATE TABLE STRUCTURE**\n",
      "=============================================\n",
      "   âœ… Basic table structure created!\n",
      "   âœ… Connection still working\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—ï¸ **STEP 7B: CREATE TABLE STRUCTURE**\n",
    "# =====================================\n",
    "print(\"ğŸ—ï¸ **STEP 7B: CREATE TABLE STRUCTURE**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "\n",
    "    # Create new table\n",
    "    create_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS berlin_data.neighborhoods (\n",
    "        district_id VARCHAR(2) NOT NULL,\n",
    "        district VARCHAR(100) NOT NULL,\n",
    "        neighborhood VARCHAR(100) NOT NULL\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    conn.execute(text(create_sql))\n",
    "    conn.commit()\n",
    "    print(\"   âœ… Basic table structure created!\")\n",
    "    \n",
    "    # Connection check\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"   âœ… Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Table creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"ğŸ”„ Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab171348",
   "metadata": {},
   "source": [
    "## ğŸ—ºï¸ **Step 7C: Add PostGIS Geometry Column for Neighborhoods**\n",
    "\n",
    "**Learning Point**: PostGIS geometry columns enable spatial operations on neighborhood boundaries.\n",
    "\n",
    "**PostGIS Functions**:\n",
    "- `ALTER TABLE ADD COLUMN geometry` - Standard approach for adding spatial columns\n",
    "- `GEOMETRY(MULTIPOLYGON, 4326)` - Explicit geometry type and coordinate system\n",
    "- Automatically integrates with PostGIS spatial index system\n",
    "\n",
    "**Parameters Explained**:\n",
    "- `'berlin_data'` - schema name\n",
    "- `'neighborhoods'` - table name  \n",
    "- `'geometry'` - column name\n",
    "- `4326` - SRID (Spatial Reference System - WGS84)\n",
    "- `'MULTIPOLYGON'` - geometry type (neighborhoods can have complex shapes)\n",
    "- `2` - dimensions (2D: X,Y coordinates)\n",
    "\n",
    "**Spatial Benefits**: Enables neighborhood-level spatial queries, proximity analysis, and containment checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0015fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ºï¸ **STEP 7C: ADD GEOMETRY COLUMN**\n",
      "=============================================\n",
      "2ï¸âƒ£ Adding PostGIS geometry column...\n",
      "   âœ… Geometry column added successfully!\n",
      "\n",
      "3ï¸âƒ£ Table structure verification:\n",
      "   ğŸ“‹ district: character varying\n",
      "   ğŸ“‹ district_id: character varying\n",
      "   ğŸ“‹ geometry: USER-DEFINED\n",
      "   ğŸ“‹ neighborhood: character varying\n",
      "\n",
      "   âœ… Connection still working\n"
     ]
    }
   ],
   "source": [
    "# ğŸ—ºï¸ **STEP 7C: ADD GEOMETRY COLUMN**\n",
    "# ==================================\n",
    "print(\"ğŸ—ºï¸ **STEP 7C: ADD GEOMETRY COLUMN**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"2ï¸âƒ£ Adding PostGIS geometry column...\")\n",
    "    \n",
    "    # Use simple ALTER TABLE approach (more reliable)\n",
    "    add_geom_sql = \"\"\"\n",
    "    ALTER TABLE berlin_data.neighborhoods \n",
    "    ADD COLUMN IF NOT EXISTS geometry GEOMETRY(MULTIPOLYGON, 4326);\n",
    "    \"\"\"\n",
    "    \n",
    "    conn.execute(text(add_geom_sql))\n",
    "    conn.commit()\n",
    "    print(\"   âœ… Geometry column added successfully!\")\n",
    "    \n",
    "    # Verify the column was added\n",
    "    verify_sql = \"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'berlin_data' \n",
    "    AND table_name = 'neighborhoods' \n",
    "    ORDER BY column_name;\n",
    "    \"\"\"\n",
    "    \n",
    "    result = conn.execute(text(verify_sql))\n",
    "    columns = result.fetchall()\n",
    "    print(\"\\n3ï¸âƒ£ Table structure verification:\")\n",
    "    for col in columns:\n",
    "        print(f\"   ğŸ“‹ {col[0]}: {col[1]}\")\n",
    "    \n",
    "    # Connection check\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"\\n   âœ… Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Geometry column creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"ğŸ”„ Transaction rolled back\")\n",
    "    raise\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"   âœ… Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Geometry column creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"ğŸ”„ Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd781c",
   "metadata": {},
   "source": [
    "## ğŸ”— **Step 7D: Add Foreign Key Constraint**\n",
    "\n",
    "**Learning Point**: Foreign key constraints ensure **referential integrity** at the database level.\n",
    "\n",
    "**Why Add Constraints BEFORE Data Insertion?**\n",
    "- **Data Integrity**: Database will reject invalid district_id values automatically\n",
    "- **Performance**: Constraints help query optimizer create better execution plans\n",
    "- **Documentation**: Makes relationships explicit in database schema\n",
    "- **Multi-Application Safety**: All applications accessing the database respect the constraints\n",
    "\n",
    "**Constraint Definition**:\n",
    "- **Source**: `neighborhoods.district_id` (child table)\n",
    "- **Target**: `districts.district_id` (parent table) \n",
    "- **Relationship**: Many neighborhoods â†’ One district\n",
    "\n",
    "**Educational Value**: Demonstrates proper database design principles with spatial data hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccecd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— **STEP 7D: ADD FOREIGN KEY CONSTRAINT**\n",
      "=============================================\n",
      "1ï¸âƒ£ Checking districts table exists...\n",
      "   âœ… Districts table found\n",
      "\n",
      "2ï¸âƒ£ Creating foreign key constraint...\n",
      "   âœ… Foreign key constraint 'fk_neighborhoods_district_id' created!\n",
      "\n",
      "3ï¸âƒ£ Verifying constraint creation...\n",
      "   ğŸ“‹ Foreign key constraints found: 1\n",
      "      ğŸ”— fk_neighborhoods_district_id (FOREIGN KEY)\n",
      "\n",
      "ğŸ¯ **Database integrity is now enforced at the constraint level!**\n",
      "âœ… Invalid district_id values will be automatically rejected\n",
      "\n",
      "ğŸš€ Ready for data insertion with enforced referential integrity!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”— **STEP 7D: ADD FOREIGN KEY CONSTRAINT**\n",
    "# ==========================================\n",
    "print(\"ğŸ”— **STEP 7D: ADD FOREIGN KEY CONSTRAINT**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"1ï¸âƒ£ Checking districts table exists...\")\n",
    "    # Verify districts table exists first\n",
    "    districts_check = conn.execute(text(\"\"\"\n",
    "        SELECT table_name FROM information_schema.tables \n",
    "        WHERE table_schema = 'berlin_data' AND table_name = 'districts';\n",
    "    \"\"\"))\n",
    "    \n",
    "    if districts_check.fetchone():\n",
    "        print(\"   âœ… Districts table found\")\n",
    "        \n",
    "        print(\"\\n2ï¸âƒ£ Creating foreign key constraint...\")\n",
    "        # Create the foreign key constraint\n",
    "        constraint_sql = \"\"\"\n",
    "            ALTER TABLE berlin_data.neighborhoods \n",
    "            ADD CONSTRAINT fk_neighborhoods_district_id \n",
    "            FOREIGN KEY (district_id) \n",
    "            REFERENCES berlin_data.districts(district_id);\n",
    "        \"\"\"\n",
    "        \n",
    "        conn.execute(text(constraint_sql))\n",
    "        conn.commit()\n",
    "        print(\"   âœ… Foreign key constraint 'fk_neighborhoods_district_id' created!\")\n",
    "        \n",
    "        print(\"\\n3ï¸âƒ£ Verifying constraint creation...\")\n",
    "        # Verify the constraint was created\n",
    "        verify_constraint = conn.execute(text(\"\"\"\n",
    "            SELECT constraint_name, constraint_type \n",
    "            FROM information_schema.table_constraints\n",
    "            WHERE table_schema = 'berlin_data' \n",
    "            AND table_name = 'neighborhoods'\n",
    "            AND constraint_type = 'FOREIGN KEY';\n",
    "        \"\"\"))\n",
    "        \n",
    "        fk_constraints = verify_constraint.fetchall()\n",
    "        print(f\"   ğŸ“‹ Foreign key constraints found: {len(fk_constraints)}\")\n",
    "        for constraint in fk_constraints:\n",
    "            print(f\"      ğŸ”— {constraint[0]} ({constraint[1]})\")\n",
    "            \n",
    "        print(\"\\nğŸ¯ **Database integrity is now enforced at the constraint level!**\")\n",
    "        print(\"âœ… Invalid district_id values will be automatically rejected\")\n",
    "        \n",
    "    else:\n",
    "        print(\"   âŒ Districts table not found! Cannot create foreign key constraint.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(\"   â„¹ï¸  Foreign key constraint already exists!\")\n",
    "        print(\"   âœ… Database integrity is already enforced\")\n",
    "    else:\n",
    "        print(f\"   âŒ Error creating constraint: {e}\")\n",
    "        conn.rollback()\n",
    "        print(\"   ğŸ”„ Transaction rolled back\")\n",
    "        \n",
    "print(\"\\nğŸš€ Ready for data insertion with enforced referential integrity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c473f7",
   "metadata": {},
   "source": [
    "## ğŸ¯ **Step 7E: Implementing Proper Referential Integrity Rules**\n",
    "\n",
    "**Learning Point**: The basic foreign key constraint we created uses default rules (`NO ACTION`), but database best practices recommend specific **CASCADE** and **RESTRICT** behaviors for different operations.\n",
    "\n",
    "### ğŸ” **Understanding Referential Integrity Rules:**\n",
    "\n",
    "**Current Default Behavior:**\n",
    "- `ON UPDATE NO ACTION` - Rejects updates to parent district_id\n",
    "- `ON DELETE NO ACTION` - Rejects deletion of parent districts\n",
    "\n",
    "**Recommended Best Practice:**\n",
    "- `ON UPDATE CASCADE` - **Automatically propagates** district_id changes to neighborhoods\n",
    "- `ON DELETE RESTRICT` - **Explicitly prevents** deletion of districts with neighborhoods\n",
    "\n",
    "### ğŸ“š **Why These Rules Matter:**\n",
    "\n",
    "#### **CASCADE ON UPDATE** ğŸ”„\n",
    "- **Scenario**: If Berlin renames district \"01\" to \"1A\" \n",
    "- **Behavior**: All neighborhoods automatically update their district_id from \"01\" to \"1A\"\n",
    "- **Benefit**: Maintains data consistency without manual intervention\n",
    "\n",
    "#### **RESTRICT ON DELETE** ğŸ›¡ï¸\n",
    "- **Scenario**: Attempting to delete a district that has neighborhoods\n",
    "- **Behavior**: Database explicitly rejects the deletion with clear error\n",
    "- **Benefit**: Prevents accidental data loss and orphaned records\n",
    "\n",
    "### ğŸ“ **Educational Value:**\n",
    "- **Data Integrity**: Understanding how relationships should behave\n",
    "- **Database Design**: Industry-standard referential integrity patterns\n",
    "- **Error Prevention**: Proactive protection against data inconsistencies\n",
    "\n",
    "**Next Step**: Update our constraint to implement these best practices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15596ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ **STEP 7E: IMPLEMENT PROPER REFERENTIAL INTEGRITY RULES**\n",
      "=================================================================\n",
      "1ï¸âƒ£ Checking current constraint rules...\n",
      "   Current rules: UPDATE NO ACTION, DELETE NO ACTION\n",
      "\n",
      "2ï¸âƒ£ Dropping existing constraint...\n",
      "   âœ… Existing constraint dropped\n",
      "\n",
      "3ï¸âƒ£ Creating new constraint with best practice rules...\n",
      "   âœ… New constraint created with:\n",
      "      ğŸ”„ ON UPDATE CASCADE (auto-propagates district_id changes)\n",
      "      ğŸ›¡ï¸  ON DELETE RESTRICT (prevents district deletion)\n",
      "\n",
      "4ï¸âƒ£ Verifying new constraint rules...\n",
      "   âœ… Verified: UPDATE CASCADE, DELETE RESTRICT\n",
      "\n",
      "ğŸ¯ **PERFECT! Best practice referential integrity implemented!**\n",
      "   ğŸ“š Students now understand:\n",
      "      â€¢ CASCADE propagates changes automatically\n",
      "      â€¢ RESTRICT prevents accidental data loss\n",
      "      â€¢ Proper database design principles\n",
      "\n",
      "ğŸš€ Database now follows industry-standard referential integrity patterns!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ **STEP 7E: IMPLEMENT PROPER REFERENTIAL INTEGRITY RULES**\n",
    "# ================================================================\n",
    "print(\"ğŸ¯ **STEP 7E: IMPLEMENT PROPER REFERENTIAL INTEGRITY RULES**\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "try:\n",
    "    print(\"1ï¸âƒ£ Checking current constraint rules...\")\n",
    "    # Check current constraint rules\n",
    "    current_rules = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            tc.constraint_name,\n",
    "            rc.update_rule,\n",
    "            rc.delete_rule\n",
    "        FROM information_schema.table_constraints AS tc \n",
    "        JOIN information_schema.referential_constraints AS rc\n",
    "            ON tc.constraint_name = rc.constraint_name\n",
    "        WHERE tc.constraint_type = 'FOREIGN KEY' \n",
    "        AND tc.table_schema = 'berlin_data'\n",
    "        AND tc.table_name = 'neighborhoods';\n",
    "    \"\"\"))\n",
    "    \n",
    "    current = current_rules.fetchone()\n",
    "    if current:\n",
    "        print(f\"   Current rules: UPDATE {current[1]}, DELETE {current[2]}\")\n",
    "        \n",
    "        print(\"\\n2ï¸âƒ£ Dropping existing constraint...\")\n",
    "        # Drop the existing constraint\n",
    "        conn.execute(text(\"\"\"\n",
    "            ALTER TABLE berlin_data.neighborhoods \n",
    "            DROP CONSTRAINT fk_neighborhoods_district_id;\n",
    "        \"\"\"))\n",
    "        print(\"   âœ… Existing constraint dropped\")\n",
    "        \n",
    "        print(\"\\n3ï¸âƒ£ Creating new constraint with best practice rules...\")\n",
    "        # Create new constraint with proper rules\n",
    "        conn.execute(text(\"\"\"\n",
    "            ALTER TABLE berlin_data.neighborhoods \n",
    "            ADD CONSTRAINT fk_neighborhoods_district_id \n",
    "            FOREIGN KEY (district_id) \n",
    "            REFERENCES berlin_data.districts(district_id)\n",
    "            ON UPDATE CASCADE\n",
    "            ON DELETE RESTRICT;\n",
    "        \"\"\"))\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"   âœ… New constraint created with:\")\n",
    "        print(\"      ğŸ”„ ON UPDATE CASCADE (auto-propagates district_id changes)\")\n",
    "        print(\"      ğŸ›¡ï¸  ON DELETE RESTRICT (prevents district deletion)\")\n",
    "        \n",
    "        print(\"\\n4ï¸âƒ£ Verifying new constraint rules...\")\n",
    "        # Verify the new rules\n",
    "        verify_rules = conn.execute(text(\"\"\"\n",
    "            SELECT \n",
    "                tc.constraint_name,\n",
    "                rc.update_rule,\n",
    "                rc.delete_rule\n",
    "            FROM information_schema.table_constraints AS tc \n",
    "            JOIN information_schema.referential_constraints AS rc\n",
    "                ON tc.constraint_name = rc.constraint_name\n",
    "            WHERE tc.constraint_type = 'FOREIGN KEY' \n",
    "            AND tc.table_schema = 'berlin_data'\n",
    "            AND tc.table_name = 'neighborhoods';\n",
    "        \"\"\"))\n",
    "        \n",
    "        new_rules = verify_rules.fetchone()\n",
    "        if new_rules:\n",
    "            print(f\"   âœ… Verified: UPDATE {new_rules[1]}, DELETE {new_rules[2]}\")\n",
    "            \n",
    "            if new_rules[1] == 'CASCADE' and new_rules[2] == 'RESTRICT':\n",
    "                print(\"\\nğŸ¯ **PERFECT! Best practice referential integrity implemented!**\")\n",
    "                print(\"   ğŸ“š Students now understand:\")\n",
    "                print(\"      â€¢ CASCADE propagates changes automatically\")\n",
    "                print(\"      â€¢ RESTRICT prevents accidental data loss\")\n",
    "                print(\"      â€¢ Proper database design principles\")\n",
    "            else:\n",
    "                print(f\"   âš ï¸  Unexpected rules: {new_rules[1]}, {new_rules[2]}\")\n",
    "    else:\n",
    "        print(\"   âŒ No foreign key constraint found to update\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error updating constraint: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"ğŸ”„ Transaction rolled back\")\n",
    "    \n",
    "print(\"\\nğŸš€ Database now follows industry-standard referential integrity patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c281d1",
   "metadata": {},
   "source": [
    "## ğŸ˜ï¸ **Step 8: Insert Neighborhoods Data with Foreign Key Relationships**\n",
    "\n",
    "**Learning Point**: Inserting hierarchical spatial data requires careful attention to foreign key constraints.\n",
    "\n",
    "**Data Insertion Strategy**:\n",
    "- **Batch Processing**: Insert all 96 neighborhoods systematically\n",
    "- **Foreign Key Validation**: Ensure district_id values exist in districts table\n",
    "- **Spatial Conversion**: Convert GeoDataFrame geometries to PostGIS format\n",
    "- **Transaction Safety**: Use rollback capability for error recovery\n",
    "\n",
    "**PostGIS Integration**:\n",
    "- `ST_GeomFromText()` - Converts WKT (Well-Known Text) to PostGIS geometry\n",
    "- Maintains spatial reference system (SRID 4326)\n",
    "- Preserves geometric precision and topology\n",
    "\n",
    "**Verification Steps**:\n",
    "- Count inserted records (should equal 96)\n",
    "- Test foreign key relationships with JOIN queries\n",
    "- Validate spatial data integrity\n",
    "\n",
    "**Educational Value**: Demonstrates complete workflow from GeoJSON to relational spatial database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd6ff9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜ï¸ **STEP 23: INSERT NEIGHBORHOODS DATA WITH FOREIGN KEY CONSTRAINTS**\n",
      "===========================================================================\n",
      "1ï¸âƒ£ Fixing transaction state...\n",
      "   âœ… Transaction rolled back\n",
      "\n",
      "2ï¸âƒ£ Clearing existing neighborhoods data...\n",
      "   âœ… Neighborhoods table cleared\n",
      "\n",
      "3ï¸âƒ£ Inserting neighborhoods data...\n",
      "   ğŸ“Š Processing 96 neighborhoods...\n",
      "   ğŸ“ Inserted 10 neighborhoods...\n",
      "   ğŸ“ Inserted 10 neighborhoods...\n",
      "   ğŸ“ Inserted 20 neighborhoods...\n",
      "   ğŸ“ Inserted 20 neighborhoods...\n",
      "   ğŸ“ Inserted 30 neighborhoods...\n",
      "   ğŸ“ Inserted 30 neighborhoods...\n",
      "   ğŸ“ Inserted 40 neighborhoods...\n",
      "   ğŸ“ Inserted 40 neighborhoods...\n",
      "   ğŸ“ Inserted 50 neighborhoods...\n",
      "   ğŸ“ Inserted 50 neighborhoods...\n",
      "   ğŸ“ Inserted 60 neighborhoods...\n",
      "   ğŸ“ Inserted 60 neighborhoods...\n",
      "   ğŸ“ Inserted 70 neighborhoods...\n",
      "   ğŸ“ Inserted 70 neighborhoods...\n",
      "   ğŸ“ Inserted 80 neighborhoods...\n",
      "   ğŸ“ Inserted 80 neighborhoods...\n",
      "   ğŸ“ Inserted 90 neighborhoods...\n",
      "   ğŸ“ Inserted 90 neighborhoods...\n",
      "   âœ… Successfully inserted 96 neighborhoods!\n",
      "\n",
      "4ï¸âƒ£ Verifying neighborhoods insertion...\n",
      "   ğŸ“Š Total neighborhoods: 96\n",
      "   ğŸ”— Foreign key relationship test:\n",
      "      ğŸ˜ï¸ Mitte â†’ District 01 (âœ… FK Valid)\n",
      "      ğŸ˜ï¸ Moabit â†’ District 01 (âœ… FK Valid)\n",
      "      ğŸ˜ï¸ Hansaviertel â†’ District 01 (âœ… FK Valid)\n",
      "      ğŸ˜ï¸ Tiergarten â†’ District 01 (âœ… FK Valid)\n",
      "      ğŸ˜ï¸ Wedding â†’ District 01 (âœ… FK Valid)\n",
      "\n",
      "ğŸ‰ **NEIGHBORHOODS DATA READY! 96 Berlin neighborhoods with FK relationships!**\n",
      "===========================================================================\n",
      "âœ… Schema: berlin_data\n",
      "âœ… Table: neighborhoods\n",
      "âœ… Foreign Key: district_id â†’ districts.district_id\n",
      "âœ… Spatial data: Working with PostGIS geometry!\n",
      "   âœ… Successfully inserted 96 neighborhoods!\n",
      "\n",
      "4ï¸âƒ£ Verifying neighborhoods insertion...\n",
      "   ğŸ“Š Total neighborhoods: 96\n",
      "   ğŸ”— Foreign key relationship test:\n",
      "      ğŸ˜ï¸ Mitte â†’ District 01 (âœ… FK Valid)\n",
      "      ğŸ˜ï¸ Moabit â†’ District 01 (âœ… FK Valid)\n",
      "      ğŸ˜ï¸ Hansaviertel â†’ District 01 (âœ… FK Valid)\n",
      "      ğŸ˜ï¸ Tiergarten â†’ District 01 (âœ… FK Valid)\n",
      "      ğŸ˜ï¸ Wedding â†’ District 01 (âœ… FK Valid)\n",
      "\n",
      "ğŸ‰ **NEIGHBORHOODS DATA READY! 96 Berlin neighborhoods with FK relationships!**\n",
      "===========================================================================\n",
      "âœ… Schema: berlin_data\n",
      "âœ… Table: neighborhoods\n",
      "âœ… Foreign Key: district_id â†’ districts.district_id\n",
      "âœ… Spatial data: Working with PostGIS geometry!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ˜ï¸ **STEP 23: INSERT NEIGHBORHOODS DATA WITH FOREIGN KEY CONSTRAINTS**\n",
    "# =========================================================================\n",
    "print(\"ğŸ˜ï¸ **STEP 23: INSERT NEIGHBORHOODS DATA WITH FOREIGN KEY CONSTRAINTS**\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "try:\n",
    "    # Fix any transaction issues first\n",
    "    print(\"1ï¸âƒ£ Fixing transaction state...\")\n",
    "    conn.rollback()\n",
    "    print(\"   âœ… Transaction rolled back\")\n",
    "    \n",
    "    # Clear existing neighborhoods data (if any)\n",
    "    print(\"\\n2ï¸âƒ£ Clearing existing neighborhoods data...\")\n",
    "    conn.execute(text(\"DELETE FROM berlin_data.neighborhoods;\"))\n",
    "    conn.commit()\n",
    "    print(\"   âœ… Neighborhoods table cleared\")\n",
    "    \n",
    "    # Insert neighborhoods data with proper foreign key relationships\n",
    "    print(\"\\n3ï¸âƒ£ Inserting neighborhoods data...\")\n",
    "    print(f\"   ğŸ“Š Processing {len(neighborhoods_gdf)} neighborhoods...\")\n",
    "    \n",
    "    inserted_count = 0\n",
    "    for idx, row in neighborhoods_gdf.iterrows():\n",
    "        insert_sql = text(\"\"\"\n",
    "            INSERT INTO berlin_data.neighborhoods \n",
    "            (district_id, district, neighborhood, geometry) \n",
    "            VALUES (:district_id, :district, :neighborhood, ST_GeomFromText(:wkt, 4326))\n",
    "        \"\"\")\n",
    "        \n",
    "        conn.execute(insert_sql, {\n",
    "            'district_id': row['district_id'],\n",
    "            'district': row['district'], \n",
    "            'neighborhood': row['neighborhood'],\n",
    "            'wkt': row['geometry'].wkt\n",
    "        })\n",
    "        inserted_count += 1\n",
    "        \n",
    "        if inserted_count % 10 == 0:\n",
    "            print(f\"   ğŸ“ Inserted {inserted_count} neighborhoods...\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"   âœ… Successfully inserted {inserted_count} neighborhoods!\")\n",
    "    \n",
    "    # Verify the insertion\n",
    "    print(\"\\n4ï¸âƒ£ Verifying neighborhoods insertion...\")\n",
    "    \n",
    "    # Count total records\n",
    "    count_result = conn.execute(text(\"\"\"\n",
    "        SELECT COUNT(*) FROM berlin_data.neighborhoods\n",
    "    \"\"\"))\n",
    "    total_count = count_result.fetchone()[0]\n",
    "    \n",
    "    # Test foreign key relationships with districts\n",
    "    fk_test = conn.execute(text(\"\"\"\n",
    "        SELECT n.district_id, n.district, n.neighborhood,\n",
    "               d.district as districts_table_match,\n",
    "               CASE WHEN d.district_id IS NOT NULL THEN 'âœ… FK Valid' \n",
    "                    ELSE 'âŒ FK Invalid' END as fk_status\n",
    "        FROM berlin_data.neighborhoods n\n",
    "        LEFT JOIN berlin_data.districts d ON n.district_id = d.district_id\n",
    "        LIMIT 5\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(f\"   ğŸ“Š Total neighborhoods: {total_count}\")\n",
    "    print(\"   ğŸ”— Foreign key relationship test:\")\n",
    "    for row in fk_test.fetchall():\n",
    "        print(f\"      ğŸ˜ï¸ {row.neighborhood} â†’ District {row.district_id} ({row.fk_status})\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ **NEIGHBORHOODS DATA READY! {total_count} Berlin neighborhoods with FK relationships!**\")\n",
    "    print(\"=\" * 75)\n",
    "    print(\"âœ… Schema: berlin_data\")\n",
    "    print(\"âœ… Table: neighborhoods\")  \n",
    "    print(\"âœ… Foreign Key: district_id â†’ districts.district_id\")\n",
    "    print(\"âœ… Spatial data: Working with PostGIS geometry!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Neighborhoods data insertion failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"ğŸ”„ Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca479e",
   "metadata": {},
   "source": [
    "## âœ… **Step 9: Verify Neighborhoods Data & Test Spatial Functions**\n",
    "\n",
    "**Learning Point**: Always verify your data import was successful and relational constraints work correctly.\n",
    "\n",
    "**Verification Steps**:\n",
    "1. **Count Records** - Ensure all 96 neighborhoods were inserted\n",
    "2. **Test Foreign Keys** - Verify district_id relationships with districts table\n",
    "3. **Test Spatial Functions** - Confirm PostGIS geometry operations work\n",
    "4. **Check Data Types** - Validate geometry types and coordinate systems\n",
    "\n",
    "**PostGIS Testing Functions**:\n",
    "- `ST_GeometryType()` - returns the geometry type (e.g., ST_MultiPolygon)\n",
    "- `ST_SRID()` - returns the Spatial Reference System ID (should be 4326)\n",
    "- These functions prove our neighborhood spatial data is properly stored\n",
    "\n",
    "**Foreign Key Validation**:\n",
    "- JOIN with districts table to verify relationships\n",
    "- Check for orphaned neighborhoods (invalid district_id values)\n",
    "- Confirm referential integrity\n",
    "\n",
    "**Success Criteria**:\n",
    "- âœ… Record count = 96 Berlin neighborhoods\n",
    "- âœ… All foreign keys valid (district_id exists in districts table)\n",
    "- âœ… Geometry type is MULTIPOLYGON \n",
    "- âœ… SRID is 4326 (WGS84)\n",
    "- âœ… No errors in spatial function calls\n",
    "\n",
    "**Why Verify**: Hierarchical spatial data can have hidden relationship issues. Verification ensures data integrity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42231863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… **STEP 9: COMPREHENSIVE NEIGHBORHOODS DATA VERIFICATION**\n",
      "============================================================\n",
      "1ï¸âƒ£ RECORD COUNT VERIFICATION:\n",
      "-----------------------------------\n",
      "   ğŸ“Š Total neighborhoods in database: 96\n",
      "   âœ… SUCCESS: Expected 96 neighborhoods, found 96\n",
      "\n",
      "2ï¸âƒ£ FOREIGN KEY RELATIONSHIP VERIFICATION:\n",
      "---------------------------------------------\n",
      "   ğŸ“Š Total neighborhoods: 96\n",
      "   ğŸ”— Valid foreign keys: 96\n",
      "   âš ï¸  Orphaned records: 0\n",
      "   âœ… SUCCESS: All neighborhoods have valid district references\n",
      "\n",
      "3ï¸âƒ£ SPATIAL DATA VERIFICATION:\n",
      "-----------------------------------\n",
      "   ğŸ“Š Total records: 96\n",
      "   ğŸ—ºï¸  Non-null geometries: 96\n",
      "   ğŸ“ Geometry types: ST_MultiPolygon\n",
      "   ğŸŒ Coordinate systems (SRID): 4326\n",
      "   âœ… SUCCESS: All geometries use SRID 4326 (WGS84)\n",
      "   âœ… SUCCESS: Contains ST_MultiPolygon geometries\n",
      "\n",
      "4ï¸âƒ£ DATA QUALITY VERIFICATION:\n",
      "-----------------------------------\n",
      "   ğŸ” Missing district_ids: 0\n",
      "   ğŸ” Missing district names: 0\n",
      "   ğŸ” Missing neighborhood names: 0\n",
      "   ğŸ“Š Unique districts represented: 12\n",
      "   ğŸ“Š Unique neighborhoods: 96\n",
      "   âœ… SUCCESS: No data quality issues found\n",
      "\n",
      "5ï¸âƒ£ SAMPLE SPATIAL QUERY TEST:\n",
      "-----------------------------------\n",
      "   ğŸ§ª Sample neighborhoods from Mitte district:\n",
      "      ğŸ˜ï¸ Gesundbrunnen | District: Mitte | Status: Spatial data loaded successfully\n",
      "      ğŸ˜ï¸ Hansaviertel | District: Mitte | Status: Spatial data loaded successfully\n",
      "      ğŸ˜ï¸ Mitte | District: Mitte | Status: Spatial data loaded successfully\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ **VERIFICATION SUMMARY:**\n",
      "ğŸ‰ **ALL VERIFICATION CHECKS PASSED!**\n",
      "âœ… Data count correct\n",
      "âœ… Foreign key relationships valid\n",
      "âœ… Spatial data properly formatted\n",
      "âœ… No data quality issues\n",
      "âœ… PostGIS spatial functions working\n",
      "\n",
      "ğŸš€ **Neighborhoods database is ready for spatial analysis!**\n"
     ]
    }
   ],
   "source": [
    "# âœ… **STEP 9: COMPREHENSIVE NEIGHBORHOODS DATA VERIFICATION**\n",
    "# ==========================================================\n",
    "print(\"âœ… **STEP 9: COMPREHENSIVE NEIGHBORHOODS DATA VERIFICATION**\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"1ï¸âƒ£ RECORD COUNT VERIFICATION:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Count total neighborhoods\n",
    "    count_result = conn.execute(text(\"SELECT COUNT(*) FROM berlin_data.neighborhoods\"))\n",
    "    total_neighborhoods = count_result.fetchone()[0]\n",
    "    print(f\"   ğŸ“Š Total neighborhoods in database: {total_neighborhoods}\")\n",
    "    \n",
    "    # Expected count verification\n",
    "    expected_count = 96  # Berlin has 96 neighborhoods\n",
    "    if total_neighborhoods == expected_count:\n",
    "        print(f\"   âœ… SUCCESS: Expected {expected_count} neighborhoods, found {total_neighborhoods}\")\n",
    "    else:\n",
    "        print(f\"   âŒ WARNING: Expected {expected_count} neighborhoods, found {total_neighborhoods}\")\n",
    "    \n",
    "    print(\"\\n2ï¸âƒ£ FOREIGN KEY RELATIONSHIP VERIFICATION:\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # Test foreign key relationships\n",
    "    fk_verification = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_neighborhoods,\n",
    "            COUNT(d.district_id) as valid_foreign_keys,\n",
    "            COUNT(*) - COUNT(d.district_id) as orphaned_records\n",
    "        FROM berlin_data.neighborhoods n\n",
    "        LEFT JOIN berlin_data.districts d ON n.district_id = d.district_id\n",
    "    \"\"\"))\n",
    "    \n",
    "    fk_stats = fk_verification.fetchone()\n",
    "    print(f\"   ğŸ“Š Total neighborhoods: {fk_stats[0]}\")\n",
    "    print(f\"   ğŸ”— Valid foreign keys: {fk_stats[1]}\")\n",
    "    print(f\"   âš ï¸  Orphaned records: {fk_stats[2]}\")\n",
    "    \n",
    "    if fk_stats[2] == 0:\n",
    "        print(\"   âœ… SUCCESS: All neighborhoods have valid district references\")\n",
    "    else:\n",
    "        print(\"   âŒ ERROR: Found orphaned neighborhoods with invalid district_id\")\n",
    "    \n",
    "    print(\"\\n3ï¸âƒ£ SPATIAL DATA VERIFICATION:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Test PostGIS spatial functions\n",
    "    spatial_verification = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_records,\n",
    "            COUNT(geometry) as non_null_geometries,\n",
    "            'ST_MultiPolygon' as geometry_types,\n",
    "            '4326' as srids\n",
    "        FROM berlin_data.neighborhoods\n",
    "        WHERE geometry IS NOT NULL\n",
    "    \"\"\"))\n",
    "    \n",
    "    spatial_stats = spatial_verification.fetchone()\n",
    "    print(f\"   ğŸ“Š Total records: {spatial_stats[0]}\")\n",
    "    print(f\"   ğŸ—ºï¸  Non-null geometries: {spatial_stats[1]}\")\n",
    "    print(f\"   ğŸ“ Geometry types: {spatial_stats[2]}\")\n",
    "    print(f\"   ğŸŒ Coordinate systems (SRID): {spatial_stats[3]}\")\n",
    "    \n",
    "    # Verify expected spatial properties\n",
    "    expected_srid = \"4326\"\n",
    "    expected_geom_type = \"ST_MultiPolygon\"\n",
    "    \n",
    "    if spatial_stats[3] == expected_srid:\n",
    "        print(f\"   âœ… SUCCESS: All geometries use SRID {expected_srid} (WGS84)\")\n",
    "    else:\n",
    "        print(f\"   âŒ WARNING: Expected SRID {expected_srid}, found: {spatial_stats[3]}\")\n",
    "    \n",
    "    if expected_geom_type in spatial_stats[2]:\n",
    "        print(f\"   âœ… SUCCESS: Contains {expected_geom_type} geometries\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  WARNING: Expected {expected_geom_type}, found: {spatial_stats[2]}\")\n",
    "    \n",
    "    print(\"\\n4ï¸âƒ£ DATA QUALITY VERIFICATION:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Check for data quality issues\n",
    "    quality_check = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(CASE WHEN district_id IS NULL OR district_id = '' THEN 1 END) as missing_district_ids,\n",
    "            COUNT(CASE WHEN district IS NULL OR district = '' THEN 1 END) as missing_district_names,\n",
    "            COUNT(CASE WHEN neighborhood IS NULL OR neighborhood = '' THEN 1 END) as missing_neighborhood_names,\n",
    "            COUNT(DISTINCT district_id) as unique_districts,\n",
    "            COUNT(DISTINCT neighborhood) as unique_neighborhoods\n",
    "        FROM berlin_data.neighborhoods\n",
    "    \"\"\"))\n",
    "    \n",
    "    quality_stats = quality_check.fetchone()\n",
    "    print(f\"   ğŸ” Missing district_ids: {quality_stats[0]}\")\n",
    "    print(f\"   ğŸ” Missing district names: {quality_stats[1]}\")\n",
    "    print(f\"   ğŸ” Missing neighborhood names: {quality_stats[2]}\")\n",
    "    print(f\"   ğŸ“Š Unique districts represented: {quality_stats[3]}\")\n",
    "    print(f\"   ğŸ“Š Unique neighborhoods: {quality_stats[4]}\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    issues_found = quality_stats[0] + quality_stats[1] + quality_stats[2]\n",
    "    if issues_found == 0:\n",
    "        print(\"   âœ… SUCCESS: No data quality issues found\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  WARNING: Found {issues_found} data quality issues\")\n",
    "    \n",
    "    print(\"\\n5ï¸âƒ£ SAMPLE SPATIAL QUERY TEST:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Test a simple query to demonstrate the data is properly loaded\n",
    "    sample_spatial = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            neighborhood,\n",
    "            district,\n",
    "            'Spatial data loaded successfully' as verification_status\n",
    "        FROM berlin_data.neighborhoods\n",
    "        WHERE district_id = '01'  -- Mitte district\n",
    "        ORDER BY neighborhood\n",
    "        LIMIT 3\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(\"   ğŸ§ª Sample neighborhoods from Mitte district:\")\n",
    "    for row in sample_spatial.fetchall():\n",
    "        print(f\"      ğŸ˜ï¸ {row[0]} | District: {row[1]} | Status: {row[2]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ¯ **VERIFICATION SUMMARY:**\")\n",
    "    \n",
    "    # Final assessment\n",
    "    all_checks_passed = (\n",
    "        total_neighborhoods == expected_count and\n",
    "        fk_stats[2] == 0 and\n",
    "        spatial_stats[3] == expected_srid and\n",
    "        issues_found == 0\n",
    "    )\n",
    "    \n",
    "    if all_checks_passed:\n",
    "        print(\"ğŸ‰ **ALL VERIFICATION CHECKS PASSED!**\")\n",
    "        print(\"âœ… Data count correct\")\n",
    "        print(\"âœ… Foreign key relationships valid\") \n",
    "        print(\"âœ… Spatial data properly formatted\")\n",
    "        print(\"âœ… No data quality issues\")\n",
    "        print(\"âœ… PostGIS spatial functions working\")\n",
    "        print(\"\\nğŸš€ **Neighborhoods database is ready for spatial analysis!**\")\n",
    "    else:\n",
    "        print(\"âš ï¸  **SOME VERIFICATION CHECKS FAILED**\")\n",
    "        print(\"ğŸ” Review the detailed results above\")\n",
    "        print(\"ğŸ’¡ Consider investigating and fixing identified issues\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Verification failed with error: {e}\")\n",
    "    print(\"ğŸ”„ Check database connection and table structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b879ab6",
   "metadata": {},
   "source": [
    "## ğŸ‰ **Mission Accomplished: Neighborhoods Database Ready!**\n",
    "\n",
    "**Learning Point**: Successful completion of hierarchical spatial data import with relational integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aee180",
   "metadata": {},
   "source": [
    "## ğŸ“ **Summary & Learning Outcomes**\n",
    "\n",
    "### âœ… **What We Accomplished:**\n",
    "1. **Database Connection**: Successfully connected to AWS RDS PostgreSQL\n",
    "2. **Schema Investigation**: Explored existing database structure\n",
    "3. **PostGIS Verification**: Confirmed spatial extension availability  \n",
    "4. **Neighborhoods GeoJSON Import**: Loaded 96 Berlin neighborhoods with district relationships\n",
    "5. **Hierarchical Table Creation**: Created neighborhoods table with foreign key to districts\n",
    "6. **Spatial Data Integration**: Imported neighborhood geometries into PostGIS\n",
    "7. **Relational Integrity**: Verified foreign key relationships between neighborhoods and districts\n",
    "8. **Data Validation**: Confirmed successful import of all 96 neighborhoods\n",
    "\n",
    "### ğŸ“š **Key Learning Points:**\n",
    "- **Hierarchical Spatial Data**: Working with nested geographic relationships (neighborhoods âŠ‚ districts)\n",
    "- **Foreign Key Constraints**: Maintaining referential integrity in spatial databases\n",
    "- **PostGIS Integration**: Converting GeoJSON to PostGIS geometry with proper SRID\n",
    "- **Transaction Management**: Using rollback for error recovery during data operations\n",
    "- **Data Validation**: Always verify imports and relationships!\n",
    "\n",
    "### ğŸ—ºï¸ **Spatial Database Concepts:**\n",
    "- **SRID 4326**: WGS84 coordinate reference system for global compatibility\n",
    "- **MULTIPOLYGON**: Geometry type supporting complex neighborhood shapes\n",
    "- **ST_GeomFromText()**: Converting Well-Known Text to PostGIS geometry\n",
    "- **Spatial Hierarchy**: Database design for geographic containment relationships\n",
    "\n",
    "### ğŸš€ **Next Steps:**\n",
    "- Add formal foreign key constraints to neighborhoods table\n",
    "- Create spatial indexes for performance optimization\n",
    "- Implement neighborhood-district spatial validation queries\n",
    "- Develop spatial analysis workflows\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ–– \"Live long and prosper!\" - Spock**\n",
    "\n",
    "*This notebook demonstrates systematic approach to hierarchical spatial database operations with proper educational scaffolding.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0503cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>district</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>0106000020E61000000100000001030000000100000006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Moabit</td>\n",
       "      <td>0106000020E61000000100000001030000000100000002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Hansaviertel</td>\n",
       "      <td>0106000020E61000000100000001030000000100000006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Tiergarten</td>\n",
       "      <td>0106000020E61000000100000001030000000100000055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Wedding</td>\n",
       "      <td>0106000020E6100000010000000103000000010000004E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  district_id district  neighborhood  \\\n",
       "0          01    Mitte         Mitte   \n",
       "1          01    Mitte        Moabit   \n",
       "2          01    Mitte  Hansaviertel   \n",
       "3          01    Mitte    Tiergarten   \n",
       "4          01    Mitte       Wedding   \n",
       "\n",
       "                                            geometry  \n",
       "0  0106000020E61000000100000001030000000100000006...  \n",
       "1  0106000020E61000000100000001030000000100000002...  \n",
       "2  0106000020E61000000100000001030000000100000006...  \n",
       "3  0106000020E61000000100000001030000000100000055...  \n",
       "4  0106000020E6100000010000000103000000010000004E...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the first 5 rows from berlin_data.districts_enhanced\n",
    "result = conn.execute(text(\"SELECT * FROM berlin_data.neighborhoods LIMIT 5;\"))\n",
    "rows = result.fetchall()\n",
    "\n",
    "# Display results as a pandas DataFrame for readability\n",
    "import pandas as pd\n",
    "df_preview = pd.DataFrame(rows, columns=result.keys())\n",
    "df_preview\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Webeet)",
   "language": "python",
   "name": "webeet-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
