{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf57fa1",
   "metadata": {},
   "source": [
    "# 🗄️ **AWS Database Investigation & Districts Table Creation**\n",
    "\n",
    "## 🎯 **Learning Objectives**\n",
    "By the end of this notebook, students will understand:\n",
    "1. **Database Connection**: How to connect to AWS RDS PostgreSQL\n",
    "2. **Schema Investigation**: How to explore existing database structure\n",
    "3. **PostGIS Setup**: Understanding spatial database extensions\n",
    "4. **GeoJSON Import**: How to create PostGIS tables from GeoJSON files\n",
    "5. **Data Validation**: How to verify successful data import\n",
    "\n",
    "## 📋 **Prerequisites**\n",
    "- ✅ Enhanced GeoJSON file (`districts_enhanced.geojson`)\n",
    "- ✅ AWS database credentials\n",
    "- ✅ Basic understanding of PostgreSQL and spatial data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b143c6",
   "metadata": {},
   "source": [
    "## 📦 **Step 1: Import Required Libraries**\n",
    "\n",
    "**Learning Point**: We need specific libraries for spatial data and database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c370f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n",
      "📚 Ready for spatial database operations\n"
     ]
    }
   ],
   "source": [
    "# 📦 Import required libraries for spatial database operations\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"📚 Ready for spatial database operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfd4f7",
   "metadata": {},
   "source": [
    "## 🔌 **Step 2: AWS Database Connection**\n",
    "\n",
    "**Learning Point**: Connection strings contain all necessary information to connect to a database.\n",
    "\n",
    "**Format**: `postgresql+psycopg2://username:password@host:port/database`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd607c9",
   "metadata": {},
   "source": [
    "## 🔍 **Step 3: Database Schema Investigation**\n",
    "\n",
    "**Learning Point**: Before creating new tables, always investigate existing database structure to avoid conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32859f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔌 **CONNECTING TO AWS DATABASE**\n",
      "========================================\n",
      "1️⃣ Creating database engine...\n",
      "2️⃣ Testing connection...\n",
      "   ✅ Connected successfully!\n",
      "   🗄️  Database: berlin_project_db\n",
      "   👤 User: postgres\n",
      "   📊 PostgreSQL Version: PostgreSQL 17.4 on aarch64-unknown-linux-gnu, comp...\n"
     ]
    }
   ],
   "source": [
    "# 🔐 Clean and professional database connection using python-dotenv\n",
    "print(\"🔌 **CONNECTING TO AWS DATABASE**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Load environment variables from .env file (no string functions needed!)\n",
    "load_dotenv('../ignored_files/.env')\n",
    "PASSWORD = os.getenv('PASSWORD')\n",
    "\n",
    "# Build connection URL with secure password from .env\n",
    "DATABASE_URL = f'postgresql+psycopg2://postgres:{PASSWORD}@layered-data-warehouse.cdg2ok68acsn.eu-central-1.rds.amazonaws.com:5432/berlin_project_db'\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Creating database engine...\")\n",
    "    engine = create_engine(DATABASE_URL, connect_args={'connect_timeout': 10})\n",
    "    \n",
    "    print(\"2️⃣ Testing connection...\")\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    # Test query\n",
    "    test_result = conn.execute(text(\"SELECT current_database(), current_user, version()\"))\n",
    "    db_info = test_result.fetchone()\n",
    "    \n",
    "    print(f\"   ✅ Connected successfully!\")\n",
    "    print(f\"   🗄️  Database: {db_info[0]}\")\n",
    "    print(f\"   👤 User: {db_info[1]}\")\n",
    "    print(f\"   📊 PostgreSQL Version: {db_info[2][:50]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection failed: {e}\")\n",
    "    print(\"💡 Check network connection and credentials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6bf9338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 **DATABASE SCHEMA INVESTIGATION**\n",
      "========================================\n",
      "1️⃣ Available schemas:\n",
      "   📁 berlin_data\n",
      "   📁 public\n",
      "\n",
      "2️⃣ Target schema 'berlin_data' exists: ✅ YES\n",
      "   📋 Search path set to: berlin_data, public\n",
      "\n",
      "3️⃣ Existing tables in berlin_data schema:\n",
      "   🗄️  districts (BASE TABLE)\n",
      "   🗄️  districts_pop_stat (BASE TABLE)\n",
      "   🗄️  geography_columns (VIEW)\n",
      "   🗄️  geometry_columns (VIEW)\n",
      "   🗄️  green_spaces (BASE TABLE)\n",
      "   🗄️  hospitals (BASE TABLE)\n",
      "   🗄️  neighborhoods (BASE TABLE)\n",
      "   🗄️  regional_statistics (BASE TABLE)\n",
      "   🗄️  schools_kai (BASE TABLE)\n",
      "   🗄️  short_time_listings (BASE TABLE)\n",
      "   🗄️  spatial_ref_sys (BASE TABLE)\n",
      "   🗄️  ubahn (BASE TABLE)\n",
      "\n",
      "   📊 Total tables found: 12\n",
      "\n",
      "✅ Schema investigation complete!\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Investigate existing database structure\n",
    "print(\"🔍 **DATABASE SCHEMA INVESTIGATION**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Check available schemas\n",
    "    print(\"1️⃣ Available schemas:\")\n",
    "    schemas_result = conn.execute(text(\"\"\"\n",
    "        SELECT schema_name \n",
    "        FROM information_schema.schemata \n",
    "        WHERE schema_name NOT IN ('information_schema', 'pg_catalog', 'pg_toast')\n",
    "        ORDER BY schema_name\n",
    "    \"\"\"))\n",
    "    schemas = [row[0] for row in schemas_result.fetchall()]\n",
    "    \n",
    "    for schema in schemas:\n",
    "        print(f\"   📁 {schema}\")\n",
    "    \n",
    "    # Check if berlin_data schema exists\n",
    "    berlin_data_exists = 'berlin_data' in schemas\n",
    "    print(f\"\\n2️⃣ Target schema 'berlin_data' exists: {'✅ YES' if berlin_data_exists else '❌ NO'}\")\n",
    "    \n",
    "    if berlin_data_exists:\n",
    "        # Set search path to berlin_data\n",
    "        conn.execute(text(\"SET search_path = berlin_data, public;\"))\n",
    "        conn.commit()\n",
    "        print(\"   📋 Search path set to: berlin_data, public\")\n",
    "        \n",
    "        # Check existing tables in berlin_data\n",
    "        print(\"\\n3️⃣ Existing tables in berlin_data schema:\")\n",
    "        tables_result = conn.execute(text(\"\"\"\n",
    "            SELECT table_name, table_type \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = 'berlin_data'\n",
    "            ORDER BY table_name\n",
    "        \"\"\"))\n",
    "        tables = tables_result.fetchall()\n",
    "        \n",
    "        for table in tables:\n",
    "            print(f\"   🗄️  {table.table_name} ({table.table_type})\")\n",
    "        \n",
    "        print(f\"\\n   📊 Total tables found: {len(tables)}\")\n",
    "    \n",
    "    print(\"\\n✅ Schema investigation complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Schema investigation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055cdaff",
   "metadata": {},
   "source": [
    "## 🗺️ **Step 4: PostGIS Extension Check**\n",
    "\n",
    "**Learning Point**: PostGIS is essential for spatial data operations in PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e8d5729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗺️ **POSTGIS EXTENSION CHECK**\n",
      "========================================\n",
      "✅ PostGIS is installed!\n",
      "   📦 Extension: postgis\n",
      "   🔢 Version: 3.5.1\n",
      "   📋 Schema: berlin_data\n",
      "\n",
      "✅ PostGIS check complete!\n"
     ]
    }
   ],
   "source": [
    "# 🗺️ Check PostGIS extension status\n",
    "print(\"🗺️ **POSTGIS EXTENSION CHECK**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Check if PostGIS is installed\n",
    "    postgis_check = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            extname as extension_name,\n",
    "            extversion as version,\n",
    "            nspname as schema\n",
    "        FROM pg_extension e\n",
    "        JOIN pg_namespace n ON e.extnamespace = n.oid\n",
    "        WHERE extname = 'postgis'\n",
    "    \"\"\"))\n",
    "    \n",
    "    postgis_info = postgis_check.fetchone()\n",
    "    \n",
    "    if postgis_info:\n",
    "        print(f\"✅ PostGIS is installed!\")\n",
    "        print(f\"   📦 Extension: {postgis_info.extension_name}\")\n",
    "        print(f\"   🔢 Version: {postgis_info.version}\")\n",
    "        print(f\"   📋 Schema: {postgis_info.schema}\")\n",
    "    else:\n",
    "        print(\"❌ PostGIS not found\")\n",
    "        print(\"💡 PostGIS extension may need to be enabled\")\n",
    "    \n",
    "    print(\"\\n✅ PostGIS check complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ PostGIS check failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7e412",
   "metadata": {},
   "source": [
    "## 📂 **Step 5: Load Enhanced Districts GeoJSON**\n",
    "\n",
    "**Learning Point**: GeoJSON is a standard format for geographic data that can be easily imported into PostGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "578a7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 **LOADING ENHANCED DISTRICTS GEOJSON**\n",
      "========================================\n",
      "1️⃣ Checking file existence...\n",
      "   ✅ File found: districts_enhanced.geojson\n",
      "2️⃣ Loading GeoJSON with GeoPandas...\n",
      "   ✅ Loaded 12 districts\n",
      "   📊 Columns: ['district_id', 'district', 'geometry']\n",
      "   🌍 Coordinate Reference System: EPSG:4326\n",
      "   📏 Geometry types: ['MultiPolygon']\n",
      "\n",
      "3️⃣ Sample data preview:\n",
      "   🏢 12: Reinickendorf\n",
      "   🏢 04: Charlottenburg-Wilmersdorf\n",
      "   🏢 09: Treptow-Köpenick\n",
      "\n",
      "4️⃣ CRS verification: ✅ Already EPSG:4326\n",
      "\n",
      "✅ GeoJSON loaded and ready for database import!\n"
     ]
    }
   ],
   "source": [
    "# 📂 Load the enhanced districts GeoJSON file\n",
    "print(\"📂 **LOADING ENHANCED DISTRICTS GEOJSON**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Path to the enhanced GeoJSON file\n",
    "geojson_path = \"/Users/zeal.v/Desktop/Webeet-Internship/districts-neighborhoods-populating-db/layered-populate-data-pool-da/districts-neighborhoods-populating-db/sources/districts_enhanced.geojson\"\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Checking file existence...\")\n",
    "    if os.path.exists(geojson_path):\n",
    "        print(f\"   ✅ File found: {os.path.basename(geojson_path)}\")\n",
    "        \n",
    "        print(\"2️⃣ Loading GeoJSON with GeoPandas...\")\n",
    "        districts_gdf = gpd.read_file(geojson_path)\n",
    "        \n",
    "        print(f\"   ✅ Loaded {len(districts_gdf)} districts\")\n",
    "        print(f\"   📊 Columns: {list(districts_gdf.columns)}\")\n",
    "        print(f\"   🌍 Coordinate Reference System: {districts_gdf.crs}\")\n",
    "        print(f\"   📏 Geometry types: {districts_gdf.geometry.geom_type.unique()}\")\n",
    "        \n",
    "        print(\"\\n3️⃣ Sample data preview:\")\n",
    "        sample_data = districts_gdf[['district_id', 'district']].head(3)\n",
    "        for idx, row in sample_data.iterrows():\n",
    "            print(f\"   🏢 {row['district_id']}: {row['district']}\")\n",
    "        \n",
    "        # Ensure correct CRS (EPSG:4326 for WGS84)\n",
    "        if districts_gdf.crs != 'EPSG:4326':\n",
    "            print(f\"\\n4️⃣ Converting CRS to EPSG:4326...\")\n",
    "            districts_gdf = districts_gdf.to_crs('EPSG:4326')\n",
    "            print(\"   ✅ CRS converted to EPSG:4326\")\n",
    "        else:\n",
    "            print(\"\\n4️⃣ CRS verification: ✅ Already EPSG:4326\")\n",
    "        \n",
    "        print(\"\\n✅ GeoJSON loaded and ready for database import!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   ❌ File not found: {geojson_path}\")\n",
    "        print(\"   💡 Make sure to run the main notebook first to create enhanced files\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading GeoJSON: {e}\")\n",
    "    print(f\"🔍 Details: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c46eb",
   "metadata": {},
   "source": [
    "## 🔧 **Step 6: Enable PostGIS for Table Creation**\n",
    "\n",
    "**Learning Point**: PostGIS extension must be enabled before creating spatial tables.\n",
    "\n",
    "**Simple approach**: Enable PostGIS and set proper search path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e16bf371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 **COMPREHENSIVE POSTGIS SETUP & DIAGNOSTICS**\n",
      "=======================================================\n",
      "1️⃣ Checking PostGIS installation status...\n",
      "   ✅ PostGIS extension found: v3.5.1 in berlin_data schema\n",
      "\n",
      "2️⃣ Checking available PostGIS types...\n",
      "   📋 Available spatial types:\n",
      "      • geography in berlin_data schema\n",
      "      • geometry in berlin_data schema\n",
      "\n",
      "3️⃣ Ensuring PostGIS is properly enabled...\n",
      "   ✅ PostGIS extension command executed\n",
      "\n",
      "4️⃣ Testing PostGIS functionality...\n",
      "   ✅ PostGIS is working! Version: 3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\n",
      "   ✅ Geometry functions work: True\n",
      "\n",
      "5️⃣ Setting search path...\n",
      "   ✅ Search path: berlin_data, public\n",
      "\n",
      "6️⃣ Final spatial type availability check...\n",
      "   📋 Available types now: ['geography', 'geometry']\n",
      "\n",
      "🎉 **PostGIS setup complete! Geography type is available.**\n"
     ]
    }
   ],
   "source": [
    "# 🔧 COMPREHENSIVE PostGIS Setup and Diagnostics\n",
    "print(\"🔧 **COMPREHENSIVE POSTGIS SETUP & DIAGNOSTICS**\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "try:\n",
    "    # Step 1: Check current PostGIS status\n",
    "    print(\"1️⃣ Checking PostGIS installation status...\")\n",
    "    \n",
    "    # Check if PostGIS extension exists\n",
    "    ext_check = conn.execute(text(\"\"\"\n",
    "        SELECT extname, extversion, nspname as schema_name\n",
    "        FROM pg_extension e\n",
    "        JOIN pg_namespace n ON e.extnamespace = n.oid\n",
    "        WHERE extname = 'postgis'\n",
    "    \"\"\"))\n",
    "    \n",
    "    postgis_ext = ext_check.fetchone()\n",
    "    if postgis_ext:\n",
    "        print(f\"   ✅ PostGIS extension found: v{postgis_ext.extversion} in {postgis_ext.schema_name} schema\")\n",
    "    else:\n",
    "        print(\"   ❌ PostGIS extension not found\")\n",
    "    \n",
    "    # Step 2: Check available PostGIS types\n",
    "    print(\"\\n2️⃣ Checking available PostGIS types...\")\n",
    "    \n",
    "    types_check = conn.execute(text(\"\"\"\n",
    "        SELECT typname, nspname \n",
    "        FROM pg_type t \n",
    "        JOIN pg_namespace n ON t.typnamespace = n.oid \n",
    "        WHERE typname IN ('geometry', 'geography')\n",
    "        ORDER BY typname, nspname\n",
    "    \"\"\"))\n",
    "    \n",
    "    types_found = types_check.fetchall()\n",
    "    if types_found:\n",
    "        print(\"   📋 Available spatial types:\")\n",
    "        for type_info in types_found:\n",
    "            print(f\"      • {type_info.typname} in {type_info.nspname} schema\")\n",
    "    else:\n",
    "        print(\"   ❌ No spatial types found\")\n",
    "    \n",
    "    # Step 3: Enable PostGIS properly\n",
    "    print(\"\\n3️⃣ Ensuring PostGIS is properly enabled...\")\n",
    "    \n",
    "    # Try to enable PostGIS extension\n",
    "    conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS postgis;\"))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ PostGIS extension command executed\")\n",
    "    \n",
    "    # Check if it worked by testing PostGIS function\n",
    "    print(\"\\n4️⃣ Testing PostGIS functionality...\")\n",
    "    try:\n",
    "        test_result = conn.execute(text(\"SELECT PostGIS_Version();\"))\n",
    "        version = test_result.fetchone()[0]\n",
    "        print(f\"   ✅ PostGIS is working! Version: {version}\")\n",
    "        \n",
    "        # Test geometry creation\n",
    "        geom_test = conn.execute(text(\"\"\"\n",
    "            SELECT ST_GeomFromText('POINT(13.4050 52.5200)', 4326) IS NOT NULL as geom_works\n",
    "        \"\"\"))\n",
    "        geom_works = geom_test.fetchone()[0]\n",
    "        print(f\"   ✅ Geometry functions work: {geom_works}\")\n",
    "        \n",
    "    except Exception as test_error:\n",
    "        print(f\"   ❌ PostGIS function test failed: {test_error}\")\n",
    "    \n",
    "    # Step 5: Set search path\n",
    "    print(\"\\n5️⃣ Setting search path...\")\n",
    "    conn.execute(text(\"SET search_path = berlin_data, public;\"))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Search path: berlin_data, public\")\n",
    "    \n",
    "    # Step 6: Final type check\n",
    "    print(\"\\n6️⃣ Final spatial type availability check...\")\n",
    "    final_check = conn.execute(text(\"\"\"\n",
    "        SELECT typname \n",
    "        FROM pg_type \n",
    "        WHERE typname IN ('geometry', 'geography')\n",
    "    \"\"\"))\n",
    "    \n",
    "    final_types = [row[0] for row in final_check.fetchall()]\n",
    "    print(f\"   📋 Available types now: {final_types}\")\n",
    "    \n",
    "    if 'geography' in final_types:\n",
    "        print(\"\\n🎉 **PostGIS setup complete! Geography type is available.**\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ **Geography type still not available. Will use alternative approach.**\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ PostGIS setup failed: {e}\")\n",
    "    import traceback\n",
    "    print(f\"� Details: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de63580",
   "metadata": {},
   "source": [
    "## 🚀 **Step 7: Create Districts Table (AWS_grocery Method)**\n",
    "\n",
    "**Learning Point**: We'll use the exact same method that works in AWS_grocery project.\n",
    "\n",
    "**Proven approach**: geoalchemy2.Geography + SRID=4326;WKT format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "712ae038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 **STEP 7.5: CLEARING TRANSACTION ERROR**\n",
      "=============================================\n",
      "✅ Transaction rolled back successfully!\n",
      "🚀 Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# 🔧 **STEP 7.0: TRANSACTION ROLLBACK** (if there was an error)\n",
    "# =======================================\n",
    "print(\"🔧 **STEP 7.5: CLEARING TRANSACTION ERROR**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    # Rollback any failed transaction\n",
    "    conn.rollback()\n",
    "    print(\"✅ Transaction rolled back successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"ℹ️  Rollback note: {e}\")\n",
    "\n",
    "print(\"🚀 Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75ecfd",
   "metadata": {},
   "source": [
    "## 🔧 **Step 7A: Connection Check & Transaction Reset**\n",
    "\n",
    "**Learning Point**: Before creating tables, always verify your connection is working and clear any pending transactions.\n",
    "\n",
    "**Why this matters**: \n",
    "- Database connections can have \"dirty\" transaction states\n",
    "- Rolling back ensures we start with a clean slate\n",
    "- Connection tests verify we can communicate with the database\n",
    "\n",
    "**Best Practice**: Always check connection health before major operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "111e648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "� **STEP 7A: CONNECTION CHECK & ROLLBACK**\n",
      "=============================================\n",
      "✅ Connection working: 1\n",
      "✅ Transaction state cleared\n",
      "� Ready for table creation!\n"
     ]
    }
   ],
   "source": [
    "# � **STEP 7A: CONNECTION CHECK & ROLLBACK**\n",
    "# ============================================\n",
    "print(\"� **STEP 7A: CONNECTION CHECK & ROLLBACK**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    # Check connection status\n",
    "    test_result = conn.execute(text(\"SELECT 1 as test\"))\n",
    "    test_value = test_result.fetchone()[0]\n",
    "    print(f\"✅ Connection working: {test_value}\")\n",
    "    \n",
    "    # Rollback any pending transactions\n",
    "    conn.rollback()\n",
    "    print(\"✅ Transaction state cleared\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection issue: {e}\")\n",
    "    print(\"� Try reconnecting if needed\")\n",
    "\n",
    "print(\"� Ready for table creation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a556a3",
   "metadata": {},
   "source": [
    "## 🏗️ **Step 7B: Create Basic Table Structure**\n",
    "\n",
    "**Learning Point**: Start with simple table structure before adding complex spatial columns.\n",
    "\n",
    "**Why this approach**:\n",
    "- Creates the basic columns first (district_id, district)\n",
    "- Uses `CREATE TABLE IF NOT EXISTS` to avoid errors if table exists\n",
    "- Establishes primary structure before spatial additions\n",
    "\n",
    "**SQL Concepts**:\n",
    "- `VARCHAR(2)` for district_id (Berlin has 2-digit district codes)\n",
    "- `UNIQUE NOT NULL` ensures no duplicate district IDs\n",
    "- `VARCHAR(100)` for district names\n",
    "\n",
    "**Best Practice**: Build tables incrementally - structure first, then spatial features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be825e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ **STEP 7B: CREATE TABLE STRUCTURE**\n",
      "=============================================\n",
      "1️⃣ Creating basic table structure...\n",
      "   ✅ Basic table structure created!\n",
      "   ✅ Connection still working\n",
      "   ✅ Basic table structure created!\n",
      "   ✅ Connection still working\n"
     ]
    }
   ],
   "source": [
    "# 🏗️ **STEP 7B: CREATE TABLE STRUCTURE**\n",
    "# =====================================\n",
    "print(\"🏗️ **STEP 7B: CREATE TABLE STRUCTURE**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Creating basic table structure...\")\n",
    "    \n",
    "    create_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS berlin_data.districts_enhanced (\n",
    "        district_id VARCHAR(2) UNIQUE NOT NULL,\n",
    "        district VARCHAR(100) NOT NULL\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    conn.execute(text(create_sql))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Basic table structure created!\")\n",
    "    \n",
    "    # Connection check\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"   ✅ Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Table creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab171348",
   "metadata": {},
   "source": [
    "## 🗺️ **Step 7C: Add PostGIS Geometry Column**\n",
    "\n",
    "**Learning Point**: PostGIS provides special functions for adding spatial columns with proper constraints.\n",
    "\n",
    "**PostGIS Functions**:\n",
    "- `AddGeometryColumn()` - The standard PostGIS way to add spatial columns\n",
    "- Automatically sets up spatial constraints and metadata\n",
    "- Registers the column in PostGIS system tables\n",
    "\n",
    "**Parameters Explained**:\n",
    "- `'berlin_data'` - schema name\n",
    "- `'districts_enhanced'` - table name  \n",
    "- `'geometry'` - column name\n",
    "- `4326` - SRID (Spatial Reference System - WGS84)\n",
    "- `'MULTIPOLYGON'` - geometry type (districts can have multiple polygons)\n",
    "- `2` - dimensions (2D: X,Y coordinates)\n",
    "\n",
    "**Fallback Strategy**: If AddGeometryColumn fails, we use manual ALTER TABLE as backup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0015fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗺️ **STEP 7C: ADD GEOMETRY COLUMN**\n",
      "=============================================\n",
      "2️⃣ Adding PostGIS geometry column...\n",
      "   ✅ Geometry column added with AddGeometryColumn!\n",
      "   ✅ Connection still working\n",
      "   ✅ Connection still working\n"
     ]
    }
   ],
   "source": [
    "# 🗺️ **STEP 7C: ADD GEOMETRY COLUMN**\n",
    "# ==================================\n",
    "print(\"🗺️ **STEP 7C: ADD GEOMETRY COLUMN**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"2️⃣ Adding PostGIS geometry column...\")\n",
    "    \n",
    "    # Use AddGeometryColumn - the PostGIS standard way\n",
    "    add_geom_sql = \"\"\"\n",
    "    SELECT AddGeometryColumn('berlin_data', 'districts_enhanced', 'geometry', 4326, 'MULTIPOLYGON', 2);\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        conn.execute(text(add_geom_sql))\n",
    "        conn.commit()\n",
    "        print(\"   ✅ Geometry column added with AddGeometryColumn!\")\n",
    "    except Exception as geom_error:\n",
    "        if \"already exists\" in str(geom_error):\n",
    "            print(\"   ✅ Geometry column already exists!\")\n",
    "        else:\n",
    "            print(f\"   ⚠️ AddGeometryColumn failed: {geom_error}\")\n",
    "            print(\"   🔄 Trying alternative approach...\")\n",
    "            \n",
    "            # Alternative: Add column manually\n",
    "            alt_sql = \"\"\"\n",
    "            ALTER TABLE berlin_data.districts_enhanced \n",
    "            ADD COLUMN IF NOT EXISTS geometry GEOMETRY(MULTIPOLYGON, 4326);\n",
    "            \"\"\"\n",
    "            conn.execute(text(alt_sql))\n",
    "            conn.commit()\n",
    "            print(\"   ✅ Geometry column added manually!\")\n",
    "    \n",
    "    # Connection check\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"   ✅ Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Geometry column creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c281d1",
   "metadata": {},
   "source": [
    "## 🧹 **Step 7D: Clear Existing Data**\n",
    "\n",
    "**Learning Point**: Before inserting new data, always clear existing records to avoid duplicates.\n",
    "\n",
    "**Why clear data**:\n",
    "- Prevents duplicate records if we re-run the notebook\n",
    "- Ensures clean, consistent dataset\n",
    "- Allows for fresh data imports during development\n",
    "\n",
    "**SQL Concepts**:\n",
    "- `DELETE FROM table` - removes all records but keeps table structure\n",
    "- Much faster than `DROP TABLE` + `CREATE TABLE`\n",
    "- Preserves table constraints and indexes\n",
    "\n",
    "**Verification**: We count records after deletion to confirm the table is empty.\n",
    "\n",
    "**Best Practice**: Always verify your operations worked as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6addad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 **STEP 7D: CLEAR EXISTING DATA**\n",
      "=============================================\n",
      "3️⃣ Clearing existing data...\n",
      "   ✅ Table cleared successfully\n",
      "   📊 Current record count: 0\n",
      "   ✅ Connection still working\n"
     ]
    }
   ],
   "source": [
    "# 🧹 **STEP 7D: CLEAR EXISTING DATA**\n",
    "# =================================\n",
    "print(\"🧹 **STEP 7D: CLEAR EXISTING DATA**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"3️⃣ Clearing existing data...\")\n",
    "    \n",
    "    # Clear the table\n",
    "    conn.execute(text(\"DELETE FROM berlin_data.districts_enhanced;\"))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Table cleared successfully\")\n",
    "    \n",
    "    # Verify it's empty\n",
    "    count_check = conn.execute(text(\"SELECT COUNT(*) FROM berlin_data.districts_enhanced;\"))\n",
    "    count = count_check.fetchone()[0]\n",
    "    print(f\"   📊 Current record count: {count}\")\n",
    "    \n",
    "    # Connection check\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"   ✅ Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Data clearing failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34249618",
   "metadata": {},
   "source": [
    "## 📥 **Step 7E: Insert Districts with Spatial Data**\n",
    "\n",
    "**Learning Point**: Converting GeoDataFrame geometries to PostGIS format using WKT (Well-Known Text).\n",
    "\n",
    "**Spatial Data Conversion**:\n",
    "- `row['geometry'].wkt` - converts shapely geometry to WKT string\n",
    "- `ST_GeomFromText(wkt, 4326)` - PostGIS function to create geometry from WKT\n",
    "- SRID 4326 ensures proper coordinate reference system\n",
    "\n",
    "**Insertion Strategy**:\n",
    "- Loop through each district in our GeoDataFrame\n",
    "- Use parameterized queries to prevent SQL injection\n",
    "- Insert both attribute data (district_id, district) and spatial data (geometry)\n",
    "\n",
    "**Progress Tracking**: We show progress every 3 insertions so students can see the process.\n",
    "\n",
    "**Why WKT**: Well-Known Text is a standard, human-readable format for geometric data that PostGIS understands perfectly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8465e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 **STEP 7E: INSERT DISTRICTS DATA**\n",
      "=============================================\n",
      "4️⃣ Inserting districts data...\n",
      "❌ Data insertion failed: (psycopg2.errors.UndefinedTable) relation \"berlin_data.districts_enhanced\" does not exist\n",
      "LINE 2:             INSERT INTO berlin_data.districts_enhanced \n",
      "                                ^\n",
      "\n",
      "[SQL: \n",
      "            INSERT INTO berlin_data.districts_enhanced \n",
      "            (district_id, district, geometry) \n",
      "            VALUES (%(district_id)s, %(district)s, ST_GeomFromText(%(wkt)s, 4326))\n",
      "        ]\n",
      "[parameters: {'district_id': '12', 'district': 'Reinickendorf', 'wkt': 'MULTIPOLYGON (((13.320744327762688 52.6265990635977, 13.320450024315486 52.62661432040652, 13.320156209034547 52.626629556435226, 13.319861608831037  ... (92321 characters truncated) ... 21483735159507 52.626560722834455, 13.321338930680731 52.62656821917953, 13.321038601486716 52.62658380563724, 13.320744327762688 52.6265990635977)))'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "🔄 Transaction rolled back\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.UndefinedTable) relation \"berlin_data.districts_enhanced\" does not exist\nLINE 2:             INSERT INTO berlin_data.districts_enhanced \n                                ^\n\n[SQL: \n            INSERT INTO berlin_data.districts_enhanced \n            (district_id, district, geometry) \n            VALUES (%(district_id)s, %(district)s, ST_GeomFromText(%(wkt)s, 4326))\n        ]\n[parameters: {'district_id': '12', 'district': 'Reinickendorf', 'wkt': 'MULTIPOLYGON (((13.320744327762688 52.6265990635977, 13.320450024315486 52.62661432040652, 13.320156209034547 52.626629556435226, 13.319861608831037  ... (92321 characters truncated) ... 21483735159507 52.626560722834455, 13.321338930680731 52.62656821917953, 13.321038601486716 52.62658380563724, 13.320744327762688 52.6265990635977)))'}]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUndefinedTable\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1967\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:924\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUndefinedTable\u001b[39m: relation \"berlin_data.districts_enhanced\" does not exist\nLINE 2:             INSERT INTO berlin_data.districts_enhanced \n                                ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m districts_gdf.iterrows():\n\u001b[32m     11\u001b[39m     insert_sql = text(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m        INSERT INTO berlin_data.districts_enhanced \u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33m        (district_id, district, geometry) \u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m        VALUES (:district_id, :district, ST_GeomFromText(:wkt, 4326))\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_sql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistrict_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistrict_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistrict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistrict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwkt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgeometry\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwkt\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     inserted_count += \u001b[32m1\u001b[39m\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Progress indicator every 3 records\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1418\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:515\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m    514\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1640\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1628\u001b[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001b[32m   1629\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1630\u001b[39m )\n\u001b[32m   1632\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1633\u001b[39m     dialect=dialect,\n\u001b[32m   1634\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1638\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1639\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1640\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1654\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1655\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1659\u001b[39m         ret,\n\u001b[32m   1660\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1846\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1844\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1845\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1986\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1983\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2353\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2351\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2352\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2353\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2354\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2355\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1967\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1965\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1972\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1973\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1974\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1978\u001b[39m         context.executemany,\n\u001b[32m   1979\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Webeet-Internship/.venv/lib/python3.11/site-packages/sqlalchemy/engine/default.py:924\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mProgrammingError\u001b[39m: (psycopg2.errors.UndefinedTable) relation \"berlin_data.districts_enhanced\" does not exist\nLINE 2:             INSERT INTO berlin_data.districts_enhanced \n                                ^\n\n[SQL: \n            INSERT INTO berlin_data.districts_enhanced \n            (district_id, district, geometry) \n            VALUES (%(district_id)s, %(district)s, ST_GeomFromText(%(wkt)s, 4326))\n        ]\n[parameters: {'district_id': '12', 'district': 'Reinickendorf', 'wkt': 'MULTIPOLYGON (((13.320744327762688 52.6265990635977, 13.320450024315486 52.62661432040652, 13.320156209034547 52.626629556435226, 13.319861608831037  ... (92321 characters truncated) ... 21483735159507 52.626560722834455, 13.321338930680731 52.62656821917953, 13.321038601486716 52.62658380563724, 13.320744327762688 52.6265990635977)))'}]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "# 📥 **STEP 7E: INSERT DISTRICTS DATA**\n",
    "# ===================================\n",
    "print(\"📥 **STEP 7E: INSERT DISTRICTS DATA**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"4️⃣ Inserting districts data...\")\n",
    "    \n",
    "    inserted_count = 0\n",
    "    for idx, row in districts_gdf.iterrows():\n",
    "        insert_sql = text(\"\"\"\n",
    "            INSERT INTO berlin_data.districts_enhanced \n",
    "            (district_id, district, geometry) \n",
    "            VALUES (:district_id, :district, ST_GeomFromText(:wkt, 4326))\n",
    "        \"\"\")\n",
    "        \n",
    "        conn.execute(insert_sql, {\n",
    "            'district_id': row['district_id'],\n",
    "            'district': row['district'],\n",
    "            'wkt': row['geometry'].wkt\n",
    "        })\n",
    "        inserted_count += 1\n",
    "        \n",
    "        # Progress indicator every 3 records\n",
    "        if inserted_count % 3 == 0:\n",
    "            print(f\"   📍 Inserted {inserted_count} districts...\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"   ✅ Successfully inserted {inserted_count} districts!\")\n",
    "    \n",
    "    # Connection check\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"   ✅ Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Data insertion failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca479e",
   "metadata": {},
   "source": [
    "## ✅ **Step 7F: Verify Success & Test Spatial Functions**\n",
    "\n",
    "**Learning Point**: Always verify your data import was successful and spatial functions work correctly.\n",
    "\n",
    "**Verification Steps**:\n",
    "1. **Count Records** - Ensure all districts were inserted\n",
    "2. **Test Spatial Functions** - Verify PostGIS geometry operations work\n",
    "3. **Check Data Types** - Confirm geometry types and coordinate systems\n",
    "\n",
    "**PostGIS Testing Functions**:\n",
    "- `ST_GeometryType()` - returns the geometry type (e.g., ST_MultiPolygon)\n",
    "- `ST_SRID()` - returns the Spatial Reference System ID (should be 4326)\n",
    "- These functions prove our spatial data is properly stored and accessible\n",
    "\n",
    "**Success Criteria**:\n",
    "- ✅ Record count matches expected districts (should be 12 for Berlin)\n",
    "- ✅ Geometry type is MULTIPOLYGON \n",
    "- ✅ SRID is 4326 (WGS84)\n",
    "- ✅ No errors in spatial function calls\n",
    "\n",
    "**Why Verify**: Data can appear to import successfully but have hidden issues. Testing catches problems early!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7518cf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ **STEP 7F: VERIFY SUCCESS**\n",
      "=============================================\n",
      "5️⃣ Verifying results...\n",
      "   ✅ Total records: 12\n",
      "   📊 Sample spatial data:\n",
      "      🏢 12: Reinickendorf\n",
      "         📐 Type: ST_MultiPolygon, SRID: 4326\n",
      "      🏢 04: Charlottenburg-Wilmersdorf\n",
      "         📐 Type: ST_MultiPolygon, SRID: 4326\n",
      "      🏢 09: Treptow-Köpenick\n",
      "         📐 Type: ST_MultiPolygon, SRID: 4326\n",
      "\n",
      "🎉 **SUCCESS! Districts table created and populated!**\n",
      "=============================================\n",
      "✅ Schema: berlin_data\n",
      "✅ Table: districts_enhanced (12 records)\n",
      "✅ Geometry: MULTIPOLYGON with SRID 4326\n",
      "✅ Method: Direct SQL + ST_GeomFromText\n",
      "\n",
      "🖖 'Sometimes the direct path is the most logical!' - Spock\n"
     ]
    }
   ],
   "source": [
    "# ✅ **STEP 7F: VERIFY SUCCESS**\n",
    "# ===============================\n",
    "print(\"✅ **STEP 7F: VERIFY SUCCESS**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"5️⃣ Verifying results...\")\n",
    "    \n",
    "    # Count total records\n",
    "    count_result = conn.execute(text(\"\"\"\n",
    "        SELECT COUNT(*) FROM berlin_data.districts_enhanced\n",
    "    \"\"\"))\n",
    "    total_count = count_result.fetchone()[0]\n",
    "    \n",
    "    # Test spatial functionality\n",
    "    spatial_test = conn.execute(text(\"\"\"\n",
    "        SELECT district_id, district, \n",
    "               ST_GeometryType(geometry) as geom_type,\n",
    "               ST_SRID(geometry) as srid\n",
    "        FROM berlin_data.districts_enhanced \n",
    "        LIMIT 3\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(f\"   ✅ Total records: {total_count}\")\n",
    "    print(\"   📊 Sample spatial data:\")\n",
    "    for row in spatial_test.fetchall():\n",
    "        print(f\"      🏢 {row.district_id}: {row.district}\")\n",
    "        print(f\"         📐 Type: {row.geom_type}, SRID: {row.srid}\")\n",
    "    \n",
    "    print(\"\\n🎉 **SUCCESS! Districts table created and populated!**\")\n",
    "    print(\"=\" * 45)\n",
    "    print(\"✅ Schema: berlin_data\")\n",
    "    print(f\"✅ Table: districts_enhanced ({total_count} records)\")\n",
    "    print(\"✅ Geometry: MULTIPOLYGON with SRID 4326\")\n",
    "    print(\"✅ Method: Direct SQL + ST_GeomFromText\")\n",
    "    \n",
    "    print(\"\\n🖖 'Sometimes the direct path is the most logical!' - Spock\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Verification failed: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b879ab6",
   "metadata": {},
   "source": [
    "## ✅ **Step 8: Verify Success**\n",
    "\n",
    "**Learning Point**: Always verify your data was imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d66dd05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ **LEGACY CELL - FIXED VERSION**\n",
      "=============================================\n",
      "1️⃣ Fixing transaction state...\n",
      "   ✅ Transaction rolled back\n",
      "\n",
      "2️⃣ Clearing existing data...\n",
      "   ✅ Table cleared\n",
      "\n",
      "3️⃣ Inserting districts data...\n",
      "   ✅ Successfully inserted 12 districts!\n",
      "\n",
      "4️⃣ Final verification...\n",
      "   ✅ Total records: 12\n",
      "   📊 Sample spatial data:\n",
      "      🏢 12: Reinickendorf\n",
      "         📐 Type: ST_MultiPolygon, SRID: 4326\n",
      "      🏢 04: Charlottenburg-Wilmersdorf\n",
      "         📐 Type: ST_MultiPolygon, SRID: 4326\n",
      "      🏢 09: Treptow-Köpenick\n",
      "         📐 Type: ST_MultiPolygon, SRID: 4326\n",
      "\n",
      "🎉 **LEGACY CELL FIXED! 12 Berlin districts ready!**\n",
      "=============================================\n",
      "✅ Schema: berlin_data\n",
      "✅ Table: districts_enhanced\n",
      "✅ Column names: FIXED to match actual table structure\n",
      "✅ Spatial data: Working perfectly!\n",
      "\n",
      "🖖 'Logic and consistency restore order!' - Spock\n",
      "   ✅ Successfully inserted 12 districts!\n",
      "\n",
      "4️⃣ Final verification...\n",
      "   ✅ Total records: 12\n",
      "   📊 Sample spatial data:\n",
      "      🏢 12: Reinickendorf\n",
      "         📐 Type: ST_MultiPolygon, SRID: 4326\n",
      "      🏢 04: Charlottenburg-Wilmersdorf\n",
      "         📐 Type: ST_MultiPolygon, SRID: 4326\n",
      "      🏢 09: Treptow-Köpenick\n",
      "         📐 Type: ST_MultiPolygon, SRID: 4326\n",
      "\n",
      "🎉 **LEGACY CELL FIXED! 12 Berlin districts ready!**\n",
      "=============================================\n",
      "✅ Schema: berlin_data\n",
      "✅ Table: districts_enhanced\n",
      "✅ Column names: FIXED to match actual table structure\n",
      "✅ Spatial data: Working perfectly!\n",
      "\n",
      "🖖 'Logic and consistency restore order!' - Spock\n"
     ]
    }
   ],
   "source": [
    "# ✅ **LEGACY CELL - FIXED VERSION**\n",
    "print(\"✅ **LEGACY CELL - FIXED VERSION**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    # Fix the transaction state\n",
    "    print(\"1️⃣ Fixing transaction state...\")\n",
    "    conn.rollback()\n",
    "    print(\"   ✅ Transaction rolled back\")\n",
    "    \n",
    "    # Clear existing data\n",
    "    print(\"\\n2️⃣ Clearing existing data...\")\n",
    "    conn.execute(text(\"DELETE FROM berlin_data.districts_enhanced;\"))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Table cleared\")\n",
    "    \n",
    "    # Insert districts data (FIXED: using 'district' not 'district_name')\n",
    "    print(\"\\n3️⃣ Inserting districts data...\")\n",
    "    \n",
    "    inserted_count = 0\n",
    "    for idx, row in districts_gdf.iterrows():\n",
    "        insert_sql = text(\"\"\"\n",
    "            INSERT INTO berlin_data.districts_enhanced \n",
    "            (district_id, district, geometry) \n",
    "            VALUES (:district_id, :district, ST_GeomFromText(:wkt, 4326))\n",
    "        \"\"\")\n",
    "        \n",
    "        conn.execute(insert_sql, {\n",
    "            'district_id': row['district_id'],\n",
    "            'district': row['district'],\n",
    "            'wkt': row['geometry'].wkt\n",
    "        })\n",
    "        inserted_count += 1\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"   ✅ Successfully inserted {inserted_count} districts!\")\n",
    "    \n",
    "    # Verify final results (FIXED: using 'district' not 'district_name')\n",
    "    print(\"\\n4️⃣ Final verification...\")\n",
    "    \n",
    "    count_result = conn.execute(text(\"\"\"\n",
    "        SELECT COUNT(*) FROM berlin_data.districts_enhanced\n",
    "    \"\"\"))\n",
    "    total_count = count_result.fetchone()[0]\n",
    "    \n",
    "    # Test spatial functionality (FIXED: using 'district' not 'district_name')\n",
    "    spatial_test = conn.execute(text(\"\"\"\n",
    "        SELECT district_id, district, \n",
    "               ST_GeometryType(geometry) as geom_type,\n",
    "               ST_SRID(geometry) as srid\n",
    "        FROM berlin_data.districts_enhanced \n",
    "        LIMIT 3\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(f\"   ✅ Total records: {total_count}\")\n",
    "    print(\"   📊 Sample spatial data:\")\n",
    "    for row in spatial_test.fetchall():\n",
    "        print(f\"      🏢 {row.district_id}: {row.district}\")\n",
    "        print(f\"         📐 Type: {row.geom_type}, SRID: {row.srid}\")\n",
    "    \n",
    "    print(f\"\\n🎉 **LEGACY CELL FIXED! {total_count} Berlin districts ready!**\")\n",
    "    print(\"=\" * 45)\n",
    "    print(\"✅ Schema: berlin_data\")\n",
    "    print(\"✅ Table: districts_enhanced\")\n",
    "    print(\"✅ Column names: FIXED to match actual table structure\")\n",
    "    print(\"✅ Spatial data: Working perfectly!\")\n",
    "    \n",
    "    print(\"\\n🖖 'Logic and consistency restore order!' - Spock\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aee180",
   "metadata": {},
   "source": [
    "## 🎓 **Summary & Learning Outcomes**\n",
    "\n",
    "### ✅ **What We Accomplished:**\n",
    "1. **Database Connection**: Successfully connected to AWS RDS PostgreSQL\n",
    "2. **Schema Investigation**: Explored existing database structure\n",
    "3. **PostGIS Verification**: Confirmed spatial extension availability\n",
    "4. **GeoJSON Import**: Loaded enhanced districts data\n",
    "5. **Table Creation**: Created new districts table with PostGIS geometry\n",
    "6. **Data Validation**: Verified successful import\n",
    "\n",
    "### 📚 **Key Learning Points:**\n",
    "- **Connection Strings**: How to format and use database URLs\n",
    "- **Schema Management**: Importance of investigating existing structures\n",
    "- **Spatial Data**: Working with coordinate reference systems (CRS)\n",
    "- **PostGIS**: Using spatial database extensions\n",
    "- **Data Validation**: Always verify your imports!\n",
    "\n",
    "### 🚀 **Next Steps:**\n",
    "- Create neighborhoods table with district relationships\n",
    "- Add spatial indexes for performance\n",
    "- Implement data quality checks\n",
    "- Create spatial queries and analysis\n",
    "\n",
    "---\n",
    "\n",
    "**🖖 \"Logic is the beginning of wisdom, not the end.\" - Spock**\n",
    "\n",
    "*This notebook demonstrates systematic approach to spatial database operations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54aedbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 **SIMPLE TABLE CHECK**\n",
      "📊 Total records: 12\n",
      "📋 Columns: district_id, district, geometry\n",
      "✅ Quick check complete!\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Simple & Fast Check\n",
    "print(\"🚀 **SIMPLE TABLE CHECK**\")\n",
    "\n",
    "# Just check if table exists and count records\n",
    "simple_count = conn.execute(text(\"SELECT COUNT(*) FROM berlin_data.districts_enhanced;\"))\n",
    "count = simple_count.fetchone()[0]\n",
    "print(f\"📊 Total records: {count}\")\n",
    "\n",
    "# Show columns\n",
    "cols = conn.execute(text(\"\"\"\n",
    "    SELECT column_name FROM information_schema.columns \n",
    "    WHERE table_schema = 'berlin_data' AND table_name = 'districts_enhanced';\n",
    "\"\"\"))\n",
    "column_list = [col[0] for col in cols.fetchall()]\n",
    "print(f\"📋 Columns: {', '.join(column_list)}\")\n",
    "\n",
    "print(\"✅ Quick check complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0503cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>district</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Reinickendorf</td>\n",
       "      <td>0106000020E61000000100000001030000000100000084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04</td>\n",
       "      <td>Charlottenburg-Wilmersdorf</td>\n",
       "      <td>0106000020E6100000010000000103000000010000000D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09</td>\n",
       "      <td>Treptow-Köpenick</td>\n",
       "      <td>0106000020E610000001000000010300000001000000E9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>Pankow</td>\n",
       "      <td>0106000020E61000000400000001030000000100000012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08</td>\n",
       "      <td>Neukölln</td>\n",
       "      <td>0106000020E610000001000000010300000001000000BF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  district_id                    district  \\\n",
       "0          12               Reinickendorf   \n",
       "1          04  Charlottenburg-Wilmersdorf   \n",
       "2          09            Treptow-Köpenick   \n",
       "3          03                      Pankow   \n",
       "4          08                    Neukölln   \n",
       "\n",
       "                                            geometry  \n",
       "0  0106000020E61000000100000001030000000100000084...  \n",
       "1  0106000020E6100000010000000103000000010000000D...  \n",
       "2  0106000020E610000001000000010300000001000000E9...  \n",
       "3  0106000020E61000000400000001030000000100000012...  \n",
       "4  0106000020E610000001000000010300000001000000BF...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the first 5 rows from berlin_data.districts_enhanced\n",
    "result = conn.execute(text(\"SELECT * FROM berlin_data.districts_enhanced LIMIT 5;\"))\n",
    "rows = result.fetchall()\n",
    "\n",
    "# Display results as a pandas DataFrame for readability\n",
    "import pandas as pd\n",
    "df_preview = pd.DataFrame(rows, columns=result.keys())\n",
    "df_preview\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Webeet)",
   "language": "python",
   "name": "webeet-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
