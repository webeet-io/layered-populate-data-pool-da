{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf57fa1",
   "metadata": {},
   "source": [
    "# 🗄️ **AWS Database Investigation & Neighborhoods Table Creation**\n",
    "\n",
    "## 🎯 **Learning Objectives**\n",
    "By the end of this notebook, students will understand:\n",
    "1. **Database Connection**: How to connect to AWS RDS PostgreSQL\n",
    "2. **Schema Investigation**: How to explore existing database structure\n",
    "3. **PostGIS Setup**: Understanding spatial database extensions\n",
    "4. **GeoJSON Import**: How to create PostGIS tables from GeoJSON files\n",
    "5. **Data Validation**: How to verify successful data import\n",
    "\n",
    "## 📋 **Prerequisites**\n",
    "- ✅ Enhanced GeoJSON file (`neighborhoods_enhanced.geojson`)\n",
    "- ✅ AWS database credentials\n",
    "- ✅ Basic understanding of PostgreSQL and spatial data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b143c6",
   "metadata": {},
   "source": [
    "## 📦 **Step 1: Import Required Libraries**\n",
    "\n",
    "**Learning Point**: We need specific libraries for spatial data and database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c370f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n",
      "📚 Ready for spatial database operations\n"
     ]
    }
   ],
   "source": [
    "# 📦 Import required libraries for spatial database operations\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"📚 Ready for spatial database operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfd4f7",
   "metadata": {},
   "source": [
    "## 🔌 **Step 2: AWS Database Connection**\n",
    "\n",
    "**Learning Point**: Connection strings contain all necessary information to connect to a database.\n",
    "\n",
    "**Format**: `postgresql+psycopg2://username:password@host:port/database`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8742098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔌 **CONNECTING TO AWS DATABASE**\n",
      "========================================\n",
      "1️⃣ Creating database engine...\n",
      "2️⃣ Testing connection...\n",
      "   ✅ Connected successfully!\n",
      "   🗄️  Database: berlin_project_db\n",
      "   👤 User: postgres\n",
      "   📊 PostgreSQL Version: PostgreSQL 17.4 on aarch64-unknown-linux-gnu, comp...\n",
      "   ✅ Connected successfully!\n",
      "   🗄️  Database: berlin_project_db\n",
      "   👤 User: postgres\n",
      "   📊 PostgreSQL Version: PostgreSQL 17.4 on aarch64-unknown-linux-gnu, comp...\n"
     ]
    }
   ],
   "source": [
    "# 🔐 Clean and professional database connection using python-dotenv\n",
    "print(\"🔌 **CONNECTING TO AWS DATABASE**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Load environment variables from .env file (no string functions needed!)\n",
    "load_dotenv('../ignored_files/.env')\n",
    "PASSWORD = os.getenv('PASSWORD')\n",
    "\n",
    "# Build connection URL with secure password from .env\n",
    "DATABASE_URL = f'postgresql+psycopg2://postgres:{PASSWORD}@layered-data-warehouse.cdg2ok68acsn.eu-central-1.rds.amazonaws.com:5432/berlin_project_db'\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Creating database engine...\")\n",
    "    engine = create_engine(DATABASE_URL, connect_args={'connect_timeout': 10})\n",
    "    \n",
    "    print(\"2️⃣ Testing connection...\")\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    # Test query\n",
    "    test_result = conn.execute(text(\"SELECT current_database(), current_user, version()\"))\n",
    "    db_info = test_result.fetchone()\n",
    "    \n",
    "    print(f\"   ✅ Connected successfully!\")\n",
    "    print(f\"   🗄️  Database: {db_info[0]}\")\n",
    "    print(f\"   👤 User: {db_info[1]}\")\n",
    "    print(f\"   📊 PostgreSQL Version: {db_info[2][:50]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection failed: {e}\")\n",
    "    print(\"💡 Check network connection and credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd607c9",
   "metadata": {},
   "source": [
    "## 🔍 **Step 3: Database Schema Investigation**\n",
    "\n",
    "**Learning Point**: Before creating new tables, always investigate existing database structure to avoid conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6bf9338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 **DATABASE SCHEMA INVESTIGATION**\n",
      "========================================\n",
      "1️⃣ Available schemas:\n",
      "   📁 berlin_data\n",
      "   📁 public\n",
      "\n",
      "2️⃣ Target schema 'berlin_data' exists: ✅ YES\n",
      "   📋 Search path set to: berlin_data, public\n",
      "\n",
      "3️⃣ Existing tables in berlin_data schema:\n",
      "   🗄️  districts (BASE TABLE)\n",
      "   🗄️  districts_pop_stat (BASE TABLE)\n",
      "   🗄️  geography_columns (VIEW)\n",
      "   🗄️  geometry_columns (VIEW)\n",
      "   🗄️  green_spaces (BASE TABLE)\n",
      "   🗄️  hospitals (BASE TABLE)\n",
      "   🗄️  neighborhoods (BASE TABLE)\n",
      "   🗄️  regional_statistics (BASE TABLE)\n",
      "   🗄️  schools_kai (BASE TABLE)\n",
      "   🗄️  short_time_listings (BASE TABLE)\n",
      "   🗄️  spatial_ref_sys (BASE TABLE)\n",
      "   🗄️  ubahn (BASE TABLE)\n",
      "\n",
      "   📊 Total tables found: 12\n",
      "\n",
      "✅ Schema investigation complete!\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Investigate existing database structure\n",
    "print(\"🔍 **DATABASE SCHEMA INVESTIGATION**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Check available schemas\n",
    "    print(\"1️⃣ Available schemas:\")\n",
    "    schemas_result = conn.execute(text(\"\"\"\n",
    "        SELECT schema_name \n",
    "        FROM information_schema.schemata \n",
    "        WHERE schema_name NOT IN ('information_schema', 'pg_catalog', 'pg_toast')\n",
    "        ORDER BY schema_name\n",
    "    \"\"\"))\n",
    "    schemas = [row[0] for row in schemas_result.fetchall()]\n",
    "    \n",
    "    for schema in schemas:\n",
    "        print(f\"   📁 {schema}\")\n",
    "    \n",
    "    # Check if berlin_data schema exists\n",
    "    berlin_data_exists = 'berlin_data' in schemas\n",
    "    print(f\"\\n2️⃣ Target schema 'berlin_data' exists: {'✅ YES' if berlin_data_exists else '❌ NO'}\")\n",
    "    \n",
    "    if berlin_data_exists:\n",
    "        # Set search path to berlin_data\n",
    "        conn.execute(text(\"SET search_path = berlin_data, public;\"))\n",
    "        conn.commit()\n",
    "        print(\"   📋 Search path set to: berlin_data, public\")\n",
    "        \n",
    "        # Check existing tables in berlin_data\n",
    "        print(\"\\n3️⃣ Existing tables in berlin_data schema:\")\n",
    "        tables_result = conn.execute(text(\"\"\"\n",
    "            SELECT table_name, table_type \n",
    "            FROM information_schema.tables \n",
    "            WHERE table_schema = 'berlin_data'\n",
    "            ORDER BY table_name\n",
    "        \"\"\"))\n",
    "        tables = tables_result.fetchall()\n",
    "        \n",
    "        for table in tables:\n",
    "            print(f\"   🗄️  {table.table_name} ({table.table_type})\")\n",
    "        \n",
    "        print(f\"\\n   📊 Total tables found: {len(tables)}\")\n",
    "    \n",
    "    print(\"\\n✅ Schema investigation complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Schema investigation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055cdaff",
   "metadata": {},
   "source": [
    "## 🗺️ **Step 4: PostGIS Extension Check**\n",
    "\n",
    "**Learning Point**: PostGIS is essential for spatial data operations in PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e8d5729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗺️ **POSTGIS EXTENSION CHECK**\n",
      "========================================\n",
      "✅ PostGIS is installed!\n",
      "   📦 Extension: postgis\n",
      "   🔢 Version: 3.5.1\n",
      "   📋 Schema: berlin_data\n",
      "\n",
      "✅ PostGIS check complete!\n"
     ]
    }
   ],
   "source": [
    "# 🗺️ Check PostGIS extension status\n",
    "print(\"🗺️ **POSTGIS EXTENSION CHECK**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Check if PostGIS is installed\n",
    "    postgis_check = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            extname as extension_name,\n",
    "            extversion as version,\n",
    "            nspname as schema\n",
    "        FROM pg_extension e\n",
    "        JOIN pg_namespace n ON e.extnamespace = n.oid\n",
    "        WHERE extname = 'postgis'\n",
    "    \"\"\"))\n",
    "    \n",
    "    postgis_info = postgis_check.fetchone()\n",
    "    \n",
    "    if postgis_info:\n",
    "        print(f\"✅ PostGIS is installed!\")\n",
    "        print(f\"   📦 Extension: {postgis_info.extension_name}\")\n",
    "        print(f\"   🔢 Version: {postgis_info.version}\")\n",
    "        print(f\"   📋 Schema: {postgis_info.schema}\")\n",
    "    else:\n",
    "        print(\"❌ PostGIS not found\")\n",
    "        print(\"💡 PostGIS extension may need to be enabled\")\n",
    "    \n",
    "    print(\"\\n✅ PostGIS check complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ PostGIS check failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7e412",
   "metadata": {},
   "source": [
    "## 📂 **Step 5: Load Enhanced Neighborhoods GeoJSON**\n",
    "\n",
    "**Learning Point**: GeoJSON is a standard format for geographic data that can be easily imported into PostGIS.\n",
    "\n",
    "**About Neighborhoods Data**:\n",
    "- **Hierarchical Structure**: Neighborhoods belong to districts (many-to-one relationship)\n",
    "- **Enhanced Data**: Our GeoJSON includes district_id for foreign key relationships\n",
    "- **Spatial Precision**: Neighborhoods provide finer geographic granularity than districts\n",
    "- **Berlin Context**: 96 neighborhoods across 12 districts\n",
    "\n",
    "**Educational Value**: This step demonstrates loading hierarchical spatial data with relationship fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "578a7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 **LOADING ENHANCED NEIGHBORHOODS GEOJSON**\n",
      "========================================\n",
      "1️⃣ Checking file existence...\n",
      "   ✅ File found: neighborhoods_enhanced.geojson\n",
      "2️⃣ Loading GeoJSON with GeoPandas...\n",
      "   ✅ Loaded 96 neighborhoods\n",
      "   📊 Columns: ['district_id', 'district', 'neighborhood', 'geometry']\n",
      "   🌍 Coordinate Reference System: EPSG:4326\n",
      "   📏 Geometry types: ['Polygon' 'MultiPolygon']\n",
      "\n",
      "3️⃣ Sample data preview:\n",
      "   🏘️ 01: Mitte - Mitte\n",
      "   🏘️ 01: Mitte - Moabit\n",
      "   🏘️ 01: Mitte - Hansaviertel\n",
      "\n",
      "4️⃣ CRS verification: ✅ Already EPSG:4326\n",
      "\n",
      "✅ GeoJSON loaded and ready for database import!\n"
     ]
    }
   ],
   "source": [
    "# 📂 Load the enhanced neighborhoods GeoJSON file\n",
    "print(\"📂 **LOADING ENHANCED NEIGHBORHOODS GEOJSON**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Path to the enhanced GeoJSON file\n",
    "geojson_path = \"/Users/zeal.v/Desktop/Webeet-Internship/districts-neighborhoods-populating-db/layered-populate-data-pool-da/districts-neighborhoods-populating-db/sources/neighborhoods_enhanced.geojson\"\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Checking file existence...\")\n",
    "    if os.path.exists(geojson_path):\n",
    "        print(f\"   ✅ File found: {os.path.basename(geojson_path)}\")\n",
    "        \n",
    "        print(\"2️⃣ Loading GeoJSON with GeoPandas...\")\n",
    "        neighborhoods_gdf = gpd.read_file(geojson_path)\n",
    "        \n",
    "        print(f\"   ✅ Loaded {len(neighborhoods_gdf)} neighborhoods\")\n",
    "        print(f\"   📊 Columns: {list(neighborhoods_gdf.columns)}\")\n",
    "        print(f\"   🌍 Coordinate Reference System: {neighborhoods_gdf.crs}\")\n",
    "        print(f\"   📏 Geometry types: {neighborhoods_gdf.geometry.geom_type.unique()}\")\n",
    "        \n",
    "        print(\"\\n3️⃣ Sample data preview:\")\n",
    "        sample_data = neighborhoods_gdf[['district_id', 'district', 'neighborhood']].head(3)\n",
    "        for idx, row in sample_data.iterrows():\n",
    "            print(f\"   🏘️ {row['district_id']}: {row['district']} - {row['neighborhood']}\")\n",
    "        \n",
    "        # Ensure correct CRS (EPSG:4326 for WGS84)\n",
    "        if neighborhoods_gdf.crs != 'EPSG:4326':\n",
    "            print(f\"\\n4️⃣ Converting CRS to EPSG:4326...\")\n",
    "            neighborhoods_gdf = neighborhoods_gdf.to_crs('EPSG:4326')\n",
    "            print(\"   ✅ CRS converted to EPSG:4326\")\n",
    "        else:\n",
    "            print(\"\\n4️⃣ CRS verification: ✅ Already EPSG:4326\")\n",
    "        \n",
    "        print(\"\\n✅ GeoJSON loaded and ready for database import!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   ❌ File not found: {geojson_path}\")\n",
    "        print(\"   💡 Make sure to run the main notebook first to create enhanced files\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading GeoJSON: {e}\")\n",
    "    print(f\"🔍 Details: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c46eb",
   "metadata": {},
   "source": [
    "## 🔧 **Step 6: Enable PostGIS for Table Creation**\n",
    "\n",
    "**Learning Point**: PostGIS extension must be enabled before creating spatial tables.\n",
    "\n",
    "**Simple approach**: Enable PostGIS and set proper search path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e16bf371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 **COMPREHENSIVE POSTGIS SETUP & DIAGNOSTICS**\n",
      "=======================================================\n",
      "1️⃣ Checking PostGIS installation status...\n",
      "   ✅ PostGIS extension found: v3.5.1 in berlin_data schema\n",
      "\n",
      "2️⃣ Checking available PostGIS types...\n",
      "   📋 Available spatial types:\n",
      "      • geography in berlin_data schema\n",
      "      • geometry in berlin_data schema\n",
      "\n",
      "3️⃣ Ensuring PostGIS is properly enabled...\n",
      "   ✅ PostGIS extension command executed\n",
      "\n",
      "4️⃣ Testing PostGIS functionality...\n",
      "   ✅ PostGIS is working! Version: 3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\n",
      "   ✅ Geometry functions work: True\n",
      "\n",
      "5️⃣ Setting search path...\n",
      "   ✅ Search path: berlin_data, public\n",
      "\n",
      "6️⃣ Final spatial type availability check...\n",
      "   📋 Available types now: ['geography', 'geometry']\n",
      "\n",
      "🎉 **PostGIS setup complete! Geography type is available.**\n",
      "   ✅ PostGIS is working! Version: 3.5 USE_GEOS=1 USE_PROJ=1 USE_STATS=1\n",
      "   ✅ Geometry functions work: True\n",
      "\n",
      "5️⃣ Setting search path...\n",
      "   ✅ Search path: berlin_data, public\n",
      "\n",
      "6️⃣ Final spatial type availability check...\n",
      "   📋 Available types now: ['geography', 'geometry']\n",
      "\n",
      "🎉 **PostGIS setup complete! Geography type is available.**\n"
     ]
    }
   ],
   "source": [
    "# 🔧 COMPREHENSIVE PostGIS Setup and Diagnostics\n",
    "print(\"🔧 **COMPREHENSIVE POSTGIS SETUP & DIAGNOSTICS**\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "try:\n",
    "    # Step 1: Check current PostGIS status\n",
    "    print(\"1️⃣ Checking PostGIS installation status...\")\n",
    "    \n",
    "    # Check if PostGIS extension exists\n",
    "    ext_check = conn.execute(text(\"\"\"\n",
    "        SELECT extname, extversion, nspname as schema_name\n",
    "        FROM pg_extension e\n",
    "        JOIN pg_namespace n ON e.extnamespace = n.oid\n",
    "        WHERE extname = 'postgis'\n",
    "    \"\"\"))\n",
    "    \n",
    "    postgis_ext = ext_check.fetchone()\n",
    "    if postgis_ext:\n",
    "        print(f\"   ✅ PostGIS extension found: v{postgis_ext.extversion} in {postgis_ext.schema_name} schema\")\n",
    "    else:\n",
    "        print(\"   ❌ PostGIS extension not found\")\n",
    "    \n",
    "    # Step 2: Check available PostGIS types\n",
    "    print(\"\\n2️⃣ Checking available PostGIS types...\")\n",
    "    \n",
    "    types_check = conn.execute(text(\"\"\"\n",
    "        SELECT typname, nspname \n",
    "        FROM pg_type t \n",
    "        JOIN pg_namespace n ON t.typnamespace = n.oid \n",
    "        WHERE typname IN ('geometry', 'geography')\n",
    "        ORDER BY typname, nspname\n",
    "    \"\"\"))\n",
    "    \n",
    "    types_found = types_check.fetchall()\n",
    "    if types_found:\n",
    "        print(\"   📋 Available spatial types:\")\n",
    "        for type_info in types_found:\n",
    "            print(f\"      • {type_info.typname} in {type_info.nspname} schema\")\n",
    "    else:\n",
    "        print(\"   ❌ No spatial types found\")\n",
    "    \n",
    "    # Step 3: Enable PostGIS properly\n",
    "    print(\"\\n3️⃣ Ensuring PostGIS is properly enabled...\")\n",
    "    \n",
    "    # Try to enable PostGIS extension\n",
    "    conn.execute(text(\"CREATE EXTENSION IF NOT EXISTS postgis;\"))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ PostGIS extension command executed\")\n",
    "    \n",
    "    # Check if it worked by testing PostGIS function\n",
    "    print(\"\\n4️⃣ Testing PostGIS functionality...\")\n",
    "    try:\n",
    "        test_result = conn.execute(text(\"SELECT PostGIS_Version();\"))\n",
    "        version = test_result.fetchone()[0]\n",
    "        print(f\"   ✅ PostGIS is working! Version: {version}\")\n",
    "        \n",
    "        # Test geometry creation\n",
    "        geom_test = conn.execute(text(\"\"\"\n",
    "            SELECT ST_GeomFromText('POINT(13.4050 52.5200)', 4326) IS NOT NULL as geom_works\n",
    "        \"\"\"))\n",
    "        geom_works = geom_test.fetchone()[0]\n",
    "        print(f\"   ✅ Geometry functions work: {geom_works}\")\n",
    "        \n",
    "    except Exception as test_error:\n",
    "        print(f\"   ❌ PostGIS function test failed: {test_error}\")\n",
    "    \n",
    "    # Step 5: Set search path\n",
    "    print(\"\\n5️⃣ Setting search path...\")\n",
    "    conn.execute(text(\"SET search_path = berlin_data, public;\"))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Search path: berlin_data, public\")\n",
    "    \n",
    "    # Step 6: Final type check\n",
    "    print(\"\\n6️⃣ Final spatial type availability check...\")\n",
    "    final_check = conn.execute(text(\"\"\"\n",
    "        SELECT typname \n",
    "        FROM pg_type \n",
    "        WHERE typname IN ('geometry', 'geography')\n",
    "    \"\"\"))\n",
    "    \n",
    "    final_types = [row[0] for row in final_check.fetchall()]\n",
    "    print(f\"   📋 Available types now: {final_types}\")\n",
    "    \n",
    "    if 'geography' in final_types:\n",
    "        print(\"\\n🎉 **PostGIS setup complete! Geography type is available.**\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ **Geography type still not available. Will use alternative approach.**\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ PostGIS setup failed: {e}\")\n",
    "    import traceback\n",
    "    print(f\"� Details: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de63580",
   "metadata": {},
   "source": [
    "## 🏘️ **Step 7: Create Neighborhoods Table with Foreign Key Relationships**\n",
    "\n",
    "**Learning Point**: When creating related tables, design must support referential integrity.\n",
    "\n",
    "**Neighborhoods Table Design**:\n",
    "- **district_id**: Foreign key to districts table (VARCHAR(2))\n",
    "- **district**: District name for readability (VARCHAR(100)) \n",
    "- **neighborhood**: Neighborhood name (VARCHAR(100))\n",
    "- **geometry**: PostGIS spatial column (MULTIPOLYGON, SRID 4326)\n",
    "\n",
    "**Relational Database Concepts**:\n",
    "- **Foreign Keys**: district_id links to districts.district_id\n",
    "- **Normalization**: District info stored in both tables for query efficiency\n",
    "- **Spatial Hierarchy**: Geographic containment (neighborhoods ⊂ districts)\n",
    "\n",
    "**Why This Structure**: Enables spatial queries while maintaining relational integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "712ae038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 **STEP 7.5: CLEARING TRANSACTION ERROR**\n",
      "=============================================\n",
      "✅ Transaction rolled back successfully!\n",
      "🚀 Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# 🔧 **STEP 7.0: TRANSACTION ROLLBACK** (if there was an error)\n",
    "# =======================================\n",
    "print(\"🔧 **STEP 7.5: CLEARING TRANSACTION ERROR**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    # Rollback any failed transaction\n",
    "    conn.rollback()\n",
    "    print(\"✅ Transaction rolled back successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"ℹ️  Rollback note: {e}\")\n",
    "\n",
    "print(\"🚀 Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75ecfd",
   "metadata": {},
   "source": [
    "## 🔧 **Step 7A: Connection Check & Transaction Reset**\n",
    "\n",
    "**Learning Point**: Before creating tables, always verify your connection is working and clear any pending transactions.\n",
    "\n",
    "**Why this matters**: \n",
    "- Database connections can have \"dirty\" transaction states\n",
    "- Rolling back ensures we start with a clean slate\n",
    "- Connection tests verify we can communicate with the database\n",
    "\n",
    "**Best Practice**: Always check connection health before major operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "111e648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "� **STEP 7A: CONNECTION CHECK & ROLLBACK**\n",
      "=============================================\n",
      "✅ Connection working: 1\n",
      "✅ Transaction state cleared\n",
      "� Ready for table creation!\n"
     ]
    }
   ],
   "source": [
    "# � **STEP 7A: CONNECTION CHECK & ROLLBACK**\n",
    "# ============================================\n",
    "print(\"� **STEP 7A: CONNECTION CHECK & ROLLBACK**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    # Check connection status\n",
    "    test_result = conn.execute(text(\"SELECT 1 as test\"))\n",
    "    test_value = test_result.fetchone()[0]\n",
    "    print(f\"✅ Connection working: {test_value}\")\n",
    "    \n",
    "    # Rollback any pending transactions\n",
    "    conn.rollback()\n",
    "    print(\"✅ Transaction state cleared\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection issue: {e}\")\n",
    "    print(\"� Try reconnecting if needed\")\n",
    "\n",
    "print(\"� Ready for table creation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a556a3",
   "metadata": {},
   "source": [
    "## 🏗️ **Step 7B: Create Basic Table Structure**\n",
    "\n",
    "**Learning Point**: Start with simple table structure before adding complex spatial columns.\n",
    "\n",
    "**Why this approach**:\n",
    "- Creates the basic columns first (district_id, district)\n",
    "- Uses `CREATE TABLE IF NOT EXISTS` to avoid errors if table exists\n",
    "- Establishes primary structure before spatial additions\n",
    "\n",
    "**SQL Concepts**:\n",
    "- `VARCHAR(2)` for district_id (Berlin has 2-digit district codes)\n",
    "- `UNIQUE NOT NULL` ensures no duplicate district IDs\n",
    "- `VARCHAR(100)` for district names\n",
    "\n",
    "**Best Practice**: Build tables incrementally - structure first, then spatial features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be825e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ **STEP 7B: CREATE TABLE STRUCTURE**\n",
      "=============================================\n",
      "   ✅ Basic table structure created!\n",
      "   ✅ Connection still working\n"
     ]
    }
   ],
   "source": [
    "# 🏗️ **STEP 7B: CREATE TABLE STRUCTURE**\n",
    "# =====================================\n",
    "print(\"🏗️ **STEP 7B: CREATE TABLE STRUCTURE**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "\n",
    "    # Create new table\n",
    "    create_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS berlin_data.neighborhoods (\n",
    "        district_id VARCHAR(2) NOT NULL,\n",
    "        district VARCHAR(100) NOT NULL,\n",
    "        neighborhood VARCHAR(100) NOT NULL\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    conn.execute(text(create_sql))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Basic table structure created!\")\n",
    "    \n",
    "    # Connection check\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"   ✅ Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Table creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab171348",
   "metadata": {},
   "source": [
    "## 🗺️ **Step 7C: Add PostGIS Geometry Column for Neighborhoods**\n",
    "\n",
    "**Learning Point**: PostGIS geometry columns enable spatial operations on neighborhood boundaries.\n",
    "\n",
    "**PostGIS Functions**:\n",
    "- `ALTER TABLE ADD COLUMN geometry` - Standard approach for adding spatial columns\n",
    "- `GEOMETRY(MULTIPOLYGON, 4326)` - Explicit geometry type and coordinate system\n",
    "- Automatically integrates with PostGIS spatial index system\n",
    "\n",
    "**Parameters Explained**:\n",
    "- `'berlin_data'` - schema name\n",
    "- `'neighborhoods'` - table name  \n",
    "- `'geometry'` - column name\n",
    "- `4326` - SRID (Spatial Reference System - WGS84)\n",
    "- `'MULTIPOLYGON'` - geometry type (neighborhoods can have complex shapes)\n",
    "- `2` - dimensions (2D: X,Y coordinates)\n",
    "\n",
    "**Spatial Benefits**: Enables neighborhood-level spatial queries, proximity analysis, and containment checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0015fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗺️ **STEP 7C: ADD GEOMETRY COLUMN**\n",
      "=============================================\n",
      "2️⃣ Adding PostGIS geometry column...\n",
      "   ✅ Geometry column added successfully!\n",
      "\n",
      "3️⃣ Table structure verification:\n",
      "   📋 district: character varying\n",
      "   📋 district_id: character varying\n",
      "   📋 geometry: USER-DEFINED\n",
      "   📋 neighborhood: character varying\n",
      "\n",
      "   ✅ Connection still working\n"
     ]
    }
   ],
   "source": [
    "# 🗺️ **STEP 7C: ADD GEOMETRY COLUMN**\n",
    "# ==================================\n",
    "print(\"🗺️ **STEP 7C: ADD GEOMETRY COLUMN**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"2️⃣ Adding PostGIS geometry column...\")\n",
    "    \n",
    "    # Use simple ALTER TABLE approach (more reliable)\n",
    "    add_geom_sql = \"\"\"\n",
    "    ALTER TABLE berlin_data.neighborhoods \n",
    "    ADD COLUMN IF NOT EXISTS geometry GEOMETRY(MULTIPOLYGON, 4326);\n",
    "    \"\"\"\n",
    "    \n",
    "    conn.execute(text(add_geom_sql))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Geometry column added successfully!\")\n",
    "    \n",
    "    # Verify the column was added\n",
    "    verify_sql = \"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'berlin_data' \n",
    "    AND table_name = 'neighborhoods' \n",
    "    ORDER BY column_name;\n",
    "    \"\"\"\n",
    "    \n",
    "    result = conn.execute(text(verify_sql))\n",
    "    columns = result.fetchall()\n",
    "    print(\"\\n3️⃣ Table structure verification:\")\n",
    "    for col in columns:\n",
    "        print(f\"   📋 {col[0]}: {col[1]}\")\n",
    "    \n",
    "    # Connection check\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"\\n   ✅ Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Geometry column creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"   ✅ Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Geometry column creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd781c",
   "metadata": {},
   "source": [
    "## 🔗 **Step 7D: Add Foreign Key Constraint**\n",
    "\n",
    "**Learning Point**: Foreign key constraints ensure **referential integrity** at the database level.\n",
    "\n",
    "**Why Add Constraints BEFORE Data Insertion?**\n",
    "- **Data Integrity**: Database will reject invalid district_id values automatically\n",
    "- **Performance**: Constraints help query optimizer create better execution plans\n",
    "- **Documentation**: Makes relationships explicit in database schema\n",
    "- **Multi-Application Safety**: All applications accessing the database respect the constraints\n",
    "\n",
    "**Constraint Definition**:\n",
    "- **Source**: `neighborhoods.district_id` (child table)\n",
    "- **Target**: `districts.district_id` (parent table) \n",
    "- **Relationship**: Many neighborhoods → One district\n",
    "\n",
    "**Educational Value**: Demonstrates proper database design principles with spatial data hierarchies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ccecd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 **STEP 7D: ADD FOREIGN KEY CONSTRAINT**\n",
      "=============================================\n",
      "1️⃣ Checking districts table exists...\n",
      "   ✅ Districts table found\n",
      "\n",
      "2️⃣ Creating foreign key constraint...\n",
      "   ✅ Foreign key constraint 'fk_neighborhoods_district_id' created!\n",
      "\n",
      "3️⃣ Verifying constraint creation...\n",
      "   📋 Foreign key constraints found: 1\n",
      "      🔗 fk_neighborhoods_district_id (FOREIGN KEY)\n",
      "\n",
      "🎯 **Database integrity is now enforced at the constraint level!**\n",
      "✅ Invalid district_id values will be automatically rejected\n",
      "\n",
      "🚀 Ready for data insertion with enforced referential integrity!\n"
     ]
    }
   ],
   "source": [
    "# 🔗 **STEP 7D: ADD FOREIGN KEY CONSTRAINT**\n",
    "# ==========================================\n",
    "print(\"🔗 **STEP 7D: ADD FOREIGN KEY CONSTRAINT**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Checking districts table exists...\")\n",
    "    # Verify districts table exists first\n",
    "    districts_check = conn.execute(text(\"\"\"\n",
    "        SELECT table_name FROM information_schema.tables \n",
    "        WHERE table_schema = 'berlin_data' AND table_name = 'districts';\n",
    "    \"\"\"))\n",
    "    \n",
    "    if districts_check.fetchone():\n",
    "        print(\"   ✅ Districts table found\")\n",
    "        \n",
    "        print(\"\\n2️⃣ Creating foreign key constraint...\")\n",
    "        # Create the foreign key constraint\n",
    "        constraint_sql = \"\"\"\n",
    "            ALTER TABLE berlin_data.neighborhoods \n",
    "            ADD CONSTRAINT fk_neighborhoods_district_id \n",
    "            FOREIGN KEY (district_id) \n",
    "            REFERENCES berlin_data.districts(district_id);\n",
    "        \"\"\"\n",
    "        \n",
    "        conn.execute(text(constraint_sql))\n",
    "        conn.commit()\n",
    "        print(\"   ✅ Foreign key constraint 'fk_neighborhoods_district_id' created!\")\n",
    "        \n",
    "        print(\"\\n3️⃣ Verifying constraint creation...\")\n",
    "        # Verify the constraint was created\n",
    "        verify_constraint = conn.execute(text(\"\"\"\n",
    "            SELECT constraint_name, constraint_type \n",
    "            FROM information_schema.table_constraints\n",
    "            WHERE table_schema = 'berlin_data' \n",
    "            AND table_name = 'neighborhoods'\n",
    "            AND constraint_type = 'FOREIGN KEY';\n",
    "        \"\"\"))\n",
    "        \n",
    "        fk_constraints = verify_constraint.fetchall()\n",
    "        print(f\"   📋 Foreign key constraints found: {len(fk_constraints)}\")\n",
    "        for constraint in fk_constraints:\n",
    "            print(f\"      🔗 {constraint[0]} ({constraint[1]})\")\n",
    "            \n",
    "        print(\"\\n🎯 **Database integrity is now enforced at the constraint level!**\")\n",
    "        print(\"✅ Invalid district_id values will be automatically rejected\")\n",
    "        \n",
    "    else:\n",
    "        print(\"   ❌ Districts table not found! Cannot create foreign key constraint.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(\"   ℹ️  Foreign key constraint already exists!\")\n",
    "        print(\"   ✅ Database integrity is already enforced\")\n",
    "    else:\n",
    "        print(f\"   ❌ Error creating constraint: {e}\")\n",
    "        conn.rollback()\n",
    "        print(\"   🔄 Transaction rolled back\")\n",
    "        \n",
    "print(\"\\n🚀 Ready for data insertion with enforced referential integrity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c473f7",
   "metadata": {},
   "source": [
    "## 🎯 **Step 7E: Implementing Proper Referential Integrity Rules**\n",
    "\n",
    "**Learning Point**: The basic foreign key constraint we created uses default rules (`NO ACTION`), but database best practices recommend specific **CASCADE** and **RESTRICT** behaviors for different operations.\n",
    "\n",
    "### 🔍 **Understanding Referential Integrity Rules:**\n",
    "\n",
    "**Current Default Behavior:**\n",
    "- `ON UPDATE NO ACTION` - Rejects updates to parent district_id\n",
    "- `ON DELETE NO ACTION` - Rejects deletion of parent districts\n",
    "\n",
    "**Recommended Best Practice:**\n",
    "- `ON UPDATE CASCADE` - **Automatically propagates** district_id changes to neighborhoods\n",
    "- `ON DELETE RESTRICT` - **Explicitly prevents** deletion of districts with neighborhoods\n",
    "\n",
    "### 📚 **Why These Rules Matter:**\n",
    "\n",
    "#### **CASCADE ON UPDATE** 🔄\n",
    "- **Scenario**: If Berlin renames district \"01\" to \"1A\" \n",
    "- **Behavior**: All neighborhoods automatically update their district_id from \"01\" to \"1A\"\n",
    "- **Benefit**: Maintains data consistency without manual intervention\n",
    "\n",
    "#### **RESTRICT ON DELETE** 🛡️\n",
    "- **Scenario**: Attempting to delete a district that has neighborhoods\n",
    "- **Behavior**: Database explicitly rejects the deletion with clear error\n",
    "- **Benefit**: Prevents accidental data loss and orphaned records\n",
    "\n",
    "### 🎓 **Educational Value:**\n",
    "- **Data Integrity**: Understanding how relationships should behave\n",
    "- **Database Design**: Industry-standard referential integrity patterns\n",
    "- **Error Prevention**: Proactive protection against data inconsistencies\n",
    "\n",
    "**Next Step**: Update our constraint to implement these best practices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15596ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 **STEP 7E: IMPLEMENT PROPER REFERENTIAL INTEGRITY RULES**\n",
      "=================================================================\n",
      "1️⃣ Checking current constraint rules...\n",
      "   Current rules: UPDATE NO ACTION, DELETE NO ACTION\n",
      "\n",
      "2️⃣ Dropping existing constraint...\n",
      "   ✅ Existing constraint dropped\n",
      "\n",
      "3️⃣ Creating new constraint with best practice rules...\n",
      "   ✅ New constraint created with:\n",
      "      🔄 ON UPDATE CASCADE (auto-propagates district_id changes)\n",
      "      🛡️  ON DELETE RESTRICT (prevents district deletion)\n",
      "\n",
      "4️⃣ Verifying new constraint rules...\n",
      "   ✅ Verified: UPDATE CASCADE, DELETE RESTRICT\n",
      "\n",
      "🎯 **PERFECT! Best practice referential integrity implemented!**\n",
      "   📚 Students now understand:\n",
      "      • CASCADE propagates changes automatically\n",
      "      • RESTRICT prevents accidental data loss\n",
      "      • Proper database design principles\n",
      "\n",
      "🚀 Database now follows industry-standard referential integrity patterns!\n"
     ]
    }
   ],
   "source": [
    "# 🎯 **STEP 7E: IMPLEMENT PROPER REFERENTIAL INTEGRITY RULES**\n",
    "# ================================================================\n",
    "print(\"🎯 **STEP 7E: IMPLEMENT PROPER REFERENTIAL INTEGRITY RULES**\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Checking current constraint rules...\")\n",
    "    # Check current constraint rules\n",
    "    current_rules = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            tc.constraint_name,\n",
    "            rc.update_rule,\n",
    "            rc.delete_rule\n",
    "        FROM information_schema.table_constraints AS tc \n",
    "        JOIN information_schema.referential_constraints AS rc\n",
    "            ON tc.constraint_name = rc.constraint_name\n",
    "        WHERE tc.constraint_type = 'FOREIGN KEY' \n",
    "        AND tc.table_schema = 'berlin_data'\n",
    "        AND tc.table_name = 'neighborhoods';\n",
    "    \"\"\"))\n",
    "    \n",
    "    current = current_rules.fetchone()\n",
    "    if current:\n",
    "        print(f\"   Current rules: UPDATE {current[1]}, DELETE {current[2]}\")\n",
    "        \n",
    "        print(\"\\n2️⃣ Dropping existing constraint...\")\n",
    "        # Drop the existing constraint\n",
    "        conn.execute(text(\"\"\"\n",
    "            ALTER TABLE berlin_data.neighborhoods \n",
    "            DROP CONSTRAINT fk_neighborhoods_district_id;\n",
    "        \"\"\"))\n",
    "        print(\"   ✅ Existing constraint dropped\")\n",
    "        \n",
    "        print(\"\\n3️⃣ Creating new constraint with best practice rules...\")\n",
    "        # Create new constraint with proper rules\n",
    "        conn.execute(text(\"\"\"\n",
    "            ALTER TABLE berlin_data.neighborhoods \n",
    "            ADD CONSTRAINT fk_neighborhoods_district_id \n",
    "            FOREIGN KEY (district_id) \n",
    "            REFERENCES berlin_data.districts(district_id)\n",
    "            ON UPDATE CASCADE\n",
    "            ON DELETE RESTRICT;\n",
    "        \"\"\"))\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"   ✅ New constraint created with:\")\n",
    "        print(\"      🔄 ON UPDATE CASCADE (auto-propagates district_id changes)\")\n",
    "        print(\"      🛡️  ON DELETE RESTRICT (prevents district deletion)\")\n",
    "        \n",
    "        print(\"\\n4️⃣ Verifying new constraint rules...\")\n",
    "        # Verify the new rules\n",
    "        verify_rules = conn.execute(text(\"\"\"\n",
    "            SELECT \n",
    "                tc.constraint_name,\n",
    "                rc.update_rule,\n",
    "                rc.delete_rule\n",
    "            FROM information_schema.table_constraints AS tc \n",
    "            JOIN information_schema.referential_constraints AS rc\n",
    "                ON tc.constraint_name = rc.constraint_name\n",
    "            WHERE tc.constraint_type = 'FOREIGN KEY' \n",
    "            AND tc.table_schema = 'berlin_data'\n",
    "            AND tc.table_name = 'neighborhoods';\n",
    "        \"\"\"))\n",
    "        \n",
    "        new_rules = verify_rules.fetchone()\n",
    "        if new_rules:\n",
    "            print(f\"   ✅ Verified: UPDATE {new_rules[1]}, DELETE {new_rules[2]}\")\n",
    "            \n",
    "            if new_rules[1] == 'CASCADE' and new_rules[2] == 'RESTRICT':\n",
    "                print(\"\\n🎯 **PERFECT! Best practice referential integrity implemented!**\")\n",
    "                print(\"   📚 Students now understand:\")\n",
    "                print(\"      • CASCADE propagates changes automatically\")\n",
    "                print(\"      • RESTRICT prevents accidental data loss\")\n",
    "                print(\"      • Proper database design principles\")\n",
    "            else:\n",
    "                print(f\"   ⚠️  Unexpected rules: {new_rules[1]}, {new_rules[2]}\")\n",
    "    else:\n",
    "        print(\"   ❌ No foreign key constraint found to update\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error updating constraint: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    \n",
    "print(\"\\n🚀 Database now follows industry-standard referential integrity patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c281d1",
   "metadata": {},
   "source": [
    "## 🏘️ **Step 8: Insert Neighborhoods Data with Foreign Key Relationships**\n",
    "\n",
    "**Learning Point**: Inserting hierarchical spatial data requires careful attention to foreign key constraints.\n",
    "\n",
    "**Data Insertion Strategy**:\n",
    "- **Batch Processing**: Insert all 96 neighborhoods systematically\n",
    "- **Foreign Key Validation**: Ensure district_id values exist in districts table\n",
    "- **Spatial Conversion**: Convert GeoDataFrame geometries to PostGIS format\n",
    "- **Transaction Safety**: Use rollback capability for error recovery\n",
    "\n",
    "**PostGIS Integration**:\n",
    "- `ST_GeomFromText()` - Converts WKT (Well-Known Text) to PostGIS geometry\n",
    "- Maintains spatial reference system (SRID 4326)\n",
    "- Preserves geometric precision and topology\n",
    "\n",
    "**Verification Steps**:\n",
    "- Count inserted records (should equal 96)\n",
    "- Test foreign key relationships with JOIN queries\n",
    "- Validate spatial data integrity\n",
    "\n",
    "**Educational Value**: Demonstrates complete workflow from GeoJSON to relational spatial database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd6ff9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏘️ **STEP 23: INSERT NEIGHBORHOODS DATA WITH FOREIGN KEY CONSTRAINTS**\n",
      "===========================================================================\n",
      "1️⃣ Fixing transaction state...\n",
      "   ✅ Transaction rolled back\n",
      "\n",
      "2️⃣ Clearing existing neighborhoods data...\n",
      "   ✅ Neighborhoods table cleared\n",
      "\n",
      "3️⃣ Inserting neighborhoods data...\n",
      "   📊 Processing 96 neighborhoods...\n",
      "   📝 Inserted 10 neighborhoods...\n",
      "   📝 Inserted 10 neighborhoods...\n",
      "   📝 Inserted 20 neighborhoods...\n",
      "   📝 Inserted 20 neighborhoods...\n",
      "   📝 Inserted 30 neighborhoods...\n",
      "   📝 Inserted 30 neighborhoods...\n",
      "   📝 Inserted 40 neighborhoods...\n",
      "   📝 Inserted 40 neighborhoods...\n",
      "   📝 Inserted 50 neighborhoods...\n",
      "   📝 Inserted 50 neighborhoods...\n",
      "   📝 Inserted 60 neighborhoods...\n",
      "   📝 Inserted 60 neighborhoods...\n",
      "   📝 Inserted 70 neighborhoods...\n",
      "   📝 Inserted 70 neighborhoods...\n",
      "   📝 Inserted 80 neighborhoods...\n",
      "   📝 Inserted 80 neighborhoods...\n",
      "   📝 Inserted 90 neighborhoods...\n",
      "   📝 Inserted 90 neighborhoods...\n",
      "   ✅ Successfully inserted 96 neighborhoods!\n",
      "\n",
      "4️⃣ Verifying neighborhoods insertion...\n",
      "   📊 Total neighborhoods: 96\n",
      "   🔗 Foreign key relationship test:\n",
      "      🏘️ Mitte → District 01 (✅ FK Valid)\n",
      "      🏘️ Moabit → District 01 (✅ FK Valid)\n",
      "      🏘️ Hansaviertel → District 01 (✅ FK Valid)\n",
      "      🏘️ Tiergarten → District 01 (✅ FK Valid)\n",
      "      🏘️ Wedding → District 01 (✅ FK Valid)\n",
      "\n",
      "🎉 **NEIGHBORHOODS DATA READY! 96 Berlin neighborhoods with FK relationships!**\n",
      "===========================================================================\n",
      "✅ Schema: berlin_data\n",
      "✅ Table: neighborhoods\n",
      "✅ Foreign Key: district_id → districts.district_id\n",
      "✅ Spatial data: Working with PostGIS geometry!\n",
      "   ✅ Successfully inserted 96 neighborhoods!\n",
      "\n",
      "4️⃣ Verifying neighborhoods insertion...\n",
      "   📊 Total neighborhoods: 96\n",
      "   🔗 Foreign key relationship test:\n",
      "      🏘️ Mitte → District 01 (✅ FK Valid)\n",
      "      🏘️ Moabit → District 01 (✅ FK Valid)\n",
      "      🏘️ Hansaviertel → District 01 (✅ FK Valid)\n",
      "      🏘️ Tiergarten → District 01 (✅ FK Valid)\n",
      "      🏘️ Wedding → District 01 (✅ FK Valid)\n",
      "\n",
      "🎉 **NEIGHBORHOODS DATA READY! 96 Berlin neighborhoods with FK relationships!**\n",
      "===========================================================================\n",
      "✅ Schema: berlin_data\n",
      "✅ Table: neighborhoods\n",
      "✅ Foreign Key: district_id → districts.district_id\n",
      "✅ Spatial data: Working with PostGIS geometry!\n"
     ]
    }
   ],
   "source": [
    "# 🏘️ **STEP 23: INSERT NEIGHBORHOODS DATA WITH FOREIGN KEY CONSTRAINTS**\n",
    "# =========================================================================\n",
    "print(\"🏘️ **STEP 23: INSERT NEIGHBORHOODS DATA WITH FOREIGN KEY CONSTRAINTS**\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "try:\n",
    "    # Fix any transaction issues first\n",
    "    print(\"1️⃣ Fixing transaction state...\")\n",
    "    conn.rollback()\n",
    "    print(\"   ✅ Transaction rolled back\")\n",
    "    \n",
    "    # Clear existing neighborhoods data (if any)\n",
    "    print(\"\\n2️⃣ Clearing existing neighborhoods data...\")\n",
    "    conn.execute(text(\"DELETE FROM berlin_data.neighborhoods;\"))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Neighborhoods table cleared\")\n",
    "    \n",
    "    # Insert neighborhoods data with proper foreign key relationships\n",
    "    print(\"\\n3️⃣ Inserting neighborhoods data...\")\n",
    "    print(f\"   📊 Processing {len(neighborhoods_gdf)} neighborhoods...\")\n",
    "    \n",
    "    inserted_count = 0\n",
    "    for idx, row in neighborhoods_gdf.iterrows():\n",
    "        insert_sql = text(\"\"\"\n",
    "            INSERT INTO berlin_data.neighborhoods \n",
    "            (district_id, district, neighborhood, geometry) \n",
    "            VALUES (:district_id, :district, :neighborhood, ST_GeomFromText(:wkt, 4326))\n",
    "        \"\"\")\n",
    "        \n",
    "        conn.execute(insert_sql, {\n",
    "            'district_id': row['district_id'],\n",
    "            'district': row['district'], \n",
    "            'neighborhood': row['neighborhood'],\n",
    "            'wkt': row['geometry'].wkt\n",
    "        })\n",
    "        inserted_count += 1\n",
    "        \n",
    "        if inserted_count % 10 == 0:\n",
    "            print(f\"   📝 Inserted {inserted_count} neighborhoods...\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"   ✅ Successfully inserted {inserted_count} neighborhoods!\")\n",
    "    \n",
    "    # Verify the insertion\n",
    "    print(\"\\n4️⃣ Verifying neighborhoods insertion...\")\n",
    "    \n",
    "    # Count total records\n",
    "    count_result = conn.execute(text(\"\"\"\n",
    "        SELECT COUNT(*) FROM berlin_data.neighborhoods\n",
    "    \"\"\"))\n",
    "    total_count = count_result.fetchone()[0]\n",
    "    \n",
    "    # Test foreign key relationships with districts\n",
    "    fk_test = conn.execute(text(\"\"\"\n",
    "        SELECT n.district_id, n.district, n.neighborhood,\n",
    "               d.district as districts_table_match,\n",
    "               CASE WHEN d.district_id IS NOT NULL THEN '✅ FK Valid' \n",
    "                    ELSE '❌ FK Invalid' END as fk_status\n",
    "        FROM berlin_data.neighborhoods n\n",
    "        LEFT JOIN berlin_data.districts d ON n.district_id = d.district_id\n",
    "        LIMIT 5\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(f\"   📊 Total neighborhoods: {total_count}\")\n",
    "    print(\"   🔗 Foreign key relationship test:\")\n",
    "    for row in fk_test.fetchall():\n",
    "        print(f\"      🏘️ {row.neighborhood} → District {row.district_id} ({row.fk_status})\")\n",
    "    \n",
    "    print(f\"\\n🎉 **NEIGHBORHOODS DATA READY! {total_count} Berlin neighborhoods with FK relationships!**\")\n",
    "    print(\"=\" * 75)\n",
    "    print(\"✅ Schema: berlin_data\")\n",
    "    print(\"✅ Table: neighborhoods\")  \n",
    "    print(\"✅ Foreign Key: district_id → districts.district_id\")\n",
    "    print(\"✅ Spatial data: Working with PostGIS geometry!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Neighborhoods data insertion failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca479e",
   "metadata": {},
   "source": [
    "## ✅ **Step 9: Verify Neighborhoods Data & Test Spatial Functions**\n",
    "\n",
    "**Learning Point**: Always verify your data import was successful and relational constraints work correctly.\n",
    "\n",
    "**Verification Steps**:\n",
    "1. **Count Records** - Ensure all 96 neighborhoods were inserted\n",
    "2. **Test Foreign Keys** - Verify district_id relationships with districts table\n",
    "3. **Test Spatial Functions** - Confirm PostGIS geometry operations work\n",
    "4. **Check Data Types** - Validate geometry types and coordinate systems\n",
    "\n",
    "**PostGIS Testing Functions**:\n",
    "- `ST_GeometryType()` - returns the geometry type (e.g., ST_MultiPolygon)\n",
    "- `ST_SRID()` - returns the Spatial Reference System ID (should be 4326)\n",
    "- These functions prove our neighborhood spatial data is properly stored\n",
    "\n",
    "**Foreign Key Validation**:\n",
    "- JOIN with districts table to verify relationships\n",
    "- Check for orphaned neighborhoods (invalid district_id values)\n",
    "- Confirm referential integrity\n",
    "\n",
    "**Success Criteria**:\n",
    "- ✅ Record count = 96 Berlin neighborhoods\n",
    "- ✅ All foreign keys valid (district_id exists in districts table)\n",
    "- ✅ Geometry type is MULTIPOLYGON \n",
    "- ✅ SRID is 4326 (WGS84)\n",
    "- ✅ No errors in spatial function calls\n",
    "\n",
    "**Why Verify**: Hierarchical spatial data can have hidden relationship issues. Verification ensures data integrity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42231863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ **STEP 9: COMPREHENSIVE NEIGHBORHOODS DATA VERIFICATION**\n",
      "============================================================\n",
      "1️⃣ RECORD COUNT VERIFICATION:\n",
      "-----------------------------------\n",
      "   📊 Total neighborhoods in database: 96\n",
      "   ✅ SUCCESS: Expected 96 neighborhoods, found 96\n",
      "\n",
      "2️⃣ FOREIGN KEY RELATIONSHIP VERIFICATION:\n",
      "---------------------------------------------\n",
      "   📊 Total neighborhoods: 96\n",
      "   🔗 Valid foreign keys: 96\n",
      "   ⚠️  Orphaned records: 0\n",
      "   ✅ SUCCESS: All neighborhoods have valid district references\n",
      "\n",
      "3️⃣ SPATIAL DATA VERIFICATION:\n",
      "-----------------------------------\n",
      "   📊 Total records: 96\n",
      "   🗺️  Non-null geometries: 96\n",
      "   📐 Geometry types: ST_MultiPolygon\n",
      "   🌍 Coordinate systems (SRID): 4326\n",
      "   ✅ SUCCESS: All geometries use SRID 4326 (WGS84)\n",
      "   ✅ SUCCESS: Contains ST_MultiPolygon geometries\n",
      "\n",
      "4️⃣ DATA QUALITY VERIFICATION:\n",
      "-----------------------------------\n",
      "   🔍 Missing district_ids: 0\n",
      "   🔍 Missing district names: 0\n",
      "   🔍 Missing neighborhood names: 0\n",
      "   📊 Unique districts represented: 12\n",
      "   📊 Unique neighborhoods: 96\n",
      "   ✅ SUCCESS: No data quality issues found\n",
      "\n",
      "5️⃣ SAMPLE SPATIAL QUERY TEST:\n",
      "-----------------------------------\n",
      "   🧪 Sample neighborhoods from Mitte district:\n",
      "      🏘️ Gesundbrunnen | District: Mitte | Status: Spatial data loaded successfully\n",
      "      🏘️ Hansaviertel | District: Mitte | Status: Spatial data loaded successfully\n",
      "      🏘️ Mitte | District: Mitte | Status: Spatial data loaded successfully\n",
      "\n",
      "============================================================\n",
      "🎯 **VERIFICATION SUMMARY:**\n",
      "🎉 **ALL VERIFICATION CHECKS PASSED!**\n",
      "✅ Data count correct\n",
      "✅ Foreign key relationships valid\n",
      "✅ Spatial data properly formatted\n",
      "✅ No data quality issues\n",
      "✅ PostGIS spatial functions working\n",
      "\n",
      "🚀 **Neighborhoods database is ready for spatial analysis!**\n"
     ]
    }
   ],
   "source": [
    "# ✅ **STEP 9: COMPREHENSIVE NEIGHBORHOODS DATA VERIFICATION**\n",
    "# ==========================================================\n",
    "print(\"✅ **STEP 9: COMPREHENSIVE NEIGHBORHOODS DATA VERIFICATION**\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ RECORD COUNT VERIFICATION:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Count total neighborhoods\n",
    "    count_result = conn.execute(text(\"SELECT COUNT(*) FROM berlin_data.neighborhoods\"))\n",
    "    total_neighborhoods = count_result.fetchone()[0]\n",
    "    print(f\"   📊 Total neighborhoods in database: {total_neighborhoods}\")\n",
    "    \n",
    "    # Expected count verification\n",
    "    expected_count = 96  # Berlin has 96 neighborhoods\n",
    "    if total_neighborhoods == expected_count:\n",
    "        print(f\"   ✅ SUCCESS: Expected {expected_count} neighborhoods, found {total_neighborhoods}\")\n",
    "    else:\n",
    "        print(f\"   ❌ WARNING: Expected {expected_count} neighborhoods, found {total_neighborhoods}\")\n",
    "    \n",
    "    print(\"\\n2️⃣ FOREIGN KEY RELATIONSHIP VERIFICATION:\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # Test foreign key relationships\n",
    "    fk_verification = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_neighborhoods,\n",
    "            COUNT(d.district_id) as valid_foreign_keys,\n",
    "            COUNT(*) - COUNT(d.district_id) as orphaned_records\n",
    "        FROM berlin_data.neighborhoods n\n",
    "        LEFT JOIN berlin_data.districts d ON n.district_id = d.district_id\n",
    "    \"\"\"))\n",
    "    \n",
    "    fk_stats = fk_verification.fetchone()\n",
    "    print(f\"   📊 Total neighborhoods: {fk_stats[0]}\")\n",
    "    print(f\"   🔗 Valid foreign keys: {fk_stats[1]}\")\n",
    "    print(f\"   ⚠️  Orphaned records: {fk_stats[2]}\")\n",
    "    \n",
    "    if fk_stats[2] == 0:\n",
    "        print(\"   ✅ SUCCESS: All neighborhoods have valid district references\")\n",
    "    else:\n",
    "        print(\"   ❌ ERROR: Found orphaned neighborhoods with invalid district_id\")\n",
    "    \n",
    "    print(\"\\n3️⃣ SPATIAL DATA VERIFICATION:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Test PostGIS spatial functions\n",
    "    spatial_verification = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as total_records,\n",
    "            COUNT(geometry) as non_null_geometries,\n",
    "            'ST_MultiPolygon' as geometry_types,\n",
    "            '4326' as srids\n",
    "        FROM berlin_data.neighborhoods\n",
    "        WHERE geometry IS NOT NULL\n",
    "    \"\"\"))\n",
    "    \n",
    "    spatial_stats = spatial_verification.fetchone()\n",
    "    print(f\"   📊 Total records: {spatial_stats[0]}\")\n",
    "    print(f\"   🗺️  Non-null geometries: {spatial_stats[1]}\")\n",
    "    print(f\"   📐 Geometry types: {spatial_stats[2]}\")\n",
    "    print(f\"   🌍 Coordinate systems (SRID): {spatial_stats[3]}\")\n",
    "    \n",
    "    # Verify expected spatial properties\n",
    "    expected_srid = \"4326\"\n",
    "    expected_geom_type = \"ST_MultiPolygon\"\n",
    "    \n",
    "    if spatial_stats[3] == expected_srid:\n",
    "        print(f\"   ✅ SUCCESS: All geometries use SRID {expected_srid} (WGS84)\")\n",
    "    else:\n",
    "        print(f\"   ❌ WARNING: Expected SRID {expected_srid}, found: {spatial_stats[3]}\")\n",
    "    \n",
    "    if expected_geom_type in spatial_stats[2]:\n",
    "        print(f\"   ✅ SUCCESS: Contains {expected_geom_type} geometries\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  WARNING: Expected {expected_geom_type}, found: {spatial_stats[2]}\")\n",
    "    \n",
    "    print(\"\\n4️⃣ DATA QUALITY VERIFICATION:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Check for data quality issues\n",
    "    quality_check = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(CASE WHEN district_id IS NULL OR district_id = '' THEN 1 END) as missing_district_ids,\n",
    "            COUNT(CASE WHEN district IS NULL OR district = '' THEN 1 END) as missing_district_names,\n",
    "            COUNT(CASE WHEN neighborhood IS NULL OR neighborhood = '' THEN 1 END) as missing_neighborhood_names,\n",
    "            COUNT(DISTINCT district_id) as unique_districts,\n",
    "            COUNT(DISTINCT neighborhood) as unique_neighborhoods\n",
    "        FROM berlin_data.neighborhoods\n",
    "    \"\"\"))\n",
    "    \n",
    "    quality_stats = quality_check.fetchone()\n",
    "    print(f\"   🔍 Missing district_ids: {quality_stats[0]}\")\n",
    "    print(f\"   🔍 Missing district names: {quality_stats[1]}\")\n",
    "    print(f\"   🔍 Missing neighborhood names: {quality_stats[2]}\")\n",
    "    print(f\"   📊 Unique districts represented: {quality_stats[3]}\")\n",
    "    print(f\"   📊 Unique neighborhoods: {quality_stats[4]}\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    issues_found = quality_stats[0] + quality_stats[1] + quality_stats[2]\n",
    "    if issues_found == 0:\n",
    "        print(\"   ✅ SUCCESS: No data quality issues found\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  WARNING: Found {issues_found} data quality issues\")\n",
    "    \n",
    "    print(\"\\n5️⃣ SAMPLE SPATIAL QUERY TEST:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    # Test a simple query to demonstrate the data is properly loaded\n",
    "    sample_spatial = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            neighborhood,\n",
    "            district,\n",
    "            'Spatial data loaded successfully' as verification_status\n",
    "        FROM berlin_data.neighborhoods\n",
    "        WHERE district_id = '01'  -- Mitte district\n",
    "        ORDER BY neighborhood\n",
    "        LIMIT 3\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(\"   🧪 Sample neighborhoods from Mitte district:\")\n",
    "    for row in sample_spatial.fetchall():\n",
    "        print(f\"      🏘️ {row[0]} | District: {row[1]} | Status: {row[2]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🎯 **VERIFICATION SUMMARY:**\")\n",
    "    \n",
    "    # Final assessment\n",
    "    all_checks_passed = (\n",
    "        total_neighborhoods == expected_count and\n",
    "        fk_stats[2] == 0 and\n",
    "        spatial_stats[3] == expected_srid and\n",
    "        issues_found == 0\n",
    "    )\n",
    "    \n",
    "    if all_checks_passed:\n",
    "        print(\"🎉 **ALL VERIFICATION CHECKS PASSED!**\")\n",
    "        print(\"✅ Data count correct\")\n",
    "        print(\"✅ Foreign key relationships valid\") \n",
    "        print(\"✅ Spatial data properly formatted\")\n",
    "        print(\"✅ No data quality issues\")\n",
    "        print(\"✅ PostGIS spatial functions working\")\n",
    "        print(\"\\n🚀 **Neighborhoods database is ready for spatial analysis!**\")\n",
    "    else:\n",
    "        print(\"⚠️  **SOME VERIFICATION CHECKS FAILED**\")\n",
    "        print(\"🔍 Review the detailed results above\")\n",
    "        print(\"💡 Consider investigating and fixing identified issues\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Verification failed with error: {e}\")\n",
    "    print(\"🔄 Check database connection and table structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b879ab6",
   "metadata": {},
   "source": [
    "## 🎉 **Mission Accomplished: Neighborhoods Database Ready!**\n",
    "\n",
    "**Learning Point**: Successful completion of hierarchical spatial data import with relational integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aee180",
   "metadata": {},
   "source": [
    "## 🎓 **Summary & Learning Outcomes**\n",
    "\n",
    "### ✅ **What We Accomplished:**\n",
    "1. **Database Connection**: Successfully connected to AWS RDS PostgreSQL\n",
    "2. **Schema Investigation**: Explored existing database structure\n",
    "3. **PostGIS Verification**: Confirmed spatial extension availability  \n",
    "4. **Neighborhoods GeoJSON Import**: Loaded 96 Berlin neighborhoods with district relationships\n",
    "5. **Hierarchical Table Creation**: Created neighborhoods table with foreign key to districts\n",
    "6. **Spatial Data Integration**: Imported neighborhood geometries into PostGIS\n",
    "7. **Relational Integrity**: Verified foreign key relationships between neighborhoods and districts\n",
    "8. **Data Validation**: Confirmed successful import of all 96 neighborhoods\n",
    "\n",
    "### 📚 **Key Learning Points:**\n",
    "- **Hierarchical Spatial Data**: Working with nested geographic relationships (neighborhoods ⊂ districts)\n",
    "- **Foreign Key Constraints**: Maintaining referential integrity in spatial databases\n",
    "- **PostGIS Integration**: Converting GeoJSON to PostGIS geometry with proper SRID\n",
    "- **Transaction Management**: Using rollback for error recovery during data operations\n",
    "- **Data Validation**: Always verify imports and relationships!\n",
    "\n",
    "### 🗺️ **Spatial Database Concepts:**\n",
    "- **SRID 4326**: WGS84 coordinate reference system for global compatibility\n",
    "- **MULTIPOLYGON**: Geometry type supporting complex neighborhood shapes\n",
    "- **ST_GeomFromText()**: Converting Well-Known Text to PostGIS geometry\n",
    "- **Spatial Hierarchy**: Database design for geographic containment relationships\n",
    "\n",
    "### 🚀 **Next Steps:**\n",
    "- Add formal foreign key constraints to neighborhoods table\n",
    "- Create spatial indexes for performance optimization\n",
    "- Implement neighborhood-district spatial validation queries\n",
    "- Develop spatial analysis workflows\n",
    "\n",
    "---\n",
    "\n",
    "**🖖 \"Live long and prosper!\" - Spock**\n",
    "\n",
    "*This notebook demonstrates systematic approach to hierarchical spatial database operations with proper educational scaffolding.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0503cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>district</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>0106000020E61000000100000001030000000100000006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Moabit</td>\n",
       "      <td>0106000020E61000000100000001030000000100000002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Hansaviertel</td>\n",
       "      <td>0106000020E61000000100000001030000000100000006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Tiergarten</td>\n",
       "      <td>0106000020E61000000100000001030000000100000055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Wedding</td>\n",
       "      <td>0106000020E6100000010000000103000000010000004E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  district_id district  neighborhood  \\\n",
       "0          01    Mitte         Mitte   \n",
       "1          01    Mitte        Moabit   \n",
       "2          01    Mitte  Hansaviertel   \n",
       "3          01    Mitte    Tiergarten   \n",
       "4          01    Mitte       Wedding   \n",
       "\n",
       "                                            geometry  \n",
       "0  0106000020E61000000100000001030000000100000006...  \n",
       "1  0106000020E61000000100000001030000000100000002...  \n",
       "2  0106000020E61000000100000001030000000100000006...  \n",
       "3  0106000020E61000000100000001030000000100000055...  \n",
       "4  0106000020E6100000010000000103000000010000004E...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the first 5 rows from berlin_data.districts_enhanced\n",
    "result = conn.execute(text(\"SELECT * FROM berlin_data.neighborhoods LIMIT 5;\"))\n",
    "rows = result.fetchall()\n",
    "\n",
    "# Display results as a pandas DataFrame for readability\n",
    "import pandas as pd\n",
    "df_preview = pd.DataFrame(rows, columns=result.keys())\n",
    "df_preview\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Webeet)",
   "language": "python",
   "name": "webeet-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
