{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a51fdb",
   "metadata": {},
   "source": [
    "## Cleaning & parsing\n",
    "    * Cleans data from berlin_venues_raw created by the venues_craper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c00eaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a784169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded variable 'df' from URI\n",
    "\n",
    "df = pd.read_csv(r'/Users/giovanigoltara/Documents/webeet/layered-populate-data-pool-da/venues/sources/berlin_venues_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab3cde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing data in columns: 'name', 'district'\n",
    "df = df.dropna(subset=['name', 'district'])\n",
    "\n",
    "# Drop duplicate rows across all columns\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39bb2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Hours parser code\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "DAY_ORDER = [\"Mo\", \"Tu\", \"We\", \"Th\", \"Fr\", \"Sa\", \"Su\"]\n",
    "\n",
    "def _normalize_day_text(s: str) -> str:\n",
    "    t = (s or \"\").strip()\n",
    "    t = t.replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"−\", \"-\").replace(\" to \", \"-\")\n",
    "    low = t.lower()\n",
    "    repl = [\n",
    "        (r'\\bpublic\\s*holidays?\\b', 'PH'), (r'\\bph\\b', 'PH'),\n",
    "        (r'\\bmonday\\b', 'Mo'), (r'\\bmon\\b', 'Mo'), (r'\\bmo\\b', 'Mo'),\n",
    "        (r'\\btuesday\\b', 'Tu'), (r'\\btues\\b', 'Tu'), (r'\\btue\\b', 'Tu'), (r'\\btu\\b', 'Tu'),\n",
    "        (r'\\bwednesday\\b', 'We'), (r'\\bweds\\b', 'We'), (r'\\bwed\\b', 'We'), (r'\\bwe\\b', 'We'),\n",
    "        (r'\\bthursday\\b', 'Th'), (r'\\bthurs\\b', 'Th'), (r'\\bthur\\b', 'Th'), (r'\\bthu\\b', 'Th'),\n",
    "        (r'\\bfriday\\b', 'Fr'), (r'\\bfri\\b', 'Fr'), (r'\\bfr\\b', 'Fr'),\n",
    "        (r'\\bsaturday\\b', 'Sa'), (r'\\bsat\\b', 'Sa'), (r'\\bsa\\b', 'Sa'),\n",
    "        (r'\\bsunday\\b', 'Su'), (r'\\bsun\\b', 'Su'), (r'\\bsu\\b', 'Su'),\n",
    "    ]\n",
    "    for pat, rep in repl:\n",
    "        low = re.sub(pat, rep, low)\n",
    "    return re.sub(r'\\s+', ' ', low).strip()\n",
    "\n",
    "def _expand_days_token(tok: str):\n",
    "    tok = tok.strip()\n",
    "    if not tok: return []\n",
    "    if tok == \"PH\": return [\"PH\"]\n",
    "    if \"-\" in tok:\n",
    "        a, b = [x.strip() for x in tok.split(\"-\", 1)]\n",
    "        if a in DAY_ORDER and b in DAY_ORDER:\n",
    "            ai, bi = DAY_ORDER.index(a), DAY_ORDER.index(b)\n",
    "            return DAY_ORDER[ai:bi+1] if ai <= bi else DAY_ORDER[ai:] + DAY_ORDER[:bi+1]\n",
    "        return []\n",
    "    return [tok] if tok in DAY_ORDER else []\n",
    "\n",
    "def _parse_time_value(t: str) -> str:\n",
    "    t = t.strip()\n",
    "    if t.lower() in {\"midnight\", \"24\", \"24:00\"}: return \"00:00\"\n",
    "    if t.lower() in {\"noon\", \"12pm\"}: return \"12:00\"\n",
    "    if re.match(r'^\\d{1,2}:\\d{1,2}$', t):\n",
    "        h, m = t.split(\":\"); return f\"{int(h):02d}:{int(m):02d}\"\n",
    "    if re.match(r'^\\d{1,2}$', t):\n",
    "        return f\"{int(t):02d}:00\"\n",
    "    return t\n",
    "\n",
    "def _parse_segment(seg: str):\n",
    "    seg = _normalize_day_text(seg)\n",
    "    mdig = re.search(r'\\d', seg)\n",
    "    day_part = seg[:mdig.start()].strip().rstrip(\",\") if mdig else seg\n",
    "    times_part = seg[mdig.start():].strip() if mdig else \"\"\n",
    "    if day_part:\n",
    "        day_tokens = [p.strip() for p in day_part.split(\",\") if p.strip()]\n",
    "        days = []\n",
    "        for tok in day_tokens:\n",
    "            days += _expand_days_token(tok)\n",
    "    else:\n",
    "        days = DAY_ORDER[:]\n",
    "    times = []\n",
    "    if times_part:\n",
    "        for tseg in [x.strip() for x in re.split(r',|\\s*/\\s*', times_part) if x.strip()]:\n",
    "            if tseg.endswith(\"+\"):\n",
    "                times.append([_parse_time_value(tseg[:-1]), \"late\"])\n",
    "            elif \"-\" in tseg:\n",
    "                a, b = tseg.split(\"-\", 1)\n",
    "                times.append([_parse_time_value(a), _parse_time_value(b)])\n",
    "            else:\n",
    "                tok = tseg.lower()\n",
    "                if tok in {\"closed\", \"off\"}:\n",
    "                    times.append([\"closed\", \"closed\"])\n",
    "                else:\n",
    "                    times.append([_parse_time_value(tseg), \"\"])\n",
    "    return days, times\n",
    "\n",
    "def opening_hours_to_dict(text: str):\n",
    "    if not isinstance(text, str) or text.strip() == \"\" or \"missing\" in text.lower():\n",
    "        return None\n",
    "    result = {}\n",
    "    segments = [s.strip() for s in re.split(r';|\\||·', text) if s.strip()]\n",
    "    if not segments: segments = [text.strip()]\n",
    "    for seg in segments:\n",
    "        days, times = _parse_segment(seg)\n",
    "        if not times: continue\n",
    "        for d in days:\n",
    "            result.setdefault(d, []).extend(times)\n",
    "    return result\n",
    "\n",
    "# --- APPLY transformation directly to df ---\n",
    "df[\"opening_hours_dict\"] = df[\"opening_hours\"].apply(opening_hours_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "037d2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans empty spaces on the phone column\n",
    "df[\"phone\"] = (\n",
    "    df[\"phone\"]\n",
    "    .str.strip()                         # remove leading/trailing\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)  # collapse multiple spaces\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a33efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the name of the actual district column to 'neighborhood'\n",
    "df.rename(columns={\"district\": \"neighborhood\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4286c15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmapped neighborhoods: ['Villavicencio' 'Kensington']\n"
     ]
    }
   ],
   "source": [
    "# Creates a new column 'district' thorugh a lookup dictionary\n",
    "# Berlin Ortsteil (neighborhood) to official 12 Bezirke mapping\n",
    "\n",
    "neighborhood_to_district = {\n",
    "    # Mitte\n",
    "    \"Mitte\": \"Mitte\",\n",
    "    \"Moabit\": \"Mitte\",\n",
    "    \"Tiergarten\": \"Mitte\",\n",
    "    \"Wedding\": \"Mitte\",\n",
    "    \"Gesundbrunnen\": \"Mitte\",\n",
    "    \"Wedding-Mitte\": \"Mitte\",\n",
    "    \"Hansaviertel\" : \"Mitte\",\n",
    "\n",
    "\n",
    "    # Friedrichshain-Kreuzberg\n",
    "    \"Friedrichshain\": \"Friedrichshain-Kreuzberg\",\n",
    "    \"Kreuzberg\": \"Friedrichshain-Kreuzberg\",\n",
    "    \"Alt-Treptow\": \"Friedrichshain-Kreuzberg\",\n",
    "    \"Oberschöneweide\": \"Friedrichshain-Kreuzberg\", \n",
    "\n",
    "    # Pankow\n",
    "    \"Prenzlauer Berg\": \"Pankow\",\n",
    "    \"Weißensee\": \"Pankow\",\n",
    "    \"Pankow\": \"Pankow\",\n",
    "    \"Blankenburg\": \"Pankow\",\n",
    "    \"Heinersdorf\": \"Pankow\",\n",
    "    \"Karow\": \"Pankow\",\n",
    "    \"Niederschönhausen\": \"Pankow\",\n",
    "    \"Rosenthal\": \"Pankow\",\n",
    "    \"Wilhelmsruh\": \"Pankow\",\n",
    "    \"Buch\": \"Pankow\",\n",
    "    \"Französisch Buchholz\": \"Pankow\",\n",
    "    \"Blankenfelde\": \"Pankow\",\n",
    "    \"Buchholz\": \"Pankow\",\n",
    "    \"Stadtrandsiedlung Malchow\": \"Pankow\",\n",
    "    \n",
    "\n",
    "    # Charlottenburg-Wilmersdorf\n",
    "    \"Charlottenburg\": \"Charlottenburg-Wilmersdorf\",\n",
    "    \"Wilmersdorf\": \"Charlottenburg-Wilmersdorf\",\n",
    "    \"Schmargendorf\": \"Charlottenburg-Wilmersdorf\",\n",
    "    \"Grunewald\": \"Charlottenburg-Wilmersdorf\",\n",
    "    \"Westend\": \"Charlottenburg-Wilmersdorf\",\n",
    "    \"Halensee\": \"Charlottenburg-Wilmersdorf\",\n",
    "    \"Charlottenburg-Nord\": \"Charlottenburg-Wilmersdorf\",\n",
    "\n",
    "    # Spandau\n",
    "    \"Spandau\": \"Spandau\",\n",
    "    \"Haselhorst\": \"Spandau\",\n",
    "    \"Siemensstadt\": \"Spandau\",\n",
    "    \"Staaken\": \"Spandau\",\n",
    "    \"Gatow\": \"Spandau\",\n",
    "    \"Kladow\": \"Spandau\",\n",
    "    \"Hakenfelde\": \"Spandau\",\n",
    "    \"Falkenhagener Feld\": \"Spandau\",\n",
    "    \"Wilhelmstadt\": \"Spandau\",\n",
    "\n",
    "\n",
    "    # Steglitz-Zehlendorf\n",
    "    \"Steglitz\": \"Steglitz-Zehlendorf\",\n",
    "    \"Lichterfelde\": \"Steglitz-Zehlendorf\",\n",
    "    \"Lankwitz\": \"Steglitz-Zehlendorf\",\n",
    "    \"Zehlendorf\": \"Steglitz-Zehlendorf\",\n",
    "    \"Dahlem\": \"Steglitz-Zehlendorf\",\n",
    "    \"Nikolassee\": \"Steglitz-Zehlendorf\",\n",
    "    \"Wannsee\": \"Steglitz-Zehlendorf\",\n",
    "    \"Teltowkanal\": \"Steglitz-Zehlendorf\",\n",
    "    \"Zehlendorf-Mitte\": \"Steglitz-Zehlendorf\", \n",
    "    \"Schlachtensee\": \"Steglitz-Zehlendorf\",\n",
    "\n",
    "    # Tempelhof-Schöneberg\n",
    "    \"Schöneberg\": \"Tempelhof-Schöneberg\",\n",
    "    \"Friedenau\": \"Tempelhof-Schöneberg\",\n",
    "    \"Tempelhof\": \"Tempelhof-Schöneberg\",\n",
    "    \"Mariendorf\": \"Tempelhof-Schöneberg\",\n",
    "    \"Marienfelde\": \"Tempelhof-Schöneberg\",\n",
    "    \"Lichtenrade\": \"Tempelhof-Schöneberg\",\n",
    "    \"Tempelhof-Süd\": \"Tempelhof-Schöneberg\",\n",
    "\n",
    "\n",
    "    # Neukölln\n",
    "    \"Neukölln\": \"Neukölln\",\n",
    "    \"Britz\": \"Neukölln\",\n",
    "    \"Buckow\": \"Neukölln\",\n",
    "    \"Rudow\": \"Neukölln\",\n",
    "    \"Gropiusstadt\": \"Neukölln\",\n",
    "\n",
    "    # Treptow-Köpenick\n",
    "    \"Alt-Treptow\": \"Treptow-Köpenick\",\n",
    "    \"Plänterwald\": \"Treptow-Köpenick\",\n",
    "    \"Baumschulenweg\": \"Treptow-Köpenick\",\n",
    "    \"Johannisthal\": \"Treptow-Köpenick\",\n",
    "    \"Niederschöneweide\": \"Treptow-Köpenick\",\n",
    "    \"Altglienicke\": \"Treptow-Köpenick\",\n",
    "    \"Adlershof\": \"Treptow-Köpenick\",\n",
    "    \"Bohnsdorf\": \"Treptow-Köpenick\",\n",
    "    \"Oberschöneweide\": \"Treptow-Köpenick\",\n",
    "    \"Köpenick\": \"Treptow-Köpenick\",\n",
    "    \"Friedrichshagen\": \"Treptow-Köpenick\",\n",
    "    \"Rahnsdorf\": \"Treptow-Köpenick\",\n",
    "    \"Grünau\": \"Treptow-Köpenick\",\n",
    "    \"Müggelheim\": \"Treptow-Köpenick\",\n",
    "    \"Schmöckwitz\": \"Treptow-Köpenick\",\n",
    "    \"Königs Wusterhausen\": \"Treptow-Köpenick\",\n",
    "\n",
    "\n",
    "    # Marzahn-Hellersdorf\n",
    "    \"Marzahn\": \"Marzahn-Hellersdorf\",\n",
    "    \"Biesdorf\": \"Marzahn-Hellersdorf\",\n",
    "    \"Kaulsdorf\": \"Marzahn-Hellersdorf\",\n",
    "    \"Mahlsdorf\": \"Marzahn-Hellersdorf\",\n",
    "    \"Hellersdorf\": \"Marzahn-Hellersdorf\",\n",
    "    \"Falkenberg\": \"Marzahn-Hellersdorf\",\n",
    "\n",
    "\n",
    "    # Lichtenberg\n",
    "    \"Fennpfuhl\": \"Lichtenberg\",\n",
    "    \"Rummelsburg\": \"Lichtenberg\",\n",
    "    \"Karlshorst\": \"Lichtenberg\",\n",
    "    \"Friedrichsfelde\": \"Lichtenberg\",\n",
    "    \"Lichtenberg\": \"Lichtenberg\",\n",
    "    \"Falkenberg\": \"Lichtenberg\",\n",
    "    \"Malchow\": \"Lichtenberg\",\n",
    "    \"Wartenberg\": \"Lichtenberg\",\n",
    "    \"Neu-Hohenschönhausen\": \"Lichtenberg\",\n",
    "    \"Alt-Hohenschönhausen\": \"Lichtenberg\",\n",
    "\n",
    "\n",
    "    # Reinickendorf\n",
    "    \"Reinickendorf\": \"Reinickendorf\",\n",
    "    \"Tegel\": \"Reinickendorf\",\n",
    "    \"Konradshöhe\": \"Reinickendorf\",\n",
    "    \"Heiligensee\": \"Reinickendorf\",\n",
    "    \"Frohnau\": \"Reinickendorf\",\n",
    "    \"Hermsdorf\": \"Reinickendorf\",\n",
    "    \"Waidmannslust\": \"Reinickendorf\",\n",
    "    \"Lübars\": \"Reinickendorf\",\n",
    "    \"Wittenau\": \"Reinickendorf\",\n",
    "    \"Märkisches Viertel\": \"Reinickendorf\",\n",
    "    \"Borsigwalde\": \"Reinickendorf\",\n",
    "\n",
    "}\n",
    "\n",
    "# Create new standardized 12-district column\n",
    "df[\"district\"] = df[\"neighborhood\"].map(neighborhood_to_district)\n",
    "\n",
    "# Find missing values (if any neighborhood not in mapping)\n",
    "missing = df[df[\"district\"].isna()][\"neighborhood\"].unique()\n",
    "print(\"Unmapped neighborhoods:\", missing)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d686cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df.to_csv(r'/Users/giovanigoltara/Documents/webeet/layered-populate-data-pool-da/venues/sources/berlin_venues_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7acf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delet rows with missing values in 'district' column\n",
    "df = df.dropna(subset=['district']) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
