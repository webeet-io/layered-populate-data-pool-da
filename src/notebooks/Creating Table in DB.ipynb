{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e8818-0596-402e-baad-abc4959c5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bcdfaf-0590-4bc4-bb01-798fb53404cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Example of df\n",
    "\n",
    "data = {\n",
    "    'id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'score': [95, 87, 78]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd49b88-2c14-46b1-be1a-44adc8a685a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name=''\n",
    "password=''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180e22d-855d-434d-855e-77d5fb377f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conection\n",
    "host = 'localhost'\n",
    "port = '5433'\n",
    "database = 'layereddb'\n",
    "schema='berlin_source_data'\n",
    "\n",
    "#connection to db after you opened tunnel\n",
    "engine = create_engine(f'postgresql+psycopg2://{user_name}:{password}@{host}:{port}/{database}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4fef27-3af3-43a6-bfbd-f55872b4bfd4",
   "metadata": {},
   "source": [
    "### Before creating the table\n",
    "Before creating the table, always pay attention to the `CREATE TABLE` statement in SQL. Check what columns are included, their order, their exact names, and their data types, including the length limits. Your Pandas DataFrame must match this table exactly — same column order, same names, and compatible data types — before you send it to the database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fcfd3c-9a70-421f-9236-c0f906d5c7f1",
   "metadata": {},
   "source": [
    "#### Constraints and references\n",
    "Pay attention to constraints and foreign key references in your table. These are defined in the `CREATE TABLE` statement. After creating the table with constraints and references, go to DBeaver and verify that the empty table has been correctly created with all the intended constraints and references.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5ed03-b129-469c-b458-a60979d5447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#this is where you create table with constraints and references first\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {schema}.test_table_{user_name} (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    score INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query to create empty table\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_table_query))\n",
    "    conn.commit()  # commit the transaction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c12117-5078-4ca0-aa4b-6f112669e501",
   "metadata": {},
   "source": [
    "####  Sending the DataFrame\n",
    "Once you have verified in DBeaver that the empty table exists with its references and constraints, it is time to send your Pandas DataFrame using `.to_sql()` with `if_exists='append'`. If there are mismatches in data types, column names, or order compared to the table, Python will raise an error. If everything matches, the table will be populated correctly, preserving the constraints and references.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40221f4-d09e-4e4a-bf2c-0a0ac2252027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Send the DataFrame to the database using .to_sql()\n",
    "df.to_sql(\n",
    "    f'test_table_{user_name}',        # table name\n",
    "    engine,\n",
    "    schema=schema,\n",
    "    if_exists='append', # append table if it exists\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"DataFrame sent to PostgreSQL using .to_sql() with psycopg2!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d05a7e-1b21-4b30-b54a-343ab81db1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##let's query test data!\n",
    "query = f\"\"\"\n",
    "SELECT * from berlin_source_data.districts\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "with engine.connect() as conn:\n",
    "    df= pd.read_sql(text(query), conn)\n",
    "    conn.commit()  # commit the transaction\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1d942-cc46-4615-bb46-554f28617a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
