{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Populate Database.**"
      ],
      "metadata": {
        "id": "Se0J58HnAJC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "import io\n",
        "import requests\n",
        "\n",
        "# For database interaction. Use the library appropriate for your database.\n",
        "# This example uses psycopg2 for PostgreSQL.\n",
        "try:\n",
        "    import psycopg2\n",
        "    from psycopg2 import sql\n",
        "except ImportError:\n",
        "    print(\"Warning: psycopg2 not found. Database functionality will not work.\")\n",
        "    print(\"Please install it with: pip install psycopg2-binary\")\n",
        "    psycopg2 = None\n",
        "\n",
        "# --- Configuration ---\n",
        "# Define the directory where your raw data files are located\n",
        "RAW_DATA_DIR = \"/content\"\n",
        "PROCESSED_DATA_DIR = os.path.join(RAW_DATA_DIR, \"processed\")\n",
        "\n",
        "# Ensure the processed data directory exists\n",
        "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
        "\n",
        "# Define paths to your input data files\n",
        "BERLIN_CSV_PATH = os.path.join(RAW_DATA_DIR, \"berlin_kitas_raw.csv\")\n",
        "NEIGHBOURHOODS_GEOJSON_URL = \"https://raw.githubusercontent.com/m-hoerz/berlin-shapes/master/berliner-bezirke.geojson\"\n",
        "\n",
        "# --- Database Configuration ---\n",
        "# IMPORTANT: Replace this with your actual database connection string\n",
        "DATABASE_URL = \"postgresql://user:password@host:port/dbname\"\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "print(\"--- Loading Data ---\")\n",
        "\n",
        "berlin_df = pd.DataFrame()\n",
        "try:\n",
        "    berlin_df = pd.read_csv(BERLIN_CSV_PATH, sep=',', encoding='utf-8', on_bad_lines='skip', header=1)\n",
        "    berlin_df.columns = berlin_df.columns.str.strip()\n",
        "    print(f\"Successfully loaded Berlin data from {BERLIN_CSV_PATH}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Berlin data file not found at {BERLIN_CSV_PATH}.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred loading Berlin data: {e}\")\n",
        "    berlin_df = pd.DataFrame()\n",
        "\n",
        "berlin_neighbourhoods = gpd.GeoDataFrame()\n",
        "try:\n",
        "    response = requests.get(NEIGHBOURHOODS_GEOJSON_URL)\n",
        "    response.raise_for_status()\n",
        "    berlin_neighbourhoods = gpd.read_file(io.StringIO(response.text))\n",
        "    print(f\"\\nSuccessfully loaded Berlin neighbourhoods GeoJSON from URL.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred loading neighbourhoods GeoJSON: {e}\")\n",
        "    berlin_neighbourhoods = gpd.GeoDataFrame()\n",
        "\n",
        "# --- 2. Data Cleaning and Transformation ---\n",
        "print(\"\\n--- Data Cleaning and Transformation ---\")\n",
        "\n",
        "berlin_processed = pd.DataFrame()\n",
        "if not berlin_df.empty:\n",
        "    print(\"Processing Berlin data...\")\n",
        "    column_map_berlin = {\n",
        "        'Einrichtungsbezirk': 'district_code',\n",
        "        'Einrichtungsbezirk Name': 'district',\n",
        "        'Einrichtungsnummer': 'kita_id',\n",
        "        'Einrichtungsname': 'name',\n",
        "        'Stra√üe': 'street',\n",
        "        'Hausnummer': 'street_number',\n",
        "        'PLZ': 'postcode',\n",
        "        'ETRS_YKOORDINATE': 'ETRS_y',\n",
        "        'ETRS_XKOORDINATE': 'ETRS_x'\n",
        "    }\n",
        "    berlin_df.rename(columns={k: v for k, v in column_map_berlin.items() if k in berlin_df.columns}, inplace=True)\n",
        "    if 'ETRS_x' in berlin_df.columns and 'ETRS_y' in berlin_df.columns:\n",
        "        berlin_df['ETRS_x'] = pd.to_numeric(berlin_df['ETRS_x'], errors='coerce')\n",
        "        berlin_df['ETRS_y'] = pd.to_numeric(berlin_df['ETRS_y'], errors='coerce')\n",
        "        berlin_df.dropna(subset=['ETRS_x', 'ETRS_y'], inplace=True)\n",
        "        berlin_df['source'] = 'berlin_gov'\n",
        "        selected_columns_berlin = ['name', 'street', 'postcode', 'ETRS_x', 'ETRS_y', 'source']\n",
        "        berlin_processed = berlin_df[[col for col in selected_columns_berlin if col in berlin_df.columns]].copy()\n",
        "        print(\"Berlin data processed.\")\n",
        "else:\n",
        "    print(\"Skipping Berlin data processing due to loading errors.\")\n",
        "\n",
        "# --- 3. Create GeoDataFrame and Spatial Join ---\n",
        "print(\"\\n--- Creating GeoDataFrame and Performing Spatial Join ---\")\n",
        "\n",
        "final_gdf = gpd.GeoDataFrame()\n",
        "if not berlin_processed.empty and not berlin_neighbourhoods.empty:\n",
        "    source_crs = \"EPSG:25833\"\n",
        "    target_crs = \"EPSG:4326\"\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        berlin_processed,\n",
        "        geometry=gpd.points_from_xy(berlin_processed['ETRS_x'], berlin_processed['ETRS_y']),\n",
        "        crs=source_crs\n",
        "    )\n",
        "    gdf = gdf.to_crs(target_crs)\n",
        "    try:\n",
        "        kitas_with_neighbourhoods = gpd.sjoin(gdf, berlin_neighbourhoods, how=\"inner\", predicate=\"intersects\")\n",
        "        print(\"Spatial join complete.\")\n",
        "        neighbourhood_col_name = next((col for col in ['name', 'name_en', 'Name', 'neighbourhood', 'NAME_BEZIR', 'name_local'] if col in berlin_neighbourhoods.columns), None)\n",
        "        if neighbourhood_col_name:\n",
        "            final_gdf = kitas_with_neighbourhoods.rename(columns={neighbourhood_col_name: 'neighbourhood'})\n",
        "            final_gdf['longitude'] = final_gdf.geometry.x\n",
        "            final_gdf['latitude'] = final_gdf.geometry.y\n",
        "            final_gdf.drop(columns=['ETRS_x', 'ETRS_y'], inplace=True)\n",
        "            print(\"Final GeoDataFrame with neighbourhood information created.\")\n",
        "        else:\n",
        "            print(\"Could not find a suitable neighbourhood name column. Using the joined data as is.\")\n",
        "            final_gdf = kitas_with_neighbourhoods.copy()\n",
        "            final_gdf['longitude'] = final_gdf.geometry.x\n",
        "            final_gdf['latitude'] = final_gdf.geometry.y\n",
        "            final_gdf.drop(columns=['ETRS_x', 'ETRS_y'], inplace=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the spatial join: {e}\")\n",
        "else:\n",
        "    print(\"Skipping spatial join because either kindergarten data or neighbourhood data was not loaded/processed correctly.\")\n",
        "\n",
        "# --- Functions for Database Population (Step 3) ---\n",
        "\n",
        "def create_kindergartens_table(conn):\n",
        "    \"\"\"Creates the berlin_kindergartens table if it doesn't exist.\"\"\"\n",
        "    print(\"Creating 'berlin_kindergartens' table...\")\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS berlin_kindergartens (\n",
        "            id SERIAL PRIMARY KEY,\n",
        "            name VARCHAR(255),\n",
        "            street VARCHAR(255),\n",
        "            postcode VARCHAR(10),\n",
        "            latitude DOUBLE PRECISION,\n",
        "            longitude DOUBLE PRECISION,\n",
        "            neighbourhood VARCHAR(255),\n",
        "            source VARCHAR(50)\n",
        "        );\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    print(\"Table 'berlin_kindergartens' created or already exists.\")\n",
        "\n",
        "def insert_data(conn, gdf):\n",
        "    \"\"\"Inserts data from the GeoDataFrame into the database.\"\"\"\n",
        "    print(\"Inserting data into 'berlin_kindergartens'...\")\n",
        "    cur = conn.cursor()\n",
        "    # Use a parameterized query to prevent SQL injection\n",
        "    insert_query = \"\"\"\n",
        "        INSERT INTO berlin_kindergartens (name, street, postcode, latitude, longitude, neighbourhood, source)\n",
        "        VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    # Iterate over the GeoDataFrame rows and insert each one\n",
        "    for index, row in gdf.iterrows():\n",
        "        try:\n",
        "            cur.execute(\n",
        "                insert_query,\n",
        "                (\n",
        "                    row['name'],\n",
        "                    row['street'],\n",
        "                    row['postcode'],\n",
        "                    row['latitude'],\n",
        "                    row['longitude'],\n",
        "                    row['neighbourhood'] if 'neighbourhood' in row else None,\n",
        "                    row['source']\n",
        "                )\n",
        "            )\n",
        "            count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error inserting row {index}: {e}\")\n",
        "            conn.rollback() # Rollback the transaction on error\n",
        "            continue\n",
        "\n",
        "    conn.commit()\n",
        "    print(f\"Successfully inserted {count} rows into the database.\")\n",
        "    cur.close()\n",
        "\n",
        "# --- 4. Populate Database (Step 3) ---\n",
        "if not final_gdf.empty and psycopg2 is not None:\n",
        "    conn = None\n",
        "    try:\n",
        "        print(\"\\n--- Populating Database (Step 3) ---\")\n",
        "        conn = psycopg2.connect(DATABASE_URL)\n",
        "        create_kindergartens_table(conn)\n",
        "        insert_data(conn, final_gdf)\n",
        "\n",
        "        # --- Verification Step ---\n",
        "        print(\"\\n--- Verifying Data Insertion ---\")\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\"SELECT COUNT(*) FROM berlin_kindergartens;\")\n",
        "        print(f\"Total rows in 'berlin_kindergartens' table: {cur.fetchone()[0]}\")\n",
        "        cur.execute(\"SELECT * FROM berlin_kindergartens LIMIT 5;\")\n",
        "        print(\"First 5 rows of the table:\")\n",
        "        for row in cur.fetchall():\n",
        "            print(row)\n",
        "        cur.close()\n",
        "\n",
        "    except psycopg2.Error as e:\n",
        "        print(f\"Database error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during database population: {e}\")\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "            print(\"Database connection closed.\")\n",
        "else:\n",
        "    if psycopg2 is None:\n",
        "        print(\"\\nSkipping database population. psycopg2 library is not installed.\")\n",
        "    else:\n",
        "        print(\"\\nSkipping database population. Final GeoDataFrame is empty.\")\n",
        "\n",
        "print(\"\\n--- Transformation Process Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHKbWwZUtq2t",
        "outputId": "0e29ff1f-992b-4a9b-8c5b-eeb45476e050"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading Data ---\n",
            "Successfully loaded Berlin data from /content/berlin_kitas_raw.csv\n",
            "\n",
            "Successfully loaded Berlin neighbourhoods GeoJSON from URL.\n",
            "\n",
            "--- Data Cleaning and Transformation ---\n",
            "Processing Berlin data...\n",
            "Berlin data processed.\n",
            "\n",
            "--- Creating GeoDataFrame and Performing Spatial Join ---\n",
            "Spatial join complete.\n",
            "Could not find a suitable neighbourhood name column. Using the joined data as is.\n",
            "\n",
            "--- Populating Database (Step 3) ---\n",
            "Database error: invalid integer value \"port\" for connection option \"port\"\n",
            "\n",
            "\n",
            "--- Transformation Process Complete ---\n"
          ]
        }
      ]
    }
  ]
}