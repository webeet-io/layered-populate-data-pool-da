{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70163d35-0040-4015-b56a-7df17ab2de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "# Define constants that are used but not defined in the snippet\n",
    "DEFAULT_ENDPOINT = \"https://overpass-api.de/api/interpreter\"\n",
    "USER_AGENT = \"YourAppName/1.0 (you@example.com)\"\n",
    "OVERPASS_QUERY = \"\"\"\n",
    "[out:json];\n",
    "area[\"name\"=\"Berlin\"][\"admin_level\"=\"4\"]->.berlin;\n",
    "(\n",
    "  node[\"healthcare\"=\"dentist\"](area.berlin);\n",
    "  way[\"healthcare\"=\"dentist\"](area.berlin);\n",
    "  relation[\"healthcare\"=\"dentist\"](area.berlin);\n",
    ");\n",
    "out center;\n",
    "\"\"\"\n",
    "\n",
    "# Function to normalize elements (placeholder implementation)\n",
    "def normalize_element(e):\n",
    "    # Implement according to your needs\n",
    "    return e\n",
    "\n",
    "# Function to convert elements to GeoJSON (placeholder implementation)\n",
    "def elements_to_geojson(elements):\n",
    "    # Implement according to your needs\n",
    "    return {\"type\": \"FeatureCollection\", \"features\": []}\n",
    "\n",
    "# Function to fetch data from Overpass API (placeholder implementation)\n",
    "def fetch_overpass(query, endpoint):\n",
    "    # Implement according to your needs\n",
    "    return {\"elements\": []}\n",
    "\n",
    "# Fixed the function name from 'ite_csv' to 'write_csv'å\n",
    "def write_csv(rows: List[Dict[str, Any]], path: str) -> None:\n",
    "    fieldnames = [\n",
    "        \"osm_type\", \"osm_id\", \"name\", \"addr_street\", \"addr_housenumber\",\n",
    "        \"addr_postcode\", \"addr_city\", \"opening_hours\", \"wheelchair\",\n",
    "        \"phone\", \"email\", \"website\", \"lat\", \"lon\"\n",
    "    ]\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for el in rows:\n",
    "            row = {k: el.get(k) for k in fieldnames}\n",
    "            writer.writerow(row)\n",
    "\n",
    "def write_geojson(geo: Dict[str, Any], path: str) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(geo, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def fetch_and_save(endpoint: str, out_prefix: str, fmt: str) -> Tuple[str, str]:\n",
    "    data = fetch_overpass(OVERPASS_QUERY, endpoint=endpoint)\n",
    "    elements = data.get(\"elements\", [])\n",
    "    rows = [normalize_element(e) for e in elements]\n",
    "    csv_path = geojson_path = None\n",
    "    if fmt in (\"csv\", \"both\"):\n",
    "        csv_path = f\"{out_prefix}.csv\"\n",
    "        write_csv(rows, csv_path)\n",
    "    if fmt in (\"geojson\", \"both\"):\n",
    "        geojson_path = f\"{out_prefix}.geojson\"\n",
    "        write_geojson(elements_to_geojson(elements), geojson_path)\n",
    "    return csv_path, geojson_path\n",
    "\n",
    "def main(argv=None):\n",
    "    parser = argparse.ArgumentParser(description=\"Fetch Berlin dental offices from OSM\")\n",
    "    parser.add_argument(\"--endpoint\", default=DEFAULT_ENDPOINT)\n",
    "    parser.add_argument(\"--out\", dest=\"out_prefix\", default=\"berlin_dentists\")\n",
    "    parser.add_argument(\"--format\", choices=[\"csv\", \"geojson\", \"both\"], default=\"both\")\n",
    "    args = parser.parse_args(argv)\n",
    "    if USER_AGENT.endswith(\"you@example.com\"):\n",
    "        print(\"[WARN] Please customize USER_AGENT.\", file=sys.stderr)\n",
    "    csv_path, geojson_path = fetch_and_save(args.endpoint, args.out_prefix, args.format)\n",
    "    if csv_path:\n",
    "        print(f\"Saved CSV: {csv_path}\")\n",
    "    if geojson_path:\n",
    "        print(f\"Saved GeoJSON: {geojson_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    args_to_parse = sys.argv[1:]\n",
    "    try:\n",
    "        # Remove Jupyter's extra args if present\n",
    "        if any(arg.endswith(\".json\") for arg in args_to_parse):\n",
    "            args_to_parse = []\n",
    "        main_parser = argparse.ArgumentParser(...)\n",
    "        # define arguments...\n",
    "        parsed_args = main_parser.parse_args(args_to_parse)\n",
    "    except SystemExit:\n",
    "        pass  # Prevent Jupyter from exiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6479c66e-e47e-439b-852e-5348f5405d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] Please set --user-agent with an email or URL (Overpass etiquette).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV: berlin_dentists.csv\n",
      "Saved GeoJSON: berlin_dentists.geojson\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Retrieve dental offices/clinics in Berlin from OpenStreetMap via Overpass API.\n",
    "\n",
    "✅ Jupyter-friendly (ignores unknown CLI args)\n",
    "✅ Adds clear diagnostics for HTTP 400 responses (shows Overpass error text)\n",
    "✅ Tries multiple mirrors automatically (\"--endpoint auto\")\n",
    "✅ Falls back between two safe queries (by area-id and by name) to avoid syntax quirks\n",
    "✅ Optional: choose output (CSV / GeoJSON / both)\n",
    "✅ Includes lightweight self-tests you can run in-notebook\n",
    "\n",
    "USAGE (terminal or Jupyter cell):\n",
    "    # defaults: auto mirror, both CSV+GeoJSON, files named berlin_dentists.*\n",
    "    main()\n",
    "\n",
    "    # custom\n",
    "    main([\n",
    "        \"--format\", \"both\",\n",
    "        \"--out\", \"berlin_dentists\",\n",
    "        \"--endpoint\", \"auto\",\n",
    "        \"--user-agent\", \"BerlinDentistsFetcher/1.0 (contact: your@email)\"\n",
    "    ])\n",
    "\n",
    "Notes:\n",
    "- Please **set a meaningful User-Agent** (email or URL) to be a good Overpass citizen.\n",
    "- If a 400 happens, this script now prints the server's error text and automatically\n",
    "  retries with a different mirror and alternate query.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import requests\n",
    "\n",
    "# --------------------------- Config & Queries --------------------------- #\n",
    "DEFAULT_ENDPOINT = \"auto\"  # \"auto\" tries MIRRORS in order below\n",
    "MIRRORS: List[str] = [\n",
    "    \"https://overpass.kumi.systems/api/interpreter\",\n",
    "    \"https://overpass-api.de/api/interpreter\",\n",
    "    \"https://z.overpass-api.de/api/interpreter\",\n",
    "]\n",
    "\n",
    "# Berlin relation id is 62422; Overpass area id is 3600000000 + 62422\n",
    "BERLIN_REL_ID = 62422\n",
    "BERLIN_AREA_ID = 3600000000 + BERLIN_REL_ID  # 3600062422\n",
    "\n",
    "# Primary query: use area by numeric id (more robust, faster)\n",
    "OVERPASS_QUERY_BY_ID = rf\"\"\"\n",
    "[out:json][timeout:180];\n",
    "area({BERLIN_AREA_ID})->.searchArea;\n",
    "(\n",
    "  node[\"amenity\"=\"dentist\"](area.searchArea);\n",
    "  way[\"amenity\"=\"dentist\"](area.searchArea);\n",
    "  relation[\"amenity\"=\"dentist\"](area.searchArea);\n",
    ");\n",
    "out tags center;\n",
    "\"\"\"\n",
    "\n",
    "# Fallback query: use name/admin filter (in case a mirror has trouble with numeric area ids)\n",
    "OVERPASS_QUERY_BY_NAME = r\"\"\"\n",
    "[out:json][timeout:180];\n",
    "area[\"name\"=\"Berlin\"][\"boundary\"=\"administrative\"][\"admin_level\"~\"^(4|6)$\"];->.searchArea;\n",
    "(\n",
    "  node[\"amenity\"=\"dentist\"](area.searchArea);\n",
    "  way[\"amenity\"=\"dentist\"](area.searchArea);\n",
    "  relation[\"amenity\"=\"dentist\"](area.searchArea);\n",
    ");\n",
    "out tags center;\n",
    "\"\"\"\n",
    "\n",
    "# Default UA can be overridden via --user-agent or OSM_USER_AGENT env var\n",
    "DEFAULT_USER_AGENT = (\n",
    "    os.getenv(\"OSM_USER_AGENT\")\n",
    "    or \"BerlinDentistsFetcher/1.0 (contact: set-your-contact@example.com)\"\n",
    ")\n",
    "\n",
    "# --------------------------- Exceptions --------------------------- #\n",
    "class OverpassError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "class OverpassBadRequest(OverpassError):\n",
    "    def __init__(self, message: str, response_text: str = \"\"):\n",
    "        super().__init__(message)\n",
    "        self.response_text = response_text\n",
    "\n",
    "# --------------------------- Core Fetch Logic --------------------------- #\n",
    "\n",
    "def _headers(user_agent: str) -> Dict[str, str]:\n",
    "    return {\n",
    "        \"User-Agent\": user_agent,\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "        \"Accept\": \"application/json\",\n",
    "    }\n",
    "\n",
    "\n",
    "def fetch_overpass_single(query: str, endpoint: str, user_agent: str, timeout_s: int = 300) -> Dict[str, Any]:\n",
    "    \"\"\"POST a single Overpass query to one endpoint, raising detailed errors.\n",
    "\n",
    "    Raises OverpassBadRequest on HTTP 400 with server error text included.\n",
    "    \"\"\"\n",
    "    resp = requests.post(\n",
    "        endpoint,\n",
    "        data={\"data\": query},\n",
    "        headers=_headers(user_agent),\n",
    "        timeout=timeout_s,\n",
    "    )\n",
    "    if resp.status_code == 400:\n",
    "        # Show server error to aid debugging (syntax errors, etc.)\n",
    "        text = (resp.text or \"\").strip()\n",
    "        raise OverpassBadRequest(\n",
    "            f\"400 Bad Request from {endpoint}\", response_text=text\n",
    "        )\n",
    "    # Retry logic for 429/5xx can be handled by caller; here we surface details\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "\n",
    "def fetch_overpass_with_retries(\n",
    "    queries: Iterable[str],\n",
    "    endpoint: str,\n",
    "    user_agent: str,\n",
    "    max_retries: int = 6,\n",
    "    base_backoff: float = 1.6,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Try queries (first to last) against endpoint with exponential backoff.\"\"\"\n",
    "    last_err: Optional[Exception] = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            for q in queries:\n",
    "                return fetch_overpass_single(q, endpoint, user_agent)\n",
    "        except OverpassBadRequest as e:\n",
    "            # Don't retry on 400 unless it's the *first* query and we can try the fallback query\n",
    "            last_err = e\n",
    "            # If first query failed (likely BY_ID) and we have a second (BY_NAME), try it next attempt\n",
    "            if attempt == 0:\n",
    "                # sleep a tiny bit then continue loop to try next query\n",
    "                time.sleep(0.2)\n",
    "                continue\n",
    "            break\n",
    "        except (requests.ConnectionError, requests.Timeout, requests.HTTPError) as e:\n",
    "            last_err = e\n",
    "            # 429 or 5xx: backoff and retry\n",
    "            sleep_s = min(90.0, base_backoff ** (attempt + 1))\n",
    "            time.sleep(sleep_s)\n",
    "            continue\n",
    "    # Exhausted retries\n",
    "    if isinstance(last_err, OverpassBadRequest):\n",
    "        msg = f\"Overpass 400 error. Server message (truncated):\\n{last_err.response_text[:500]}\"\n",
    "        raise OverpassBadRequest(msg, response_text=getattr(last_err, \"response_text\", \"\"))\n",
    "    raise OverpassError(f\"Failed after {max_retries} attempts: {last_err}\")\n",
    "\n",
    "\n",
    "def fetch_overpass_auto(\n",
    "    query_primary: str = OVERPASS_QUERY_BY_ID,\n",
    "    query_fallback: str = OVERPASS_QUERY_BY_NAME,\n",
    "    endpoint: str = DEFAULT_ENDPOINT,\n",
    "    user_agent: str = DEFAULT_USER_AGENT,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Try multiple mirrors and query fallbacks. Returns parsed JSON.\"\"\"\n",
    "    queries = (query_primary, query_fallback)\n",
    "\n",
    "    endpoints: List[str]\n",
    "    if endpoint == \"auto\":\n",
    "        endpoints = MIRRORS\n",
    "    else:\n",
    "        endpoints = [endpoint]\n",
    "\n",
    "    last_err: Optional[Exception] = None\n",
    "    for url in endpoints:\n",
    "        try:\n",
    "            return fetch_overpass_with_retries(queries, url, user_agent)\n",
    "        except Exception as e:  # capture details and move to next mirror\n",
    "            last_err = e\n",
    "            continue\n",
    "    raise OverpassError(f\"All endpoints failed. Last error: {last_err}\")\n",
    "\n",
    "# --------------------------- Transform --------------------------- #\n",
    "\n",
    "def normalize_element(el: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    el_type = el.get(\"type\")\n",
    "    osm_id = el.get(\"id\")\n",
    "    tags = el.get(\"tags\", {}) or {}\n",
    "\n",
    "    # Coordinates: for nodes use lat/lon; for ways/relations use 'center'\n",
    "    if el_type == \"node\":\n",
    "        lat = el.get(\"lat\")\n",
    "        lon = el.get(\"lon\")\n",
    "    else:\n",
    "        center = el.get(\"center\", {})\n",
    "        lat = center.get(\"lat\")\n",
    "        lon = center.get(\"lon\")\n",
    "\n",
    "    phone = tags.get(\"phone\") or tags.get(\"contact:phone\")\n",
    "    email = tags.get(\"email\") or tags.get(\"contact:email\")\n",
    "    website = tags.get(\"website\") or tags.get(\"contact:website\")\n",
    "\n",
    "    return {\n",
    "        \"osm_type\": el_type,\n",
    "        \"osm_id\": osm_id,\n",
    "        \"name\": tags.get(\"name\"),\n",
    "        \"addr_street\": tags.get(\"addr:street\"),\n",
    "        \"addr_housenumber\": tags.get(\"addr:housenumber\"),\n",
    "        \"addr_postcode\": tags.get(\"addr:postcode\"),\n",
    "        \"addr_city\": tags.get(\"addr:city\"),\n",
    "        \"opening_hours\": tags.get(\"opening_hours\"),\n",
    "        \"wheelchair\": tags.get(\"wheelchair\"),\n",
    "        \"phone\": phone,\n",
    "        \"email\": email,\n",
    "        \"website\": website,\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon,\n",
    "        \"_all_tags\": tags,\n",
    "    }\n",
    "\n",
    "\n",
    "def elements_to_geojson(elements: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    features = []\n",
    "    for el in elements:\n",
    "        norm = normalize_element(el)\n",
    "        lat, lon = norm.get(\"lat\"), norm.get(\"lon\")\n",
    "        if lat is None or lon is None:\n",
    "            continue\n",
    "        props = {k: v for k, v in norm.items() if k not in {\"lat\", \"lon\"}}\n",
    "        features.append(\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"geometry\": {\"type\": \"Point\", \"coordinates\": [lon, lat]},\n",
    "                \"properties\": props,\n",
    "            }\n",
    "        )\n",
    "    return {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "\n",
    "\n",
    "# --------------------------- I/O --------------------------- #\n",
    "\n",
    "def write_csv(rows: List[Dict[str, Any]], path: str) -> None:\n",
    "    fieldnames = [\n",
    "        \"osm_type\",\n",
    "        \"osm_id\",\n",
    "        \"name\",\n",
    "        \"addr_street\",\n",
    "        \"addr_housenumber\",\n",
    "        \"addr_postcode\",\n",
    "        \"addr_city\",\n",
    "        \"opening_hours\",\n",
    "        \"wheelchair\",\n",
    "        \"phone\",\n",
    "        \"email\",\n",
    "        \"website\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "    ]\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for el in rows:\n",
    "            row = {k: el.get(k) for k in fieldnames}\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def write_geojson(geo: Dict[str, Any], path: str) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(geo, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# --------------------------- High-level API --------------------------- #\n",
    "\n",
    "def fetch_and_save(\n",
    "    endpoint: str,\n",
    "    out_prefix: str,\n",
    "    fmt: str,\n",
    "    user_agent: str,\n",
    ") -> Tuple[Optional[str], Optional[str]]:\n",
    "    data = fetch_overpass_auto(\n",
    "        query_primary=OVERPASS_QUERY_BY_ID,\n",
    "        query_fallback=OVERPASS_QUERY_BY_NAME,\n",
    "        endpoint=endpoint,\n",
    "        user_agent=user_agent,\n",
    "    )\n",
    "    elements = data.get(\"elements\", [])\n",
    "    rows = [normalize_element(e) for e in elements]\n",
    "\n",
    "    csv_path: Optional[str] = None\n",
    "    geojson_path: Optional[str] = None\n",
    "\n",
    "    if fmt in (\"csv\", \"both\"):\n",
    "        csv_path = f\"{out_prefix}.csv\"\n",
    "        write_csv(rows, csv_path)\n",
    "    if fmt in (\"geojson\", \"both\"):\n",
    "        geojson_path = f\"{out_prefix}.geojson\"\n",
    "        write_geojson(elements_to_geojson(elements), geojson_path)\n",
    "\n",
    "    return csv_path, geojson_path\n",
    "\n",
    "\n",
    "# --------------------------- CLI / Notebook entry --------------------------- #\n",
    "\n",
    "def main(argv: Optional[List[str]] = None):\n",
    "    parser = argparse.ArgumentParser(description=\"Fetch Berlin dental offices from OSM (amenity=dentist)\")\n",
    "    parser.add_argument(\"--endpoint\", default=DEFAULT_ENDPOINT, help='Overpass endpoint or \"auto\" to try multiple mirrors')\n",
    "    parser.add_argument(\"--out\", dest=\"out_prefix\", default=\"berlin_dentists\", help=\"Output file prefix without extension\")\n",
    "    parser.add_argument(\"--format\", choices=[\"csv\", \"geojson\", \"both\"], default=\"both\", help=\"Output format\")\n",
    "    parser.add_argument(\"--user-agent\", default=DEFAULT_USER_AGENT, help=\"HTTP User-Agent (please include contact)\")\n",
    "    parser.add_argument(\"--self-test\", action=\"store_true\", help=\"Run self-tests and exit\")\n",
    "    args, _ = parser.parse_known_args(argv)\n",
    "\n",
    "    if args.self_test:\n",
    "        _run_self_tests()\n",
    "        return\n",
    "\n",
    "    if \"set-your-contact\" in args.user_agent:\n",
    "        print(\n",
    "            \"[WARN] Please set --user-agent with an email or URL (Overpass etiquette).\",\n",
    "            file=sys.stderr,\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        csv_path, geojson_path = fetch_and_save(args.endpoint, args.out_prefix, args.format, args.user_agent)\n",
    "    except OverpassBadRequest as e:\n",
    "        # Print full server message to help users fix query issues\n",
    "        print(\"[ERROR] Overpass returned 400 Bad Request.\", file=sys.stderr)\n",
    "        if e.response_text:\n",
    "            snippet = e.response_text.strip()\n",
    "            if len(snippet) > 2000:\n",
    "                snippet = snippet[:2000] + \"\\n… (truncated)\"\n",
    "            print(\"--- Server response begin ---\", file=sys.stderr)\n",
    "            print(snippet, file=sys.stderr)\n",
    "            print(\"--- Server response end ---\", file=sys.stderr)\n",
    "        raise\n",
    "    if csv_path:\n",
    "        print(f\"Saved CSV: {csv_path}\")\n",
    "    if geojson_path:\n",
    "        print(f\"Saved GeoJSON: {geojson_path}\")\n",
    "\n",
    "\n",
    "# --------------------------- Self-tests --------------------------- #\n",
    "\n",
    "def _sample_overpass_elements() -> List[Dict[str, Any]]:\n",
    "    # Minimal fixture with a node and a way (with center)\n",
    "    return [\n",
    "        {\n",
    "            \"type\": \"node\",\n",
    "            \"id\": 123,\n",
    "            \"lat\": 52.52,\n",
    "            \"lon\": 13.405,\n",
    "            \"tags\": {\n",
    "                \"amenity\": \"dentist\",\n",
    "                \"name\": \"Dr. Node\",\n",
    "                \"addr:street\": \"Alexanderplatz\",\n",
    "                \"addr:housenumber\": \"1\",\n",
    "                \"addr:postcode\": \"10178\",\n",
    "                \"addr:city\": \"Berlin\",\n",
    "                \"phone\": \"+49 30 123456\",\n",
    "                \"website\": \"https://example.com\",\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"way\",\n",
    "            \"id\": 456,\n",
    "            \"center\": {\"lat\": 52.5, \"lon\": 13.4},\n",
    "            \"tags\": {\n",
    "                \"amenity\": \"dentist\",\n",
    "                \"name\": \"Zahnzentrum Way\",\n",
    "                \"contact:phone\": \"+49 30 654321\",\n",
    "                \"contact:website\": \"https://way.example.com\",\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "def _run_self_tests() -> None:\n",
    "    elems = _sample_overpass_elements()\n",
    "    rows = [normalize_element(e) for e in elems]\n",
    "\n",
    "    # Test 1: node lat/lon retained, way center used\n",
    "    assert rows[0][\"lat\"] == 52.52 and rows[0][\"lon\"] == 13.405, \"Node coordinates broken\"\n",
    "    assert rows[1][\"lat\"] == 52.5 and rows[1][\"lon\"] == 13.4, \"Way center coordinates broken\"\n",
    "\n",
    "    # Test 2: contact fields preference\n",
    "    assert rows[0][\"phone\"] == \"+49 30 123456\", \"Phone selection failed\"\n",
    "    assert rows[1][\"website\"] == \"https://way.example.com\", \"Website contact selection failed\"\n",
    "\n",
    "    # Test 3: GeoJSON conversion produces two points with properties\n",
    "    geo = elements_to_geojson(elems)\n",
    "    assert geo[\"type\"] == \"FeatureCollection\" and len(geo[\"features\"]) == 2, \"GeoJSON feature count wrong\"\n",
    "    for feat in geo[\"features\"]:\n",
    "        assert feat[\"geometry\"][\"type\"] == \"Point\", \"GeoJSON geometry type wrong\"\n",
    "        assert \"properties\" in feat and feat[\"properties\"].get(\"osm_id\") is not None, \"GeoJSON properties missing\"\n",
    "\n",
    "    print(\"Self-tests passed ✅\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b71a201-26a7-43ff-a233-2e1fdcdb79fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV: berlin_dentists.csv\n",
      "Saved GeoJSON: berlin_dentists.geojson\n"
     ]
    }
   ],
   "source": [
    "main([\n",
    "    \"--endpoint\", \"auto\",\n",
    "    \"--format\", \"both\",\n",
    "    \"--out\", \"berlin_dentists\",\n",
    "    \"--user-agent\", \"BerlinDentistsFetcher/1.0 (contact: jaywindie@gmail.com)\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6067e7a2-a9fa-451a-9ced-65e8bb3ef679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 780 entries, 0 to 779\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   osm_type          780 non-null    object \n",
      " 1   osm_id            780 non-null    int64  \n",
      " 2   name              754 non-null    object \n",
      " 3   addr_street       568 non-null    object \n",
      " 4   addr_housenumber  568 non-null    object \n",
      " 5   addr_postcode     528 non-null    float64\n",
      " 6   addr_city         520 non-null    object \n",
      " 7   opening_hours     586 non-null    object \n",
      " 8   wheelchair        287 non-null    object \n",
      " 9   phone             452 non-null    object \n",
      " 10  email             129 non-null    object \n",
      " 11  website           413 non-null    object \n",
      " 12  lat               780 non-null    float64\n",
      " 13  lon               780 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(10)\n",
      "memory usage: 85.4+ KB\n",
      "None\n",
      "  osm_type     osm_id                 name     addr_street addr_housenumber  \\\n",
      "0     node  304183504                  NaN  Hönower Straße               75   \n",
      "1     node  313539258  Zahnzentrum Wedding    Müllerstraße              34a   \n",
      "2     node  325161442             A. Nejad             NaN              NaN   \n",
      "3     node  345236220    Dr. Beate Lengert  Kurfürstendamm              218   \n",
      "4     node  391394177      Serpil Hartfiel  Kollwitzstraße               77   \n",
      "\n",
      "   addr_postcode addr_city                                      opening_hours  \\\n",
      "0        12623.0    Berlin                                                NaN   \n",
      "1        13353.0    Berlin  Mo 09:00-19:00; Tu 09:00-18:00; We 09:00-17:00...   \n",
      "2            NaN       NaN  Mo-Tu 09:00-19:00; We 09:00-14:00; Th 09:00-19...   \n",
      "3        10719.0    Berlin                                                NaN   \n",
      "4        10435.0    Berlin                  Mo-Th 08:00-19:00; Fr 08:00-12:00   \n",
      "\n",
      "  wheelchair             phone email                                  website  \\\n",
      "0        NaN               NaN   NaN                                      NaN   \n",
      "1        yes               NaN   NaN                                      NaN   \n",
      "2        yes  +49 30 361 91 06   NaN                                      NaN   \n",
      "3        NaN               NaN   NaN          http://www.dr-beate-lengert.de/   \n",
      "4         no               NaN   NaN  https://www.zahnarztpraxis-hartfiel.de/   \n",
      "\n",
      "         lat        lon  \n",
      "0  52.511411  13.612096  \n",
      "1  52.548838  13.355305  \n",
      "2  52.508843  13.180477  \n",
      "3  52.502722  13.328137  \n",
      "4  52.537547  13.418994  \n",
      "Transformed data saved to /Users/jamie/berlin_dentists_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV\n",
    "input_file = \"/Users/jamie/berlin_dentists.csv\"  \n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: Inspect Data\n",
    "# -----------------------------\n",
    "print(\"Initial Data Info:\")\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Normalize Text Fields\n",
    "# -----------------------------\n",
    "df['name'] = df['name'].fillna('Unknown').str.strip().str.title()\n",
    "df['addr_street'] = df['addr_street'].fillna('').str.strip().str.title()\n",
    "df['addr_housenumber'] = df['addr_housenumber'].fillna('').astype(str)\n",
    "df['addr_city'] = df['addr_city'].fillna('Berlin').str.strip().str.title()\n",
    "df['addr_postcode'] = df['addr_postcode'].fillna('').astype(str)\n",
    "\n",
    "# Combine street + house number\n",
    "df['address_full'] = df['addr_street'] + ' ' + df['addr_housenumber']\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Remove Duplicates\n",
    "# -----------------------------\n",
    "df = df.drop_duplicates(subset=['name', 'address_full'])\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Normalize Phone Numbers\n",
    "# -----------------------------\n",
    "df['phone'] = df['phone'].fillna('').str.replace(' ', '').str.replace('-', '')\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: Standardize Wheelchair Column\n",
    "# -----------------------------\n",
    "df['wheelchair'] = df['wheelchair'].fillna('unknown').str.lower()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 6: Ensure Coordinates Are Correct\n",
    "# -----------------------------\n",
    "for col in ['lat', 'lon']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "df = df.dropna(subset=['lat', 'lon'])\n",
    "\n",
    "# -----------------------------\n",
    "# Step 7: Save Cleaned CSV\n",
    "# -----------------------------\n",
    "output_file = os.path.join(os.path.dirname(input_file), \"berlin_dentists_clean.csv\")\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Transformed data saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f6b83e-f577-4dfa-ac5a-a32026dc970f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osm_type</th>\n",
       "      <th>osm_id</th>\n",
       "      <th>name</th>\n",
       "      <th>addr_street</th>\n",
       "      <th>addr_housenumber</th>\n",
       "      <th>addr_postcode</th>\n",
       "      <th>addr_city</th>\n",
       "      <th>opening_hours</th>\n",
       "      <th>wheelchair</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>website</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>address_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>node</td>\n",
       "      <td>304183504</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Hönower Straße</td>\n",
       "      <td>75</td>\n",
       "      <td>12623.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.511411</td>\n",
       "      <td>13.612096</td>\n",
       "      <td>Hönower Straße 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>node</td>\n",
       "      <td>313539258</td>\n",
       "      <td>Zahnzentrum Wedding</td>\n",
       "      <td>Müllerstraße</td>\n",
       "      <td>34a</td>\n",
       "      <td>13353.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Mo 09:00-19:00; Tu 09:00-18:00; We 09:00-17:00...</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.548838</td>\n",
       "      <td>13.355305</td>\n",
       "      <td>Müllerstraße 34a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>node</td>\n",
       "      <td>325161442</td>\n",
       "      <td>A. Nejad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Mo-Tu 09:00-19:00; We 09:00-14:00; Th 09:00-19...</td>\n",
       "      <td>yes</td>\n",
       "      <td>+49303619106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.508843</td>\n",
       "      <td>13.180477</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>node</td>\n",
       "      <td>345236220</td>\n",
       "      <td>Dr. Beate Lengert</td>\n",
       "      <td>Kurfürstendamm</td>\n",
       "      <td>218</td>\n",
       "      <td>10719.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.dr-beate-lengert.de/</td>\n",
       "      <td>52.502722</td>\n",
       "      <td>13.328137</td>\n",
       "      <td>Kurfürstendamm 218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>node</td>\n",
       "      <td>391394177</td>\n",
       "      <td>Serpil Hartfiel</td>\n",
       "      <td>Kollwitzstraße</td>\n",
       "      <td>77</td>\n",
       "      <td>10435.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Mo-Th 08:00-19:00; Fr 08:00-12:00</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.zahnarztpraxis-hartfiel.de/</td>\n",
       "      <td>52.537547</td>\n",
       "      <td>13.418994</td>\n",
       "      <td>Kollwitzstraße 77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  osm_type     osm_id                 name     addr_street addr_housenumber  \\\n",
       "0     node  304183504              Unknown  Hönower Straße               75   \n",
       "1     node  313539258  Zahnzentrum Wedding    Müllerstraße              34a   \n",
       "2     node  325161442             A. Nejad             NaN              NaN   \n",
       "3     node  345236220    Dr. Beate Lengert  Kurfürstendamm              218   \n",
       "4     node  391394177      Serpil Hartfiel  Kollwitzstraße               77   \n",
       "\n",
       "   addr_postcode addr_city                                      opening_hours  \\\n",
       "0        12623.0    Berlin                                                NaN   \n",
       "1        13353.0    Berlin  Mo 09:00-19:00; Tu 09:00-18:00; We 09:00-17:00...   \n",
       "2            NaN    Berlin  Mo-Tu 09:00-19:00; We 09:00-14:00; Th 09:00-19...   \n",
       "3        10719.0    Berlin                                                NaN   \n",
       "4        10435.0    Berlin                  Mo-Th 08:00-19:00; Fr 08:00-12:00   \n",
       "\n",
       "  wheelchair         phone email                                  website  \\\n",
       "0    unknown           NaN   NaN                                      NaN   \n",
       "1        yes           NaN   NaN                                      NaN   \n",
       "2        yes  +49303619106   NaN                                      NaN   \n",
       "3    unknown           NaN   NaN          http://www.dr-beate-lengert.de/   \n",
       "4         no           NaN   NaN  https://www.zahnarztpraxis-hartfiel.de/   \n",
       "\n",
       "         lat        lon        address_full  \n",
       "0  52.511411  13.612096   Hönower Straße 75  \n",
       "1  52.548838  13.355305    Müllerstraße 34a  \n",
       "2  52.508843  13.180477                      \n",
       "3  52.502722  13.328137  Kurfürstendamm 218  \n",
       "4  52.537547  13.418994   Kollwitzstraße 77  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"berlin_dentists_clean.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe90c54e-9795-4ffc-a72c-7dd2e56ba378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8150333-5c6d-404e-a3cf-3a5a6ed6231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Downloading geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shapely\n",
      "  Downloading shapely-2.1.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting pyproj\n",
      "  Downloading pyproj-3.7.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (31 kB)\n",
      "Collecting fiona\n",
      "  Downloading fiona-1.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rtree in /opt/anaconda3/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.11.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.2.2)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from pyproj) (2025.8.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from fiona) (23.1.0)\n",
      "Requirement already satisfied: click~=8.0 in /opt/anaconda3/lib/python3.12/site-packages (from fiona) (8.1.7)\n",
      "Collecting click-plugins>=1.0 (from fiona)\n",
      "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting cligj>=0.5 (from fiona)\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.16.0)\n",
      "Downloading geopandas-1.1.1-py3-none-any.whl (338 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.4/338.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.1.1-cp312-cp312-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproj-3.7.2-cp312-cp312-macosx_14_0_arm64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fiona-1.10.1-cp312-cp312-macosx_11_0_arm64.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
      "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading pyogrio-0.11.1-cp312-cp312-macosx_12_0_arm64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely, pyproj, pyogrio, cligj, click-plugins, fiona, geopandas\n",
      "Successfully installed click-plugins-1.1.1.2 cligj-0.7.2 fiona-1.10.1 geopandas-1.1.1 pyogrio-0.11.1 pyproj-3.7.2 shapely-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas shapely pyproj fiona rtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eed83ced-f2fc-4af7-905d-f82cbe5496e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def get_bezirk(lat, lon):\n",
    "    key = (round(lat, 5), round(lon, 5))  # rounded to avoid duplicates\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), exactly_one=True, language='de')\n",
    "        sleep(1)\n",
    "        if location and \"address\" in location.raw:\n",
    "            address = location.raw[\"address\"]\n",
    "            bezirk = (\n",
    "                address.get(\"city_district\") or\n",
    "                address.get(\"borough\") or\n",
    "                address.get(\"county\")\n",
    "            )\n",
    "            cache[key] = bezirk\n",
    "            return bezirk\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73b6b4e0-e2ef-4ba2-bc17-d1eac3fdccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON downloaded as berlin_bezirksgeo.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://tsb-opendata.s3.eu-central-1.amazonaws.com/bezirksgrenzen/bezirksgrenzen.geojson\"\n",
    "resp = requests.get(url)\n",
    "with open(\"berlin_bezirksgeo.json\", \"wb\") as f:\n",
    "    f.write(resp.content)\n",
    "print(\"GeoJSON downloaded as berlin_bezirksgeo.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78663e18-a218-427b-bd5e-02f8b83c4999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/anaconda3/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (2.32.2)\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (0.11.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.2.2)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (3.7.2)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.16.0)\n",
      "Available columns in district GeoJSON: ['gml_id', 'Gemeinde_name', 'Gemeinde_schluessel', 'Land_name', 'Land_schluessel', 'Schluessel_gesamt', 'geometry']\n",
      "Available columns in U-Bahn dataset: ['osm_type', 'osm_id', 'name', 'addr_street', 'addr_housenumber', 'addr_postcode', 'addr_city', 'opening_hours', 'wheelchair', 'phone', 'email', 'website', 'lat', 'lon', 'address_full']\n",
      "✅ File saved as ubahn_with_districts.csv\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas requests\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Download district GeoJSON if it's not there\n",
    "geojson_path = \"berlin_bezirksgeo.json\"\n",
    "if not os.path.exists(geojson_path):\n",
    "    url = \"https://tsb-opendata.s3.eu-central-1.amazonaws.com/bezirksgrenzen/bezirksgrenzen.geojson\"\n",
    "    print(\"Downloading district boundaries...\")\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    with open(geojson_path, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "    print(\"Downloaded:\", geojson_path)\n",
    "\n",
    "# Load the GeoJSON\n",
    "districts = gpd.read_file(geojson_path)\n",
    "\n",
    "# Inspect the columns (to adjust names if needed)\n",
    "print(\"Available columns in district GeoJSON:\", districts.columns.tolist())\n",
    "\n",
    "# Load your existing U-Bahn dataset\n",
    "df = pd.read_csv(\"ubahn_with_neighborhoods.csv\")\n",
    "\n",
    "# Print column names to verify what's available\n",
    "print(\"Available columns in U-Bahn dataset:\", df.columns.tolist())\n",
    "\n",
    "# Convert to GeoDataFrame - use the correct column names from your dataset\n",
    "# Assuming your coordinates columns might be named differently, like 'lon'/'lat' or 'x'/'y'\n",
    "# Replace 'lon' and 'lat' with your actual column names\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]),  # Changed from longitude/latitude to lon/lat\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Ensure same CRS\n",
    "districts = districts.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Spatial join: assign each station to a district\n",
    "joined = gpd.sjoin(gdf, districts, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Rename relevant columns (adjust if GeoJSON names differ)\n",
    "joined = joined.rename(columns={\n",
    "    \"BEZIRK\": \"district\",\n",
    "    \"BEZIRKNR\": \"district_id\"\n",
    "})\n",
    "\n",
    "# Drop geometry\n",
    "result = joined.drop(columns=\"geometry\")\n",
    "\n",
    "# Save final file\n",
    "result.to_csv(\"ubahn_with_districts.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ File saved as ubahn_with_districts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e29e263-ac69-4adc-bd93-9d3ff0c8721d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osm_type</th>\n",
       "      <th>osm_id</th>\n",
       "      <th>name</th>\n",
       "      <th>addr_street</th>\n",
       "      <th>addr_housenumber</th>\n",
       "      <th>addr_postcode</th>\n",
       "      <th>addr_city</th>\n",
       "      <th>opening_hours</th>\n",
       "      <th>wheelchair</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>address_full</th>\n",
       "      <th>index_right</th>\n",
       "      <th>gml_id</th>\n",
       "      <th>Gemeinde_name</th>\n",
       "      <th>Gemeinde_schluessel</th>\n",
       "      <th>Land_name</th>\n",
       "      <th>Land_schluessel</th>\n",
       "      <th>Schluessel_gesamt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>node</td>\n",
       "      <td>304183504</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Hönower Straße</td>\n",
       "      <td>75</td>\n",
       "      <td>12623.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>52.511411</td>\n",
       "      <td>13.612096</td>\n",
       "      <td>Hönower Straße 75</td>\n",
       "      <td>6</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__7</td>\n",
       "      <td>Marzahn-Hellersdorf</td>\n",
       "      <td>10</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>node</td>\n",
       "      <td>313539258</td>\n",
       "      <td>Zahnzentrum Wedding</td>\n",
       "      <td>Müllerstraße</td>\n",
       "      <td>34a</td>\n",
       "      <td>13353.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Mo 09:00-19:00; Tu 09:00-18:00; We 09:00-17:00...</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>52.548838</td>\n",
       "      <td>13.355305</td>\n",
       "      <td>Müllerstraße 34a</td>\n",
       "      <td>9</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__10</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>node</td>\n",
       "      <td>325161442</td>\n",
       "      <td>A. Nejad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Mo-Tu 09:00-19:00; We 09:00-14:00; Th 09:00-19...</td>\n",
       "      <td>yes</td>\n",
       "      <td>+49303619106</td>\n",
       "      <td>...</td>\n",
       "      <td>52.508843</td>\n",
       "      <td>13.180477</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__8</td>\n",
       "      <td>Spandau</td>\n",
       "      <td>5</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>node</td>\n",
       "      <td>345236220</td>\n",
       "      <td>Dr. Beate Lengert</td>\n",
       "      <td>Kurfürstendamm</td>\n",
       "      <td>218</td>\n",
       "      <td>10719.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>52.502722</td>\n",
       "      <td>13.328137</td>\n",
       "      <td>Kurfürstendamm 218</td>\n",
       "      <td>1</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__2</td>\n",
       "      <td>Charlottenburg-Wilmersdorf</td>\n",
       "      <td>4</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>node</td>\n",
       "      <td>391394177</td>\n",
       "      <td>Serpil Hartfiel</td>\n",
       "      <td>Kollwitzstraße</td>\n",
       "      <td>77</td>\n",
       "      <td>10435.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Mo-Th 08:00-19:00; Fr 08:00-12:00</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>52.537547</td>\n",
       "      <td>13.418994</td>\n",
       "      <td>Kollwitzstraße 77</td>\n",
       "      <td>3</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__4</td>\n",
       "      <td>Pankow</td>\n",
       "      <td>3</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  osm_type     osm_id                 name     addr_street addr_housenumber  \\\n",
       "0     node  304183504              Unknown  Hönower Straße               75   \n",
       "1     node  313539258  Zahnzentrum Wedding    Müllerstraße              34a   \n",
       "2     node  325161442             A. Nejad             NaN              NaN   \n",
       "3     node  345236220    Dr. Beate Lengert  Kurfürstendamm              218   \n",
       "4     node  391394177      Serpil Hartfiel  Kollwitzstraße               77   \n",
       "\n",
       "   addr_postcode addr_city                                      opening_hours  \\\n",
       "0        12623.0    Berlin                                                NaN   \n",
       "1        13353.0    Berlin  Mo 09:00-19:00; Tu 09:00-18:00; We 09:00-17:00...   \n",
       "2            NaN    Berlin  Mo-Tu 09:00-19:00; We 09:00-14:00; Th 09:00-19...   \n",
       "3        10719.0    Berlin                                                NaN   \n",
       "4        10435.0    Berlin                  Mo-Th 08:00-19:00; Fr 08:00-12:00   \n",
       "\n",
       "  wheelchair         phone  ...        lat        lon        address_full  \\\n",
       "0    unknown           NaN  ...  52.511411  13.612096   Hönower Straße 75   \n",
       "1        yes           NaN  ...  52.548838  13.355305    Müllerstraße 34a   \n",
       "2        yes  +49303619106  ...  52.508843  13.180477                       \n",
       "3    unknown           NaN  ...  52.502722  13.328137  Kurfürstendamm 218   \n",
       "4         no           NaN  ...  52.537547  13.418994   Kollwitzstraße 77   \n",
       "\n",
       "   index_right                       gml_id               Gemeinde_name  \\\n",
       "0            6   s_wfs_alkis_bezirk.F176__7         Marzahn-Hellersdorf   \n",
       "1            9  s_wfs_alkis_bezirk.F176__10                       Mitte   \n",
       "2            7   s_wfs_alkis_bezirk.F176__8                     Spandau   \n",
       "3            1   s_wfs_alkis_bezirk.F176__2  Charlottenburg-Wilmersdorf   \n",
       "4            3   s_wfs_alkis_bezirk.F176__4                      Pankow   \n",
       "\n",
       "  Gemeinde_schluessel Land_name  Land_schluessel Schluessel_gesamt  \n",
       "0                  10    Berlin               11          11000010  \n",
       "1                   1    Berlin               11          11000001  \n",
       "2                   5    Berlin               11          11000005  \n",
       "3                   4    Berlin               11          11000004  \n",
       "4                   3    Berlin               11          11000003  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"ubahn_with_districts.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9047d68d-6551-465b-9f71-0606f61fcbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District file columns: ['gml_id', 'Gemeinde_name', 'Gemeinde_schluessel', 'Land_name', 'Land_schluessel', 'Schluessel_gesamt', 'geometry']\n",
      "U-Bahn dataset columns: ['osm_type', 'osm_id', 'name', 'addr_street', 'addr_housenumber', 'addr_postcode', 'addr_city', 'opening_hours', 'wheelchair', 'phone', 'email', 'website', 'lat', 'lon', 'address_full', 'index_right', 'gml_id', 'Gemeinde_name', 'Gemeinde_schluessel', 'Land_name', 'Land_schluessel', 'Schluessel_gesamt']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'index_right' cannot be a column name in the frames being joined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 41\u001b[0m\n\u001b[1;32m     36\u001b[0m districts \u001b[38;5;241m=\u001b[39m districts\u001b[38;5;241m.\u001b[39mto_crs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# 4. Spatial join: assign each station/dentist to a district\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m joined \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39msjoin(gdf, districts, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 5. Keep original dataset + enriched district info\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     46\u001b[0m keep_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m+\u001b[39m [\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistrict_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistrict_code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_offical_code\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopandas/tools/sjoin.py:119\u001b[0m, in \u001b[0;36msjoin\u001b[0;34m(left_df, right_df, how, predicate, lsuffix, rsuffix, distance, on_attribute, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m _basic_checks(left_df, right_df, how, lsuffix, rsuffix, on_attribute\u001b[38;5;241m=\u001b[39mon_attribute)\n\u001b[1;32m    115\u001b[0m indices \u001b[38;5;241m=\u001b[39m _geom_predicate_query(\n\u001b[1;32m    116\u001b[0m     left_df, right_df, predicate, distance, on_attribute\u001b[38;5;241m=\u001b[39mon_attribute\n\u001b[1;32m    117\u001b[0m )\n\u001b[0;32m--> 119\u001b[0m joined, _ \u001b[38;5;241m=\u001b[39m _frame_join(\n\u001b[1;32m    120\u001b[0m     left_df,\n\u001b[1;32m    121\u001b[0m     right_df,\n\u001b[1;32m    122\u001b[0m     indices,\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    124\u001b[0m     how,\n\u001b[1;32m    125\u001b[0m     lsuffix,\n\u001b[1;32m    126\u001b[0m     rsuffix,\n\u001b[1;32m    127\u001b[0m     predicate,\n\u001b[1;32m    128\u001b[0m     on_attribute\u001b[38;5;241m=\u001b[39mon_attribute,\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m joined\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopandas/tools/sjoin.py:461\u001b[0m, in \u001b[0;36m_frame_join\u001b[0;34m(left_df, right_df, indices, distances, how, lsuffix, rsuffix, predicate, on_attribute)\u001b[0m\n\u001b[1;32m    459\u001b[0m right_nlevels \u001b[38;5;241m=\u001b[39m right_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnlevels\n\u001b[1;32m    460\u001b[0m right_index_original \u001b[38;5;241m=\u001b[39m right_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m--> 461\u001b[0m right_df, right_column_names \u001b[38;5;241m=\u001b[39m _reset_index_with_suffix(right_df, rsuffix, left_df)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# if conflicting names in left and right, add suffix\u001b[39;00m\n\u001b[1;32m    464\u001b[0m left_column_names, right_column_names \u001b[38;5;241m=\u001b[39m _process_column_names_with_suffix(\n\u001b[1;32m    465\u001b[0m     left_column_names,\n\u001b[1;32m    466\u001b[0m     right_column_names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m     right_df,\n\u001b[1;32m    470\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopandas/tools/sjoin.py:280\u001b[0m, in \u001b[0;36m_reset_index_with_suffix\u001b[0;34m(df, suffix, other)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;66;03m# check new label will not be in other dataframe\u001b[39;00m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_label \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mor\u001b[39;00m new_label \u001b[38;5;129;01min\u001b[39;00m other\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m--> 280\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot be a column name in the frames being joined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m             )\n\u001b[1;32m    283\u001b[0m         column_names[i] \u001b[38;5;241m=\u001b[39m new_label\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_reset, pd\u001b[38;5;241m.\u001b[39mIndex(column_names)\n",
      "\u001b[0;31mValueError\u001b[0m: 'index_right' cannot be a column name in the frames being joined"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Load Bezirke polygons (already downloaded as berlin_bezirksgeo.json)\n",
    "# ------------------------------------------------------------------\n",
    "districts = gpd.read_file(\"berlin_bezirksgeo.json\")\n",
    "print(\"District file columns:\", districts.columns.tolist())\n",
    "\n",
    "# Rename German → English\n",
    "districts = districts.rename(columns={\n",
    "    \"gml_id\": \"district_id\",\n",
    "    \"Gemeinde_name\": \"district\",\n",
    "    \"Gemeinde_schluessel\": \"district_code\",\n",
    "    \"Land_name\": \"state_name\",\n",
    "    \"Land_schluessel\": \"state_code\",\n",
    "    \"Schluessel_gesamt\": \"full_offical_code\"\n",
    "})\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Load your existing U-Bahn dataset (dentists dataset)\n",
    "# ------------------------------------------------------------------\n",
    "df = pd.read_csv(\"ubahn_with_districts.csv\")\n",
    "print(\"U-Bahn dataset columns:\", df.columns.tolist())\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Convert to GeoDataFrame using lat/lon\n",
    "# ------------------------------------------------------------------\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Ensure CRS matches\n",
    "districts = districts.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Spatial join: assign each station/dentist to a district\n",
    "# ------------------------------------------------------------------\n",
    "joined = gpd.sjoin(gdf, districts, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Keep original dataset + enriched district info\n",
    "# ------------------------------------------------------------------\n",
    "keep_cols = list(df.columns) + [\n",
    "    \"district\", \"district_id\", \"district_code\",\n",
    "    \"state_name\", \"state_code\", \"full_offical_code\"\n",
    "]\n",
    "result = joined[keep_cols]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Save enriched dataset\n",
    "# ------------------------------------------------------------------\n",
    "result.to_csv(\"ubahn_with_districts.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ File saved as ubahn_with_districts.csv with district + codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e71042b-8aee-47a8-9616-ceb4f56196a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'index_right' cannot be a column name in the frames being joined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Your previous code remains the same until the spatial join\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 4. Spatial join: assign each station/dentist to a district\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Use suffixes to avoid conflicts\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m joined \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39msjoin(\n\u001b[1;32m      8\u001b[0m     gdf,\n\u001b[1;32m      9\u001b[0m     districts,\n\u001b[1;32m     10\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     predicate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithin\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Removed suffixes to keep original column names\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 5. Keep original dataset + enriched district info\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Now we can use the original column names\u001b[39;00m\n\u001b[1;32m     18\u001b[0m keep_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m+\u001b[39m [\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistrict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistrict_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistrict_code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_offical_code\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopandas/tools/sjoin.py:119\u001b[0m, in \u001b[0;36msjoin\u001b[0;34m(left_df, right_df, how, predicate, lsuffix, rsuffix, distance, on_attribute, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m _basic_checks(left_df, right_df, how, lsuffix, rsuffix, on_attribute\u001b[38;5;241m=\u001b[39mon_attribute)\n\u001b[1;32m    115\u001b[0m indices \u001b[38;5;241m=\u001b[39m _geom_predicate_query(\n\u001b[1;32m    116\u001b[0m     left_df, right_df, predicate, distance, on_attribute\u001b[38;5;241m=\u001b[39mon_attribute\n\u001b[1;32m    117\u001b[0m )\n\u001b[0;32m--> 119\u001b[0m joined, _ \u001b[38;5;241m=\u001b[39m _frame_join(\n\u001b[1;32m    120\u001b[0m     left_df,\n\u001b[1;32m    121\u001b[0m     right_df,\n\u001b[1;32m    122\u001b[0m     indices,\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    124\u001b[0m     how,\n\u001b[1;32m    125\u001b[0m     lsuffix,\n\u001b[1;32m    126\u001b[0m     rsuffix,\n\u001b[1;32m    127\u001b[0m     predicate,\n\u001b[1;32m    128\u001b[0m     on_attribute\u001b[38;5;241m=\u001b[39mon_attribute,\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m joined\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopandas/tools/sjoin.py:461\u001b[0m, in \u001b[0;36m_frame_join\u001b[0;34m(left_df, right_df, indices, distances, how, lsuffix, rsuffix, predicate, on_attribute)\u001b[0m\n\u001b[1;32m    459\u001b[0m right_nlevels \u001b[38;5;241m=\u001b[39m right_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnlevels\n\u001b[1;32m    460\u001b[0m right_index_original \u001b[38;5;241m=\u001b[39m right_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnames\n\u001b[0;32m--> 461\u001b[0m right_df, right_column_names \u001b[38;5;241m=\u001b[39m _reset_index_with_suffix(right_df, rsuffix, left_df)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# if conflicting names in left and right, add suffix\u001b[39;00m\n\u001b[1;32m    464\u001b[0m left_column_names, right_column_names \u001b[38;5;241m=\u001b[39m _process_column_names_with_suffix(\n\u001b[1;32m    465\u001b[0m     left_column_names,\n\u001b[1;32m    466\u001b[0m     right_column_names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m     right_df,\n\u001b[1;32m    470\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopandas/tools/sjoin.py:280\u001b[0m, in \u001b[0;36m_reset_index_with_suffix\u001b[0;34m(df, suffix, other)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;66;03m# check new label will not be in other dataframe\u001b[39;00m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_label \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mor\u001b[39;00m new_label \u001b[38;5;129;01min\u001b[39;00m other\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m--> 280\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot be a column name in the frames being joined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m             )\n\u001b[1;32m    283\u001b[0m         column_names[i] \u001b[38;5;241m=\u001b[39m new_label\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_reset, pd\u001b[38;5;241m.\u001b[39mIndex(column_names)\n",
      "\u001b[0;31mValueError\u001b[0m: 'index_right' cannot be a column name in the frames being joined"
     ]
    }
   ],
   "source": [
    "# Your previous code remains the same until the spatial join\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Spatial join: assign each station/dentist to a district\n",
    "# ------------------------------------------------------------------\n",
    "# Use suffixes to avoid conflicts\n",
    "joined = gpd.sjoin(\n",
    "    gdf,\n",
    "    districts,\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"  # Removed suffixes to keep original column names\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Keep original dataset + enriched district info\n",
    "# ------------------------------------------------------------------\n",
    "# Now we can use the original column names\n",
    "keep_cols = list(df.columns) + [\n",
    "    \"district\", \"district_id\", \"district_code\",\n",
    "    \"state_name\", \"state_code\", \"full_offical_code\"\n",
    "]\n",
    "\n",
    "# Check if columns exist before selecting them\n",
    "available_cols = [col for col in keep_cols if col in joined.columns]\n",
    "result = joined[available_cols]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Save enriched dataset\n",
    "# ------------------------------------------------------------------\n",
    "result.to_csv(\"ubahn_with_districts.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ File saved as ubahn_with_districts.csv with district + codes (no German columns)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ae412f1-e1f9-430f-b14a-701631f10448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File saved as ubahn_with_districts.csv with district + codes\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 4. Spatial join: assign each station/dentist to a district\n",
    "# ------------------------------------------------------------------\n",
    "# Use op_prefix parameter to avoid column name conflicts\n",
    "joined = gpd.sjoin(gdf, districts, how=\"left\", predicate=\"within\", lsuffix=\"_left\", rsuffix=\"_right\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Keep original dataset + enriched district info\n",
    "# ------------------------------------------------------------------\n",
    "keep_cols = list(df.columns) + [\n",
    "    \"district\", \"district_id\", \"district_code\",\n",
    "    \"state_name\", \"state_code\", \"full_offical_code\"\n",
    "]\n",
    "result = joined[keep_cols]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Save enriched dataset\n",
    "# ------------------------------------------------------------------\n",
    "result.to_csv(\"ubahn_with_districts.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ File saved as ubahn_with_districts.csv with district + codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "990eb23e-fa01-4ea8-9778-0b58cc5e3dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osm_type</th>\n",
       "      <th>osm_id</th>\n",
       "      <th>name</th>\n",
       "      <th>addr_street</th>\n",
       "      <th>addr_housenumber</th>\n",
       "      <th>addr_postcode</th>\n",
       "      <th>addr_city</th>\n",
       "      <th>opening_hours</th>\n",
       "      <th>wheelchair</th>\n",
       "      <th>phone</th>\n",
       "      <th>...</th>\n",
       "      <th>Gemeinde_schluessel</th>\n",
       "      <th>Land_name</th>\n",
       "      <th>Land_schluessel</th>\n",
       "      <th>Schluessel_gesamt</th>\n",
       "      <th>district</th>\n",
       "      <th>district_id</th>\n",
       "      <th>district_code</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_code</th>\n",
       "      <th>full_offical_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>node</td>\n",
       "      <td>304183504</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Hönower Straße</td>\n",
       "      <td>75</td>\n",
       "      <td>12623.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000010</td>\n",
       "      <td>Marzahn-Hellersdorf</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__7</td>\n",
       "      <td>10</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>node</td>\n",
       "      <td>313539258</td>\n",
       "      <td>Zahnzentrum Wedding</td>\n",
       "      <td>Müllerstraße</td>\n",
       "      <td>34a</td>\n",
       "      <td>13353.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Mo 09:00-19:00; Tu 09:00-18:00; We 09:00-17:00...</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000001</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__10</td>\n",
       "      <td>1</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>node</td>\n",
       "      <td>325161442</td>\n",
       "      <td>A. Nejad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Mo-Tu 09:00-19:00; We 09:00-14:00; Th 09:00-19...</td>\n",
       "      <td>yes</td>\n",
       "      <td>+49303619106</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000005</td>\n",
       "      <td>Spandau</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__8</td>\n",
       "      <td>5</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>node</td>\n",
       "      <td>345236220</td>\n",
       "      <td>Dr. Beate Lengert</td>\n",
       "      <td>Kurfürstendamm</td>\n",
       "      <td>218</td>\n",
       "      <td>10719.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000004</td>\n",
       "      <td>Charlottenburg-Wilmersdorf</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__2</td>\n",
       "      <td>4</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>node</td>\n",
       "      <td>391394177</td>\n",
       "      <td>Serpil Hartfiel</td>\n",
       "      <td>Kollwitzstraße</td>\n",
       "      <td>77</td>\n",
       "      <td>10435.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Mo-Th 08:00-19:00; Fr 08:00-12:00</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000003</td>\n",
       "      <td>Pankow</td>\n",
       "      <td>s_wfs_alkis_bezirk.F176__4</td>\n",
       "      <td>3</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>11000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  osm_type     osm_id                 name     addr_street addr_housenumber  \\\n",
       "0     node  304183504              Unknown  Hönower Straße               75   \n",
       "1     node  313539258  Zahnzentrum Wedding    Müllerstraße              34a   \n",
       "2     node  325161442             A. Nejad             NaN              NaN   \n",
       "3     node  345236220    Dr. Beate Lengert  Kurfürstendamm              218   \n",
       "4     node  391394177      Serpil Hartfiel  Kollwitzstraße               77   \n",
       "\n",
       "   addr_postcode addr_city                                      opening_hours  \\\n",
       "0        12623.0    Berlin                                                NaN   \n",
       "1        13353.0    Berlin  Mo 09:00-19:00; Tu 09:00-18:00; We 09:00-17:00...   \n",
       "2            NaN    Berlin  Mo-Tu 09:00-19:00; We 09:00-14:00; Th 09:00-19...   \n",
       "3        10719.0    Berlin                                                NaN   \n",
       "4        10435.0    Berlin                  Mo-Th 08:00-19:00; Fr 08:00-12:00   \n",
       "\n",
       "  wheelchair         phone  ... Gemeinde_schluessel Land_name  \\\n",
       "0    unknown           NaN  ...                  10    Berlin   \n",
       "1        yes           NaN  ...                   1    Berlin   \n",
       "2        yes  +49303619106  ...                   5    Berlin   \n",
       "3    unknown           NaN  ...                   4    Berlin   \n",
       "4         no           NaN  ...                   3    Berlin   \n",
       "\n",
       "   Land_schluessel  Schluessel_gesamt                    district  \\\n",
       "0               11           11000010         Marzahn-Hellersdorf   \n",
       "1               11           11000001                       Mitte   \n",
       "2               11           11000005                     Spandau   \n",
       "3               11           11000004  Charlottenburg-Wilmersdorf   \n",
       "4               11           11000003                      Pankow   \n",
       "\n",
       "                   district_id district_code state_name  state_code  \\\n",
       "0   s_wfs_alkis_bezirk.F176__7            10     Berlin          11   \n",
       "1  s_wfs_alkis_bezirk.F176__10             1     Berlin          11   \n",
       "2   s_wfs_alkis_bezirk.F176__8             5     Berlin          11   \n",
       "3   s_wfs_alkis_bezirk.F176__2             4     Berlin          11   \n",
       "4   s_wfs_alkis_bezirk.F176__4             3     Berlin          11   \n",
       "\n",
       "  full_offical_code  \n",
       "0          11000010  \n",
       "1          11000001  \n",
       "2          11000005  \n",
       "3          11000004  \n",
       "4          11000003  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"ubahn_with_districts.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5afc160-7668-44a8-ad32-048cc5deb598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
