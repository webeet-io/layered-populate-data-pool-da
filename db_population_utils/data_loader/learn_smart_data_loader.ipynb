{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "733a7b31",
      "metadata": {
        "id": "733a7b31"
      },
      "source": [
        "# ðŸŽ¯ Learn to Build SmartAutoDataLoader\n",
        "## Step-by-Step Programming Tutorial\n",
        "\n",
        "**Welcome to your programming journey!** ðŸš€\n",
        "\n",
        "This notebook will teach you how to build a professional data loader from scratch. Each section contains:\n",
        "- ðŸ“ **Clear explanations** of what each function should do\n",
        "- ðŸ”§ **Empty functions** for you to implement\n",
        "- ðŸ’¡ **Tips and hints** to guide your thinking\n",
        "- âœ… **Learning goals** for each step\n",
        "\n",
        "### What You'll Build:\n",
        "A **SmartAutoDataLoader** that can:\n",
        "- ðŸ“Š Load CSV, Excel, and JSON files automatically\n",
        "- ðŸ” Detect file formats, encodings, and delimiters\n",
        "- ðŸ“… Find and parse datetime columns automatically\n",
        "- ðŸ“‹ Generate comprehensive loading reports\n",
        "- ðŸ’¾ Estimate memory usage for large files\n",
        "\n",
        "### Learning Philosophy:\n",
        "**\"The best way to learn programming is by writing code yourself!\"**\n",
        "\n",
        "Ready to start coding? Let's begin! ðŸŽ‰"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b33c6041",
      "metadata": {
        "id": "b33c6041"
      },
      "source": [
        "## ðŸ“š Section 1: Import Required Libraries\n",
        "\n",
        "**Learning Goal:** Understand which libraries we need and why\n",
        "\n",
        "### What This Section Does:\n",
        "Import all the essential Python libraries that our SmartAutoDataLoader will use:\n",
        "\n",
        "- **`pandas`** - For reading and manipulating data (CSV, Excel, JSON)\n",
        "- **`pathlib.Path`** - For handling file paths in a modern way\n",
        "- **`time`** - For measuring loading performance\n",
        "- **`re`** - For pattern matching (finding dates in text)\n",
        "- **`typing`** - For type hints (helps catch errors early)\n",
        "- **`dataclasses`** - For creating structured data containers\n",
        "\n",
        "### Your Task:\n",
        "Import all the necessary libraries in the cell below. Think about what each library will be used for!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a4d4364c",
      "metadata": {
        "id": "a4d4364c"
      },
      "outputs": [],
      "source": [
        "# TODO: Import all required libraries here\n",
        "# Hint: You'll need pandas, pathlib, time, re, typing, and dataclasses\n",
        "\n",
        "# Your imports go here:\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import time\n",
        "import re\n",
        "from typing import Optional, List, Union, Dict, Any\n",
        "from dataclasses import dataclass, field\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39354695",
      "metadata": {
        "id": "39354695"
      },
      "source": [
        "## ðŸ“Š Section 2: Create LoadReport Data Class\n",
        "\n",
        "**Learning Goal:** Learn how to create structured data containers\n",
        "\n",
        "### What This Section Does:\n",
        "Create a `LoadReport` class that stores comprehensive information about file loading results.\n",
        "\n",
        "### Key Concepts:\n",
        "- **`@dataclass`** - A decorator that automatically creates constructor and other methods\n",
        "- **Type hints** - Specify what type of data each field should contain\n",
        "- **Data organization** - Group related information together\n",
        "\n",
        "### Your Task:\n",
        "Create a LoadReport dataclass with these fields:\n",
        "- `file_path` (str) - Path to the loaded file\n",
        "- `file_size_mb` (float) - Size of file in megabytes\n",
        "- `detected_format` (str) - File format (csv, excel, json)\n",
        "- `detected_encoding` (str) - Character encoding used\n",
        "- `detected_delimiter` (str) - CSV delimiter character\n",
        "- `has_header` (bool) - Whether file has header row\n",
        "- `total_rows` (int) - Number of data rows\n",
        "- `total_columns` (int) - Number of columns\n",
        "- `column_info` (Dict[str, str]) - Information about each column\n",
        "- `date_columns_found` (List[str]) - Names of datetime columns\n",
        "- `date_formats_detected` (Dict[str, str]) - Date formats for each datetime column\n",
        "- `loading_time_seconds` (float) - How long loading took\n",
        "- `quality_score` (int) - Data quality score (0-100)\n",
        "- `warnings` (List[str]) - Any warnings during loading\n",
        "- `errors` (List[str]) - Any errors encountered\n",
        "- `success` (bool) - Whether loading was successful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "51e796d4",
      "metadata": {
        "id": "51e796d4"
      },
      "outputs": [],
      "source": [
        "# TODO: Create the LoadReport dataclass\n",
        "# Hint: Use @dataclass decorator and include all the fields listed above\n",
        "\n",
        "# Your LoadReport class goes here:\n",
        "@dataclass\n",
        "class LoadReport:\n",
        "  file_path: str\n",
        "  file_size_mb: float\n",
        "  detected_format: str\n",
        "  detected_encoding: str\n",
        "  detected_delimiter: str\n",
        "  has_header: bool\n",
        "  total_rows: int\n",
        "  total_columns: int\n",
        "  column_info: Dict[str, str]\n",
        "  date_columns_found: List[str]\n",
        "  date_formats_detected: Dict[str, str]\n",
        "  loading_time_seconds: float\n",
        "  quality_score: int\n",
        "  warnings: List[str]\n",
        "  errors: List[str]\n",
        "  success: bool\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1475392",
      "metadata": {
        "id": "c1475392"
      },
      "source": [
        "## ðŸ”§ Section 3: Initialize SmartAutoDataLoader Class\n",
        "\n",
        "**Learning Goal:** Learn how to create class constructors and instance variables\n",
        "\n",
        "### What This Section Does:\n",
        "Create the main SmartAutoDataLoader class with its constructor (`__init__` method).\n",
        "\n",
        "### Key Concepts:\n",
        "- **Class definition** - Creating a blueprint for objects\n",
        "- **Constructor (`__init__`)** - Method that runs when creating a new instance\n",
        "- **Instance variables (`self.variable`)** - Data that belongs to each instance\n",
        "- **Default parameters** - Providing sensible defaults for optional arguments\n",
        "\n",
        "### Your Task:\n",
        "Create the SmartAutoDataLoader class with:\n",
        "\n",
        "1. **Constructor parameters:**\n",
        "   - `verbose` (bool, default=True) - Whether to print progress messages\n",
        "\n",
        "2. **Instance variables:**\n",
        "   - `self.verbose` - Store the verbose setting\n",
        "   - `self.date_patterns` - List of regex patterns for detecting dates\n",
        "\n",
        "3. **Date patterns to include:**\n",
        "   - ISO format: `r'\\d{4}-\\d{2}-\\d{2}'` â†’ `'%Y-%m-%d'`\n",
        "   - EU format: `r'\\d{2}/\\d{2}/\\d{4}'` â†’ `'%d/%m/%Y'`\n",
        "   - German format: `r'\\d{2}\\.\\d{2}\\.\\d{4}'` â†’ `'%d.%m.%Y'`\n",
        "   - UK format: `r'\\d{2}-\\d{2}-\\d{4}'` â†’ `'%d-%m-%Y'`\n",
        "   - US format: `r'\\d{4}/\\d{2}/\\d{2}'` â†’ `'%Y/%m/%d'`\n",
        "\n",
        "4. **Print welcome message** if verbose is True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fe0567e5",
      "metadata": {
        "id": "fe0567e5"
      },
      "outputs": [],
      "source": [
        "# TODO: Create the SmartAutoDataLoader class with __init__ method\n",
        "# Hint: Store verbose setting and date patterns as instance variables\n",
        "\n",
        "class SmartAutoDataLoader:\n",
        "    \"\"\"Smart automatic data loader for CSV, Excel, and JSON files\"\"\"\n",
        "    def __init__(self, verbose: bool = True):\n",
        "        \"\"\"\n",
        "        Initialize the SmartAutoDataLoader\n",
        "\n",
        "        Args:\n",
        "            verbose: Whether to print progress messages\n",
        "        \"\"\"\n",
        "        # Your initialization code goes here:\n",
        "        self.verbose = verbose\n",
        "        self.date_patterns = [\n",
        "            (r'\\d{4}-\\d{2}-\\d{2}', '%Y-%m-%d'),      # ISO format\n",
        "            (r'\\d{2}/\\d{2}/\\d{4}', '%d/%m/%Y'),      # EU format\n",
        "            (r'\\d{2}\\.\\d{2}\\.\\d{4}', '%d.%m.%Y'),    # German format\n",
        "            (r'\\d{2}-\\d{2}-\\d{4}', '%d-%m-%Y'),      # UK format\n",
        "            (r'\\d{4}/\\d{2}/\\d{2}', '%Y/%m/%d'),      # US format\n",
        "        ]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"ðŸŽ¯ SmartAutoDataLoader  initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8b4b4fa",
      "metadata": {
        "id": "f8b4b4fa"
      },
      "source": [
        "## ðŸ” Section 4: Implement Format Detection\n",
        "\n",
        "**Learning Goal:** Learn how to analyze file extensions and make decisions\n",
        "\n",
        "### What This Section Does:\n",
        "Create a method that automatically detects the file format based on the file extension.\n",
        "\n",
        "### Key Concepts:\n",
        "- **File extensions** - The part after the dot in filenames (.csv, .xlsx, .json)\n",
        "- **Dictionary mapping** - Associating extensions with format names\n",
        "- **Default values** - What to return when extension is unknown\n",
        "- **String methods** - Using `.lower()` and `.suffix` for consistent handling\n",
        "\n",
        "### Business Logic:\n",
        "**Priority System:**\n",
        "- CSV/TSV/TXT â†’ \"csv\" (95% priority - CRITICAL)\n",
        "- XLSX/XLS â†’ \"excel\" (80% priority - HIGH)  \n",
        "- JSON â†’ \"json\" (70% priority - MEDIUM)\n",
        "\n",
        "### Your Task:\n",
        "Add this method to your SmartAutoDataLoader class:\n",
        "\n",
        "```python\n",
        "def detect_format(self, source: str) -> str:\n",
        "```\n",
        "\n",
        "**Requirements:**\n",
        "1. Take a file path as input\n",
        "2. Extract the file extension (hint: use `Path(source).suffix.lower()`)\n",
        "3. Map extensions to format names using a dictionary\n",
        "4. Return the detected format (\"csv\", \"excel\", or \"json\")\n",
        "5. Default to \"csv\" for unknown extensions\n",
        "6. Print the result if verbose mode is on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "956a00ff",
      "metadata": {
        "id": "956a00ff"
      },
      "outputs": [],
      "source": [
        "# TODO: Add this method to your SmartAutoDataLoader class\n",
        "# Hint: Use Path(source).suffix.lower() to get the file extension\n",
        "\n",
        "def detect_format(self, source: str) -> str:\n",
        "    \"\"\"\n",
        "    Detect file format based on extension\n",
        "\n",
        "    Args:\n",
        "        source: Path to the file\n",
        "\n",
        "    Returns:\n",
        "        Format name: 'csv', 'excel', or 'json'\n",
        "    \"\"\"\n",
        "    path = Path(source)\n",
        "    suffix = path.suffix.lower()\n",
        "\n",
        "    format_map = {\n",
        "        '.csv': 'csv',\n",
        "        '.tsv': 'csv',  # Treat TSV as CSV for simplicity\n",
        "        '.txt': 'csv',  # Treat TXT as CSV for simplicity\n",
        "        '.xlsm': 'excel',\n",
        "        '.xlsx': 'excel',\n",
        "        '.xls': 'excel',\n",
        "        '.json': 'json',\n",
        "    }\n",
        "    detected = format_map.get(suffix, 'csv') # Default to CSV if not recognized\n",
        "    if self.verbose:\n",
        "        print(f\"ðŸ” Detected format: {detected} for file: {source}\")\n",
        "\n",
        "    return detected\n",
        "\n",
        "\n",
        "# Tip: Create a dictionary mapping extensions like {'.csv': 'csv', '.xlsx': 'excel', etc.}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9cebaf9",
      "metadata": {
        "id": "d9cebaf9"
      },
      "source": [
        "## ðŸ”¤ Section 5: Implement Encoding Detection\n",
        "\n",
        "**Learning Goal:** Learn how to handle different text encodings robustly\n",
        "\n",
        "### What This Section Does:\n",
        "Create a method that automatically detects the text encoding of a file by trying common encodings.\n",
        "\n",
        "### Key Concepts:\n",
        "- **Text encoding** - How text characters are stored as bytes (UTF-8, Latin-1, etc.)\n",
        "- **Try-except blocks** - Handling errors gracefully\n",
        "- **File reading** - Opening and reading file contents\n",
        "- **UnicodeDecodeError** - What happens when encoding is wrong\n",
        "\n",
        "### Why This Matters:\n",
        "Files can be saved in different encodings. Using the wrong encoding causes garbled text or errors. We need to detect the correct encoding automatically.\n",
        "\n",
        "### Your Task:\n",
        "Add this method to your SmartAutoDataLoader class:\n",
        "\n",
        "```python\n",
        "def detect_encoding(self, source: str) -> str:\n",
        "```\n",
        "\n",
        "**Requirements:**\n",
        "1. Try these encodings in order: ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
        "2. For each encoding, try to read the first 1024 characters of the file\n",
        "3. If reading succeeds without errors, return that encoding\n",
        "4. If all encodings fail, return 'utf-8' as fallback\n",
        "5. Print the detected encoding if verbose mode is on\n",
        "\n",
        "**Algorithm:**\n",
        "```python\n",
        "for encoding in encodings_to_try:\n",
        "    try:\n",
        "        # Try to read file with this encoding\n",
        "        # If successful, return the encoding\n",
        "    except UnicodeDecodeError:\n",
        "        # Try next encoding\n",
        "        continue\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3c23e54f",
      "metadata": {
        "id": "3c23e54f"
      },
      "outputs": [],
      "source": [
        "# TODO: Add this method to your SmartAutoDataLoader class\n",
        "# Hint: Use a for loop with try-except to test each encoding\n",
        "\n",
        "def detect_encoding(self, source: str) -> str:\n",
        "    \"\"\"\n",
        "    Detect file encoding by trying common encodings\n",
        "\n",
        "    Args:\n",
        "        source: Path to the file\n",
        "\n",
        "    Returns:\n",
        "        Detected encoding name\n",
        "    \"\"\"\n",
        "    encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1', 'utf-16', 'utf-8-sig', 'utf-32', 'utf-8-sig', 'utf-16-le', 'utf-16-be', 'utf-8-sig', 'utf-16-be']\n",
        "\n",
        "    for encoding in encodings_to_try:\n",
        "        try:\n",
        "            with open(source, 'r', encoding=encoding) as f:\n",
        "                f.read(1024)\n",
        "            if self.verbose:\n",
        "                print(f\"ðŸ”¤ Encoding detected: {encoding}\")\n",
        "            return encoding\n",
        "        except UnicodeDecodeError:\n",
        "          continue\n",
        "    return 'utf-8' #Fallback\n",
        "    pass\n",
        "\n",
        "# Tip: Use \"with open(source, 'r', encoding=encoding) as f: f.read(1024)\" to test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa443f03",
      "metadata": {
        "id": "aa443f03"
      },
      "source": [
        "## ðŸ“‹ Section 6: Implement CSV Delimiter Sniffing\n",
        "\n",
        "**Learning Goal:** Learn how to analyze text content to extract patterns\n",
        "\n",
        "### What This Section Does:\n",
        "Create a helper method that analyzes the first line of a CSV file to detect what character is used as the delimiter (comma, semicolon, tab, etc.).\n",
        "\n",
        "### Key Concepts:\n",
        "- **Delimiter** - The character that separates values in CSV files\n",
        "- **String analysis** - Counting character occurrences\n",
        "- **Dictionary operations** - Finding the key with maximum value\n",
        "- **Internal methods** - Methods that start with `_` (private/helper methods)\n",
        "\n",
        "### Common CSV Delimiters:\n",
        "- `,` (comma) - Most common, used in English locales\n",
        "- `;` (semicolon) - Common in European locales  \n",
        "- `\\t` (tab) - Used in TSV (Tab-Separated Values) files\n",
        "- `|` (pipe) - Less common but sometimes used\n",
        "\n",
        "### Your Task:\n",
        "Add this **internal helper method** to your SmartAutoDataLoader class:\n",
        "\n",
        "```python\n",
        "def _sniff_delimiter(self, path: Path, encoding: str) -> str:\n",
        "```\n",
        "\n",
        "**Requirements:**\n",
        "1. Read the first line of the file using the provided encoding\n",
        "2. Count how many times each potential delimiter appears in that line\n",
        "3. Return the delimiter that appears most frequently\n",
        "4. If no delimiters are found, return comma (`,`) as default\n",
        "5. Handle any file reading errors gracefully\n",
        "\n",
        "**Algorithm:**\n",
        "```python\n",
        "delimiters = [',', ';', '\\t', '|']\n",
        "counts = {delimiter: first_line.count(delimiter) for delimiter in delimiters}\n",
        "return delimiter_with_highest_count\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9358b3a6",
      "metadata": {
        "id": "9358b3a6"
      },
      "outputs": [],
      "source": [
        "# TODO: Add this INTERNAL helper method to your SmartAutoDataLoader class\n",
        "# Hint: Use max(counts, key=counts.get) to find the delimiter with highest count\n",
        "\n",
        "def _sniff_delimiter(self, path: Path, encoding: str) -> str:\n",
        "    \"\"\"\n",
        "    Internal method: Detect CSV delimiter by analyzing first line\n",
        "\n",
        "    Args:\n",
        "        path: Path object for the file\n",
        "        encoding: Encoding to use for reading\n",
        "\n",
        "    Returns:\n",
        "        Most likely delimiter character\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(path, 'r', encoding=encoding) as f:\n",
        "            first_line = f.readline()\n",
        "\n",
        "        delimiters = [',', ';', '\\t', '|']\n",
        "        counts = {delimiter: first_line.count(delimiter) for delimiter in delimiters}\n",
        "        return max(counts, key=counts.get) if max(counts.values()) > 0 else ','\n",
        "    except Exception:\n",
        "        return ','\n",
        "\n",
        "# Tip: Count occurrences of [',', ';', '\\t', '|'] in the first line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9dddee5",
      "metadata": {
        "id": "d9dddee5"
      },
      "source": [
        "## ðŸ”§ Section 7: Implement CSV Parameter Detection\n",
        "\n",
        "**Learning Goal:** Learn how to combine multiple detection functions\n",
        "\n",
        "### What This Section Does:\n",
        "Create a method that combines encoding and delimiter detection into a comprehensive CSV parameter detection function.\n",
        "\n",
        "### Key Concepts:\n",
        "- **Function composition** - Using one function's output as another's input\n",
        "- **Dictionary returns** - Returning structured data as dictionaries\n",
        "- **Method calling** - Using `self.method_name()` to call other methods in the same class\n",
        "\n",
        "### Your Task:\n",
        "Add this method to your SmartAutoDataLoader class:\n",
        "\n",
        "```python\n",
        "def sniff_csv_params(self, source: str) -> Dict[str, Any]:\n",
        "```\n",
        "\n",
        "**Requirements:**\n",
        "1. Call `self.detect_encoding(source)` to get the encoding\n",
        "2. Call `self._sniff_delimiter(Path(source), encoding)` to get the delimiter\n",
        "3. Return a dictionary with detected parameters\n",
        "4. Print the results if verbose mode is on\n",
        "\n",
        "**Return Dictionary Structure:**\n",
        "```python\n",
        "{\n",
        "    'delimiter': detected_delimiter,\n",
        "    'encoding': detected_encoding,\n",
        "    'has_header': True  # Assume files have headers for now\n",
        "}\n",
        "```\n",
        "\n",
        "This method brings together your encoding and delimiter detection into one convenient function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9b6b1372",
      "metadata": {
        "id": "9b6b1372"
      },
      "outputs": [],
      "source": [
        "# TODO: Add this method to your SmartAutoDataLoader class\n",
        "# Hint: Call your other detection methods and combine results\n",
        "\n",
        "def sniff_csv_params(self, source: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Detect comprehensive CSV parameters\n",
        "\n",
        "    Args:\n",
        "        source: Path to the CSV file\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with detected parameters\n",
        "    \"\"\"\n",
        "    # Your CSV parameter detection code goes here:\n",
        "    pass\n",
        "\n",
        "# Tip: Use self.detect_encoding() and self._sniff_delimiter() methods you created"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23ce99a9",
      "metadata": {
        "id": "23ce99a9"
      },
      "source": [
        "## ðŸ“… Section 8: Implement DateTime Parsing\n",
        "\n",
        "**Learning Goal:** Learn how to detect and convert datetime patterns in data\n",
        "\n",
        "### What This Section Does:\n",
        "Create a method that automatically finds columns containing dates and converts them to proper datetime format.\n",
        "\n",
        "### Key Concepts:\n",
        "- **Regular expressions (regex)** - Pattern matching for finding dates in text\n",
        "- **pandas datetime conversion** - Using `pd.to_datetime()` to convert strings to dates\n",
        "- **Data sampling** - Looking at a few rows to determine column patterns\n",
        "- **Data type checking** - Using `df[col].dtype == 'object'` to find text columns\n",
        "\n",
        "### Your Task:\n",
        "Add this method to your SmartAutoDataLoader class:\n",
        "\n",
        "```python\n",
        "def parse_datetimes(self, df: 'pd.DataFrame') -> 'pd.DataFrame':\n",
        "```\n",
        "\n",
        "**Requirements:**\n",
        "1. Create a copy of the input DataFrame\n",
        "2. Initialize an empty list to track found date columns\n",
        "3. For each column in the DataFrame:\n",
        "   - Skip non-text columns (only check `object` dtype)\n",
        "   - Take a sample of 10 non-null values\n",
        "   - Check each date pattern from `self.date_patterns`\n",
        "   - If >50% of sample values match a pattern, convert the column\n",
        "4. Print results if verbose mode is on\n",
        "5. Return the modified DataFrame\n",
        "\n",
        "**Algorithm:**\n",
        "```python\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':  # Text columns only\n",
        "        sample = df[col].dropna().astype(str).head(10)\n",
        "        for pattern, date_format in self.date_patterns:\n",
        "            matches = sum(1 for val in sample if re.search(pattern, val))\n",
        "            if matches >= len(sample) * 0.5:  # 50% threshold\n",
        "                # Convert column to datetime\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "631bb648",
      "metadata": {
        "id": "631bb648"
      },
      "outputs": [],
      "source": [
        "# TODO: Add this method to your SmartAutoDataLoader class\n",
        "# Hint: Use re.search() to check patterns and pd.to_datetime() to convert\n",
        "\n",
        "def parse_datetimes(self, df: 'pd.DataFrame') -> 'pd.DataFrame':\n",
        "    \"\"\"\n",
        "    Automatically detect and parse datetime columns\n",
        "\n",
        "    Args:\n",
        "        df: Input DataFrame\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with datetime columns converted\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    # Your datetime parsing code goes here:\n",
        "    pass\n",
        "\n",
        "# Tip: Use try-except when calling pd.to_datetime() in case conversion fails"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97d3f4c4",
      "metadata": {
        "id": "97d3f4c4"
      },
      "source": [
        "## ðŸŽ¯ Section 9: Implement Universal Load Method\n",
        "\n",
        "**Learning Goal:** Learn how to create a main method that coordinates other methods\n",
        "\n",
        "### What This Section Does:\n",
        "Create the main `load()` method that automatically detects file format and calls the appropriate loading function.\n",
        "\n",
        "### Key Concepts:\n",
        "- **Method delegation** - Using one method to call other specialized methods\n",
        "- **Conditional logic** - Using if/elif/else to make decisions\n",
        "- **Error handling** - Raising appropriate errors for unsupported formats\n",
        "\n",
        "### Your Task:\n",
        "Add this **main method** to your SmartAutoDataLoader class:\n",
        "\n",
        "```python\n",
        "def load(self, source: str, **kwargs) -> 'pd.DataFrame':\n",
        "```\n",
        "\n",
        "**Requirements:**\n",
        "1. Print loading message with filename if verbose\n",
        "2. Call `self.detect_format(source)` to determine file type\n",
        "3. Based on detected format, call appropriate method:\n",
        "   - 'csv' or 'tsv' â†’ call `self.load_csv(source, **kwargs)`\n",
        "   - 'excel' â†’ call `self.load_excel(source, **kwargs)`  \n",
        "   - 'json' â†’ call `self.load_json(source, **kwargs)`\n",
        "4. Raise `ValueError` for unsupported formats\n",
        "5. Return the loaded DataFrame\n",
        "\n",
        "**Algorithm:**\n",
        "```python\n",
        "detected_format = self.detect_format(source)\n",
        "if detected_format in ['csv', 'tsv']:\n",
        "    return self.load_csv(source, **kwargs)\n",
        "elif detected_format == 'excel':\n",
        "    return self.load_excel(source, **kwargs)\n",
        "# ... etc\n",
        "```\n",
        "\n",
        "**Note:** You'll implement the specific loading methods (load_csv, load_excel, load_json) in the next sections!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ca5258a8",
      "metadata": {
        "id": "ca5258a8"
      },
      "outputs": [],
      "source": [
        "# TODO: Add this MAIN method to your SmartAutoDataLoader class\n",
        "# Hint: Use self.detect_format() then delegate to specific load methods\n",
        "\n",
        "def load(self, source: str, **kwargs) -> 'pd.DataFrame':\n",
        "    \"\"\"\n",
        "    Universal loading method - auto-detects format and delegates\n",
        "\n",
        "    Args:\n",
        "        source: Path to the file to load\n",
        "        **kwargs: Additional arguments to pass to specific loaders\n",
        "\n",
        "    Returns:\n",
        "        Loaded DataFrame\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    # Your universal loading code goes here:\n",
        "    pass\n",
        "\n",
        "# Tip: Use Path(source).name to get just the filename for logging"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "917e6874",
      "metadata": {
        "id": "917e6874"
      },
      "source": [
        "## ðŸ“Š Section 10: Implement CSV Loading\n",
        "\n",
        "**Learning Goal:** Learn how to use pandas to load CSV files with auto-detected parameters\n",
        "\n",
        "### What This Section Does:\n",
        "Create the specialized CSV loading method that uses your detection functions.\n",
        "\n",
        "### Your Task:\n",
        "Add this method to your SmartAutoDataLoader class:\n",
        "\n",
        "```python\n",
        "def load_csv(self, source: str, **kwargs) -> 'pd.DataFrame':\n",
        "```\n",
        "\n",
        "**Requirements:**\n",
        "1. Print loading message if verbose\n",
        "2. Auto-detect encoding using `self.detect_encoding(source)`\n",
        "3. Auto-detect delimiter using `self._sniff_delimiter(Path(source), encoding)`\n",
        "4. Load CSV using `pd.read_csv(source, encoding=encoding, sep=delimiter)`\n",
        "5. Auto-parse datetimes using `self.parse_datetimes(df)`\n",
        "6. Print success message with row/column count\n",
        "7. Return the processed DataFrame\n",
        "\n",
        "This method brings together all your detection work to load CSV files intelligently!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "33b68669",
      "metadata": {
        "id": "33b68669"
      },
      "outputs": [],
      "source": [
        "# TODO: Add this method to your SmartAutoDataLoader class\n",
        "\n",
        "def load_csv(self, source: str, **kwargs) -> 'pd.DataFrame':\n",
        "    \"\"\"\n",
        "    Load CSV files with auto-detected parameters\n",
        "\n",
        "    Args:\n",
        "        source: Path to CSV file\n",
        "        **kwargs: Additional pandas.read_csv arguments\n",
        "\n",
        "    Returns:\n",
        "        Loaded and processed DataFrame\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    # Your CSV loading code goes here:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "627f7c80",
      "metadata": {
        "id": "627f7c80"
      },
      "source": [
        "## ðŸ§ª Section 11: Test Your Implementation\n",
        "\n",
        "**Learning Goal:** Learn how to test and validate your code\n",
        "\n",
        "### What This Section Does:\n",
        "Create test cases to verify your SmartAutoDataLoader works correctly.\n",
        "\n",
        "### Your Task:\n",
        "Test your complete implementation:\n",
        "\n",
        "1. **Create an instance** of your SmartAutoDataLoader\n",
        "2. **Test format detection** with different file extensions\n",
        "3. **Test encoding detection** with a real file\n",
        "4. **Test the full loading process** with a sample file\n",
        "5. **Verify datetime parsing** is working\n",
        "6. **Check verbose logging** is providing useful information\n",
        "\n",
        "### Success Criteria:\n",
        "- âœ… No error messages during execution\n",
        "- âœ… Correct format detection for .csv, .xlsx, .json files\n",
        "- âœ… Successful file loading with proper DataFrame shape\n",
        "- âœ… Clear, helpful log messages\n",
        "- âœ… Automatic datetime conversion when applicable\n",
        "\n",
        "### Congratulations! ðŸŽ‰\n",
        "If your tests pass, you've successfully built a professional-grade data loader from scratch!\n",
        "\n",
        "**What You've Learned:**\n",
        "- Object-oriented programming with classes and methods\n",
        "- File handling and text encoding detection  \n",
        "- Data analysis with pandas\n",
        "- Regular expressions for pattern matching\n",
        "- Error handling with try-except blocks\n",
        "- Method composition and code organization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "90b06953",
      "metadata": {
        "id": "90b06953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5956a0f-e079-4834-96ef-b874bf3fd311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing SmartAutoDataLoader ===\n",
            "ðŸŽ‰ Ready to test your implementation!\n"
          ]
        }
      ],
      "source": [
        "# TODO: Test your SmartAutoDataLoader implementation\n",
        "\n",
        "# Test 1: Create an instance\n",
        "print(\"=== Testing SmartAutoDataLoader ===\")\n",
        "# loader = SmartAutoDataLoader(verbose=True)\n",
        "\n",
        "# Test 2: Test format detection\n",
        "# print(\"Testing format detection:\")\n",
        "# print(f\"CSV: {loader.detect_format('test.csv')}\")\n",
        "# print(f\"Excel: {loader.detect_format('test.xlsx')}\")\n",
        "# print(f\"JSON: {loader.detect_format('test.json')}\")\n",
        "\n",
        "# Test 3: Test full loading (replace with your actual file path)\n",
        "# df = loader.load(\"/path/to/your/test/file.csv\")\n",
        "# print(f\"Loaded DataFrame: {df.shape}\")\n",
        "# print(f\"Columns: {list(df.columns)}\")\n",
        "# print(f\"Data types:\\n{df.dtypes}\")\n",
        "\n",
        "print(\"ðŸŽ‰ Ready to test your implementation!\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}