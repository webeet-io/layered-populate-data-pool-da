{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da61b4c9",
   "metadata": {},
   "source": [
    "# Go to the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is part of the layered-populate-data-pool-da project.\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Simple path fix - go up one level to data_loader directory\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1903e40e",
   "metadata": {},
   "source": [
    "# CSV Loading TEST SmartAutoDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2da6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC: Check which methods are missing\n",
    "from smart_auto_data_loader import SmartAutoDataLoader\n",
    "\n",
    "loader = SmartAutoDataLoader()\n",
    "\n",
    "\n",
    "df = loader.load(\"/Users/svitlanakovalivska/layered-populate-data-pool-da/db_population_utils/data/test.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1195a",
   "metadata": {},
   "source": [
    "# Excel Loading TEST SmartAutoDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and test  Excel loading functionality\n",
    "from smart_auto_data_loader import SmartAutoDataLoader\n",
    "\n",
    "loader = SmartAutoDataLoader()\n",
    "df = loader.load(\"/Users/svitlanakovalivska/layered-populate-data-pool-da/db_population_utils/data/statistischer-bericht-auslaend-bevoelkerung-2010200247005.xlsx\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb13b5",
   "metadata": {},
   "source": [
    "# JSON Loading TEST SmartAutoDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_auto_data_loader import SmartAutoDataLoader\n",
    "\n",
    "loader = SmartAutoDataLoader()\n",
    "df = loader.load(\"/Users/svitlanakovalivska/layered-populate-data-pool-da/db_population_utils/data/KG_Export_Auftr√§ge.json\")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e664526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSIS: Why still only 22 columns?\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_file = \"/Users/svitlanakovalivska/layered-populate-data-pool-da/db_population_utils/data/KG_Export_Auftr√§ge.json\"\n",
    "\n",
    "print(\"=== üîç JSON FLATTENING DIAGNOSIS ===\")\n",
    "\n",
    "# Load raw data\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "print(f\"Source data: {len(raw_data)} records\")\n",
    "first_item = raw_data[0]\n",
    "workflow_steps = first_item.get('workflowSteps', [])\n",
    "print(f\"workflowSteps: {len(workflow_steps)} elements\")\n",
    "\n",
    "if workflow_steps:\n",
    "    input_rows = workflow_steps[0].get('inputRows', [])\n",
    "    print(f\"inputRows in first step: {len(input_rows)} elements\")\n",
    "\n",
    "# Test pandas normalize\n",
    "df_pandas = pd.json_normalize(raw_data, sep='_', max_level=None)\n",
    "print(f\"pandas.json_normalize: {df_pandas.shape}\")\n",
    "\n",
    "# Deep flattening\n",
    "def deep_flatten(data, sep='_', prefix=''):\n",
    "    result = {}\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            new_key = f\"{prefix}{sep}{key}\" if prefix else key\n",
    "            if isinstance(value, dict):\n",
    "                result.update(deep_flatten(value, sep, new_key))\n",
    "            elif isinstance(value, list):\n",
    "                if value and isinstance(value[0], dict):\n",
    "                    for i, item in enumerate(value):\n",
    "                        result.update(deep_flatten(item, sep, f\"{new_key}_{i}\"))\n",
    "                else:\n",
    "                    result[new_key] = str(value) if value else ''\n",
    "            else:\n",
    "                result[new_key] = value\n",
    "    return result\n",
    "\n",
    "flattened_records = [deep_flatten(item) for item in raw_data]\n",
    "df_deep = pd.DataFrame(flattened_records)\n",
    "print(f\"Deep flattening: {df_deep.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7113e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison results\n",
    "print(f\"‚úÖ Deep flattening gave {df_deep.shape[1]} columns!\")\n",
    "print(f\"‚ùå pandas.json_normalize gave only {df_pandas.shape[1]} columns\")\n",
    "\n",
    "workflow_cols = [col for col in df_deep.columns if 'workflow' in col.lower()]\n",
    "input_cols = [col for col in df_deep.columns if 'input' in col.lower()]\n",
    "\n",
    "print(f\"\\nColumns with 'workflow': {len(workflow_cols)}\")\n",
    "print(f\"Columns with 'input': {len(input_cols)}\")\n",
    "\n",
    "if workflow_cols:\n",
    "    print(\"Workflow column examples:\", workflow_cols[:3])\n",
    "\n",
    "print(f\"\\nüí° CONCLUSION:\")\n",
    "print(f\"Proper flattening gives {df_deep.shape[1]} columns instead of 22\")\n",
    "print(f\"Need to replace pd.json_normalize with deep_flatten in SmartAutoDataLoader!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if smart methods were added to SmartAutoDataLoader\n",
    "import importlib\n",
    "import smart_auto_data_loader\n",
    "importlib.reload(smart_auto_data_loader)\n",
    "\n",
    "from smart_auto_data_loader import SmartAutoDataLoader\n",
    "\n",
    "print(\"=== üîç CHECKING SMART METHODS ===\")\n",
    "\n",
    "loader = SmartAutoDataLoader(verbose=True)\n",
    "\n",
    "# Check if the new methods exist\n",
    "methods_to_check = [\n",
    "    '_analyze_json_complexity',\n",
    "    '_smart_deep_flatten_json'\n",
    "]\n",
    "\n",
    "for method in methods_to_check:\n",
    "    has_method = hasattr(loader, method)\n",
    "    print(f\"Has {method}: {has_method}\")\n",
    "\n",
    "# If methods don't exist, show current load_json parameters\n",
    "import inspect\n",
    "try:\n",
    "    signature = inspect.signature(loader.load_json)\n",
    "    print(f\"\\nCurrent load_json parameters: {list(signature.parameters.keys())}\")\n",
    "    \n",
    "    # Check for auto_deep_flatten parameter\n",
    "    if 'auto_deep_flatten' in signature.parameters:\n",
    "        print(\"‚úÖ load_json has auto_deep_flatten parameter\")\n",
    "    else:\n",
    "        print(\"‚ùå load_json missing auto_deep_flatten parameter\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Cannot inspect load_json: {e}\")\n",
    "\n",
    "# Test simple loading until methods are added\n",
    "print(f\"\\n=== üß™ TESTING CURRENT FUNCTIONALITY ===\")\n",
    "try:\n",
    "    df_test = loader.load(\"/Users/svitlanakovalivska/layered-populate-data-pool-da/db_population_utils/data/KG_Export_Auftr√§ge.json\")\n",
    "    print(f\"Current result: {df_test.shape}\")\n",
    "    \n",
    "    if df_test.shape[1] > 400:\n",
    "        print(\"üéâ SUCCESS! Smart flattening is working!\")\n",
    "    else:\n",
    "        print(\"üìù NOTE: Still using basic flattening, need to add smart methods to file\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during testing: {e}\")\n",
    "\n",
    "print(f\"\\nüí° NEXT STEPS:\")\n",
    "print(f\"1. Add _analyze_json_complexity method to smart_auto_data_loader.py\")\n",
    "print(f\"2. Add _smart_deep_flatten_json method to smart_auto_data_loader.py\") \n",
    "print(f\"3. Update load_json method with auto_deep_flatten parameter\")\n",
    "print(f\"4. Restart kernel and test again\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
