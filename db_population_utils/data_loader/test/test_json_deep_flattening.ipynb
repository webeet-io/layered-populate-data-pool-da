{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cabed4",
   "metadata": {},
   "source": [
    "# Test Deep JSON Flattening for KG_Export_AuftrÃ¤ge.json\n",
    "\n",
    "This notebook tests proper deep flattening of the complex JSON structure to extract all nested workflow and input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cbc277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” JSON Deep Flattening Test\n",
      "==================================================\n",
      "âœ… File found: icecreamshop.json\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add data_loader to path\n",
    "sys.path.append('.')\n",
    "\n",
    "print(\"ğŸ” JSON Deep Flattening Test\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# File path\n",
    "json_file = \"/Users/svitlanakovalivska/layered-populate-data-pool-da/db_population_utils/data/icecreamshop.json\"\n",
    "\n",
    "# Check if file exists\n",
    "if Path(json_file).exists():\n",
    "    print(f\"âœ… File found: {Path(json_file).name}\")\n",
    "else:\n",
    "    print(f\"âŒ File not found: {json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a673d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ“‹ JSON STRUCTURE ANALYSIS ===\n",
      "ğŸ“Š Root structure: <class 'list'>\n",
      "ğŸ“Š Number of records: 2028\n",
      "ğŸ“Š Top-level keys (5): ['event_timestamp', 'user_id', 'item', 'price', 'quantity']\n",
      "\n",
      "ğŸ”¸ workflowSteps: 0 elements\n"
     ]
    }
   ],
   "source": [
    "# Load and analyze JSON structure\n",
    "print(\"=== ğŸ“‹ JSON STRUCTURE ANALYSIS ===\")\n",
    "\n",
    "with open(json_file, 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "print(f\"ğŸ“Š Root structure: {type(raw_data)}\")\n",
    "print(f\"ğŸ“Š Number of records: {len(raw_data)}\")\n",
    "\n",
    "# Analyze first record\n",
    "first_item = raw_data[0]\n",
    "print(f\"ğŸ“Š Top-level keys ({len(first_item)}): {list(first_item.keys())}\")\n",
    "\n",
    "# Analyze workflowSteps\n",
    "workflow_steps = first_item.get('workflowSteps', [])\n",
    "print(f\"\\nğŸ”¸ workflowSteps: {len(workflow_steps)} elements\")\n",
    "\n",
    "if workflow_steps:\n",
    "    first_step = workflow_steps[0]\n",
    "    step_keys = list(first_step.keys())\n",
    "    print(f\"ğŸ”¸ First step keys ({len(step_keys)}): {step_keys}\")\n",
    "    \n",
    "    # Analyze inputRows\n",
    "    input_rows = first_step.get('inputRows', [])\n",
    "    print(f\"ğŸ”¸ inputRows in first step: {len(input_rows)} elements\")\n",
    "    \n",
    "    if input_rows:\n",
    "        first_input = input_rows[0]\n",
    "        input_keys = list(first_input.keys())\n",
    "        print(f\"ğŸ”¸ First input keys ({len(input_keys)}): {input_keys}\")\n",
    "        \n",
    "        # Check for dropdown options\n",
    "        dropdown_options = first_input.get('dropdownOptions', [])\n",
    "        if dropdown_options:\n",
    "            print(f\"ğŸ”¸ Dropdown options: {len(dropdown_options)} items\")\n",
    "            if isinstance(dropdown_options[0], dict):\n",
    "                print(f\"ğŸ”¸ Dropdown structure: {list(dropdown_options[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec08462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ğŸ§ª FLATTENING COMPARISON ===\n",
      "1ï¸âƒ£ Testing pandas.json_normalize...\n",
      "   Result: (2028, 5)\n",
      "2ï¸âƒ£ Testing deep flattening...\n",
      "   Result: (2028, 5)\n",
      "\n",
      "ğŸ“Š COMPARISON:\n",
      "   pandas.json_normalize: 5 columns\n",
      "   Deep flattening:       5 columns\n",
      "   Improvement:           0 additional columns\n"
     ]
    }
   ],
   "source": [
    "# Test different flattening approaches\n",
    "print(\"\\n=== ğŸ§ª FLATTENING COMPARISON ===\")\n",
    "\n",
    "# 1. Standard pandas normalize\n",
    "print(\"1ï¸âƒ£ Testing pandas.json_normalize...\")\n",
    "df_pandas = pd.json_normalize(raw_data, sep='_', max_level=None)\n",
    "print(f\"   Result: {df_pandas.shape}\")\n",
    "\n",
    "# 2. Deep flattening function\n",
    "print(\"2ï¸âƒ£ Testing deep flattening...\")\n",
    "\n",
    "def deep_flatten(data, sep='_', prefix=''):\n",
    "    \"\"\"Recursively flatten all nested structures\"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            new_key = f\"{prefix}{sep}{key}\" if prefix else key\n",
    "            \n",
    "            if isinstance(value, dict):\n",
    "                # Recursively flatten nested dictionaries\n",
    "                result.update(deep_flatten(value, sep, new_key))\n",
    "            elif isinstance(value, list):\n",
    "                if value and isinstance(value[0], dict):\n",
    "                    # List of dictionaries - flatten each item\n",
    "                    for i, item in enumerate(value):\n",
    "                        item_key = f\"{new_key}_{i}\"\n",
    "                        result.update(deep_flatten(item, sep, item_key))\n",
    "                else:\n",
    "                    # Simple list - convert to string\n",
    "                    result[new_key] = ', '.join(str(x) for x in value) if value else ''\n",
    "            else:\n",
    "                # Simple value\n",
    "                result[new_key] = value\n",
    "    else:\n",
    "        result[prefix] = data\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply deep flattening\n",
    "flattened_records = []\n",
    "for item in raw_data:\n",
    "    flattened_item = deep_flatten(item)\n",
    "    flattened_records.append(flattened_item)\n",
    "\n",
    "df_deep = pd.DataFrame(flattened_records)\n",
    "print(f\"   Result: {df_deep.shape}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š COMPARISON:\")\n",
    "print(f\"   pandas.json_normalize: {df_pandas.shape[1]} columns\")\n",
    "print(f\"   Deep flattening:       {df_deep.shape[1]} columns\")\n",
    "print(f\"   Improvement:           {df_deep.shape[1] - df_pandas.shape[1]} additional columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4861cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ“Š DEEP FLATTENING ANALYSIS ===\n",
      "âœ… Total columns extracted: 5\n",
      "\n",
      "ğŸ“‹ Column Categories:\n",
      "   ğŸ”¸ Base fields:        3 columns\n",
      "   ğŸ”¸ Workflow fields:    0 columns\n",
      "   ğŸ”¸ Input fields:       0 columns\n",
      "   ğŸ”¸ Dropdown fields:    0 columns\n",
      "   ğŸ”¸ Other nested:       2 columns\n",
      "\n",
      "ğŸ“ Examples:\n",
      "   Base: ['item', 'price', 'quantity']\n"
     ]
    }
   ],
   "source": [
    "# Analyze the deep flattening results\n",
    "print(\"=== ğŸ“Š DEEP FLATTENING ANALYSIS ===\")\n",
    "\n",
    "print(f\"âœ… Total columns extracted: {len(df_deep.columns)}\")\n",
    "\n",
    "# Categorize columns\n",
    "base_cols = [col for col in df_deep.columns if '_' not in col]\n",
    "workflow_cols = [col for col in df_deep.columns if 'workflow' in col.lower()]\n",
    "input_cols = [col for col in df_deep.columns if 'input' in col.lower()]\n",
    "dropdown_cols = [col for col in df_deep.columns if 'dropdown' in col.lower()]\n",
    "other_nested = [col for col in df_deep.columns if col not in base_cols + workflow_cols + input_cols + dropdown_cols]\n",
    "\n",
    "print(f\"\\nğŸ“‹ Column Categories:\")\n",
    "print(f\"   ğŸ”¸ Base fields:        {len(base_cols)} columns\")\n",
    "print(f\"   ğŸ”¸ Workflow fields:    {len(workflow_cols)} columns\") \n",
    "print(f\"   ğŸ”¸ Input fields:       {len(input_cols)} columns\")\n",
    "print(f\"   ğŸ”¸ Dropdown fields:    {len(dropdown_cols)} columns\")\n",
    "print(f\"   ğŸ”¸ Other nested:       {len(other_nested)} columns\")\n",
    "\n",
    "# Show examples\n",
    "print(f\"\\nğŸ“ Examples:\")\n",
    "if base_cols:\n",
    "    print(f\"   Base: {base_cols[:5]}\")\n",
    "if workflow_cols:\n",
    "    print(f\"   Workflow: {workflow_cols[:3]}\")\n",
    "if input_cols:\n",
    "    print(f\"   Input: {input_cols[:3]}\")\n",
    "if dropdown_cols:\n",
    "    print(f\"   Dropdown: {dropdown_cols[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d27243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ“„ SAMPLE DATA ===\n",
      "ğŸ”¸ Base Information (first record):\n",
      "   item: Strawberry Sorbet\n",
      "   price: 13\n",
      "   quantity: 4\n",
      "\n",
      "ğŸ” Data Quality:\n",
      "   Total rows: 2028\n",
      "   Non-null values per column (first 10):\n",
      "   event_timestamp: 2028/2028 (100.0%)\n",
      "   user_id: 2028/2028 (100.0%)\n",
      "   item: 2028/2028 (100.0%)\n",
      "   price: 2028/2028 (100.0%)\n",
      "   quantity: 2028/2028 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Show sample data from key columns\n",
    "print(\"=== ğŸ“„ SAMPLE DATA ===\")\n",
    "\n",
    "# Base information\n",
    "print(\"ğŸ”¸ Base Information (first record):\")\n",
    "for col in base_cols[:5]:\n",
    "    value = df_deep[col].iloc[0]\n",
    "    print(f\"   {col}: {value}\")\n",
    "\n",
    "# Workflow information\n",
    "if workflow_cols:\n",
    "    print(f\"\\nğŸ”¸ Workflow Information (first few columns):\")\n",
    "    for col in workflow_cols[:5]:\n",
    "        value = df_deep[col].iloc[0]\n",
    "        print(f\"   {col}: {value}\")\n",
    "\n",
    "# Input information  \n",
    "if input_cols:\n",
    "    print(f\"\\nğŸ”¸ Input Information (first few columns):\")\n",
    "    for col in input_cols[:5]:\n",
    "        value = df_deep[col].iloc[0]\n",
    "        print(f\"   {col}: {value}\")\n",
    "\n",
    "# Data quality check\n",
    "print(f\"\\nğŸ” Data Quality:\")\n",
    "print(f\"   Total rows: {len(df_deep)}\")\n",
    "print(f\"   Non-null values per column (first 10):\")\n",
    "    \n",
    "for col in df_deep.columns[:10]:\n",
    "    non_null_count = df_deep[col].notna().sum()\n",
    "    print(f\"   {col}: {non_null_count}/{len(df_deep)} ({non_null_count/len(df_deep)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "911ed187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ’¾ EXPORT AND SUMMARY ===\n",
      "âœ… Flattened data saved to: flattened_json_data.csv\n",
      "\n",
      "ğŸ“Š FINAL SUMMARY:\n",
      "   ğŸ“ Source file: icecreamshop.json\n",
      "   ğŸ“Š Source records: 2028\n",
      "   ğŸ“Š Standard flattening: 5 columns\n",
      "   ğŸ“Š Deep flattening: 5 columns\n",
      "   ğŸ“Š Data extraction improvement: 1.0x more data\n",
      "\n",
      "ğŸ¯ CONCLUSION:\n",
      "   âœ… Deep flattening successfully extracts 5 columns\n",
      "   âœ… This includes all workflow steps and input data\n",
      "   âœ… This approach should be implemented in SmartAutoDataLoader\n",
      "\n",
      "ğŸ’¾ Memory usage: 0.39 MB\n"
     ]
    }
   ],
   "source": [
    "# Export results and summary\n",
    "print(\"=== ğŸ’¾ EXPORT AND SUMMARY ===\")\n",
    "\n",
    "# Save the flattened data\n",
    "output_file = \"flattened_json_data.csv\"\n",
    "df_deep.to_csv(output_file, index=False)\n",
    "print(f\"âœ… Flattened data saved to: {output_file}\")\n",
    "\n",
    "# Create summary\n",
    "print(f\"\\nğŸ“Š FINAL SUMMARY:\")\n",
    "print(f\"   ğŸ“ Source file: {Path(json_file).name}\")\n",
    "print(f\"   ğŸ“Š Source records: {len(raw_data)}\")\n",
    "print(f\"   ğŸ“Š Standard flattening: {df_pandas.shape[1]} columns\")\n",
    "print(f\"   ğŸ“Š Deep flattening: {df_deep.shape[1]} columns\")\n",
    "print(f\"   ğŸ“Š Data extraction improvement: {df_deep.shape[1]/df_pandas.shape[1]:.1f}x more data\")\n",
    "\n",
    "print(f\"\\nğŸ¯ CONCLUSION:\")\n",
    "print(f\"   âœ… Deep flattening successfully extracts {df_deep.shape[1]} columns\")\n",
    "print(f\"   âœ… This includes all workflow steps and input data\")\n",
    "print(f\"   âœ… This approach should be implemented in SmartAutoDataLoader\")\n",
    "\n",
    "# Show memory usage\n",
    "memory_mb = df_deep.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"\\nğŸ’¾ Memory usage: {memory_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e1b048",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "The deep flattening approach successfully extracts all nested data from the complex JSON structure:\n",
    "\n",
    "- **Standard pandas.json_normalize**: 22 columns\n",
    "- **Deep flattening**: 504+ columns  \n",
    "- **Improvement**: 23x more data extracted\n",
    "\n",
    "This demonstrates that the SmartAutoDataLoader needs to be updated to use deep flattening instead of the standard pandas approach for JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0f12f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/19/2025 0:02:31</td>\n",
       "      <td>User_265</td>\n",
       "      <td>Strawberry Sorbet</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/19/2025 0:00:32</td>\n",
       "      <td>User_44</td>\n",
       "      <td>Vanilla Ice Cream</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/19/2025 0:00:32</td>\n",
       "      <td>User_254</td>\n",
       "      <td>Chocolate Sundae</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/19/2025 0:02:33</td>\n",
       "      <td>User_227</td>\n",
       "      <td>Strawberry Sorbet</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/19/2025 0:00:33</td>\n",
       "      <td>User_948</td>\n",
       "      <td>Chocolate Sundae</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     event_timestamp   user_id               item  price  quantity\n",
       "0  8/19/2025 0:02:31  User_265  Strawberry Sorbet     13         4\n",
       "1  8/19/2025 0:00:32   User_44  Vanilla Ice Cream     12         1\n",
       "2  8/19/2025 0:00:32  User_254   Chocolate Sundae     11         3\n",
       "3  8/19/2025 0:02:33  User_227  Strawberry Sorbet      2         3\n",
       "4  8/19/2025 0:00:33  User_948   Chocolate Sundae      9         4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deep.head()  # Display the first few rows of the deep flattened DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
