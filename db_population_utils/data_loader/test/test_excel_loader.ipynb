{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236c05ab",
   "metadata": {},
   "source": [
    "# Test SmartAutoDataLoader - Excel Files\n",
    "\n",
    "This notebook tests the Excel loading functionality of SmartAutoDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c754f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'smart_auto_data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Add the data loader to path\u001b[39;00m\n\u001b[32m      7\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33mdb_population_utils/data_loader\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msmart_auto_data_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SmartAutoDataLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'smart_auto_data_loader'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to path (go up one level from test folder)\n",
    "sys.path.append('../')\n",
    "\n",
    "from smart_auto_data_loader import SmartAutoDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a2d29",
   "metadata": {},
   "source": [
    "## 1. Create Test Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634dbf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data created:\n",
      "   ID     Name        Date  Amount Category  Active\n",
      "0   1    Alice  2023-01-15  100.50        A    True\n",
      "1   2      Bob  2023-02-20  200.75        B   False\n",
      "2   3  Charlie  2023-03-25  150.25        A    True\n",
      "3   4    Diana  2023-04-30  300.00        C    True\n",
      "4   5      Eve  2023-05-15  175.50        B   False\n",
      "\n",
      "Data types: ID            int64\n",
      "Name         object\n",
      "Date         object\n",
      "Amount      float64\n",
      "Category     object\n",
      "Active         bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create test directory\n",
    "test_dir = Path('test_data')\n",
    "test_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create sample data with different data types\n",
    "sample_data = {\n",
    "    'ID': [1, 2, 3, 4, 5],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],\n",
    "    'Date': ['2023-01-15', '2023-02-20', '2023-03-25', '2023-04-30', '2023-05-15'],\n",
    "    'Amount': [100.5, 200.75, 150.25, 300.0, 175.5],\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B'],\n",
    "    'Active': [True, False, True, True, False]\n",
    "}\n",
    "\n",
    "df_sample = pd.DataFrame(sample_data)\n",
    "print(\"Sample data created:\")\n",
    "print(df_sample)\n",
    "print(f\"\\nData types: {df_sample.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80921d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created single sheet Excel: test_data/test_single_sheet.xlsx\n",
      "✅ Created multi-sheet Excel: test_data/test_multi_sheet.xlsx\n",
      "✅ Created date test Excel: test_data/test_dates.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Create single sheet Excel file\n",
    "excel_file_single = test_dir / 'test_single_sheet.xlsx'\n",
    "df_sample.to_excel(excel_file_single, index=False)\n",
    "print(f\"✅ Created single sheet Excel: {excel_file_single}\")\n",
    "\n",
    "# Create multi-sheet Excel file\n",
    "excel_file_multi = test_dir / 'test_multi_sheet.xlsx'\n",
    "with pd.ExcelWriter(excel_file_multi) as writer:\n",
    "    df_sample.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "    df_sample.iloc[:3].to_excel(writer, sheet_name='Small_Sheet', index=False)\n",
    "    (df_sample * 2).to_excel(writer, sheet_name='Large_Sheet', index=False)\n",
    "\n",
    "print(f\"✅ Created multi-sheet Excel: {excel_file_multi}\")\n",
    "\n",
    "# Create Excel with different date formats\n",
    "date_data = {\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'ISO_Date': ['2023-12-01', '2023-12-02', '2023-12-03', '2023-12-04'],\n",
    "    'EU_Date': ['01/12/2023', '02/12/2023', '03/12/2023', '04/12/2023'],\n",
    "    'German_Date': ['01.12.2023', '02.12.2023', '03.12.2023', '04.12.2023'],\n",
    "    'Value': [10, 20, 30, 40]\n",
    "}\n",
    "\n",
    "df_dates = pd.DataFrame(date_data)\n",
    "excel_file_dates = test_dir / 'test_dates.xlsx'\n",
    "df_dates.to_excel(excel_file_dates, index=False)\n",
    "print(f\"✅ Created date test Excel: {excel_file_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbeb39b",
   "metadata": {},
   "source": [
    "## 2. Initialize SmartAutoDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ad9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 SmartAutoDataLoader ready!\n",
      "SmartAutoDataLoader initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize loader with verbose mode\n",
    "loader = SmartAutoDataLoader(verbose=True)\n",
    "print(\"SmartAutoDataLoader initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c3de2",
   "metadata": {},
   "source": [
    "## 3. Test Format Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd758ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FORMAT DETECTION TEST ===\n",
      "🔍 Format detected: excel\n",
      "File: test_single_sheet.xlsx -> Format: excel\n",
      "🔍 Format detected: excel\n",
      "File: test_multi_sheet.xlsx -> Format: excel\n",
      "🔍 Format detected: excel\n",
      "File: test_dates.xlsx -> Format: excel\n",
      "✅ Format detection passed!\n"
     ]
    }
   ],
   "source": [
    "# Test format detection\n",
    "print(\"=== FORMAT DETECTION TEST ===\")\n",
    "for file_path in [excel_file_single, excel_file_multi, excel_file_dates]:\n",
    "    detected_format = loader.detect_format(str(file_path))\n",
    "    print(f\"File: {file_path.name} -> Format: {detected_format}\")\n",
    "    assert detected_format == 'excel', f\"Expected 'excel', got '{detected_format}'\"\n",
    "\n",
    "print(\"✅ Format detection passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac10020",
   "metadata": {},
   "source": [
    "## 4. Test Single Sheet Excel Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f240a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SINGLE SHEET EXCEL TEST ===\n",
      "📈 Loading Excel file...\n",
      "   📋 Available sheets: ['Sheet1']\n",
      "   ✅ Selected sheet: 'Sheet1'\n",
      "🗓️ Searching for date columns...\n",
      "   ✅ Found date column: 'Date' (%Y-%m-%d)\n",
      "   📅 Total date columns found: 1\n",
      "✅ Excel loaded: 5 rows, 6 columns\n",
      "   📊 Column names: ['ID', 'Name', 'Date', 'Amount', 'Category', 'Active']\n",
      "\n",
      "📊 Loaded DataFrame info:\n",
      "Shape: (5, 6)\n",
      "Columns: ['ID', 'Name', 'Date', 'Amount', 'Category', 'Active']\n",
      "Data types: ID                   int64\n",
      "Name                object\n",
      "Date        datetime64[ns]\n",
      "Amount             float64\n",
      "Category            object\n",
      "Active                bool\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "   ID     Name       Date  Amount Category  Active\n",
      "0   1    Alice 2023-01-15  100.50        A    True\n",
      "1   2      Bob 2023-02-20  200.75        B   False\n",
      "2   3  Charlie 2023-03-25  150.25        A    True\n",
      "3   4    Diana 2023-04-30  300.00        C    True\n",
      "4   5      Eve 2023-05-15  175.50        B   False\n",
      "\n",
      "✅ Single sheet Excel loading passed!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SINGLE SHEET EXCEL TEST ===\")\n",
    "try:\n",
    "    df_loaded = loader.load_excel(str(excel_file_single))\n",
    "    \n",
    "    print(f\"\\n📊 Loaded DataFrame info:\")\n",
    "    print(f\"Shape: {df_loaded.shape}\")\n",
    "    print(f\"Columns: {list(df_loaded.columns)}\")\n",
    "    print(f\"Data types: {df_loaded.dtypes}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df_loaded.head())\n",
    "    \n",
    "    # Verify data integrity\n",
    "    assert len(df_loaded) == 5, f\"Expected 5 rows, got {len(df_loaded)}\"\n",
    "    assert len(df_loaded.columns) == 6, f\"Expected 6 columns, got {len(df_loaded.columns)}\"\n",
    "    \n",
    "    print(\"\\n✅ Single sheet Excel loading passed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba258f",
   "metadata": {},
   "source": [
    "## 5. Test Multi-Sheet Excel Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232fa468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULTI-SHEET EXCEL TEST ===\n",
      "📈 Loading Excel file...\n",
      "   📋 Available sheets: ['Sheet1', 'Small_Sheet', 'Large_Sheet']\n",
      "   ✅ Selected sheet: 'Sheet1'\n",
      "🗓️ Searching for date columns...\n",
      "   ✅ Found date column: 'Date' (%Y-%m-%d)\n",
      "   📅 Total date columns found: 1\n",
      "✅ Excel loaded: 5 rows, 6 columns\n",
      "   📊 Column names: ['ID', 'Name', 'Date', 'Amount', 'Category', 'Active']\n",
      "Auto-detected sheet loaded: (5, 6)\n",
      "📈 Loading Excel file...\n",
      "🗓️ Searching for date columns...\n",
      "   ✅ Found date column: 'Date' (%Y-%m-%d)\n",
      "   📅 Total date columns found: 1\n",
      "✅ Excel loaded: 3 rows, 6 columns\n",
      "   📊 Column names: ['ID', 'Name', 'Date', 'Amount', 'Category', 'Active']\n",
      "Small_Sheet loaded: (3, 6)\n",
      "📈 Loading Excel file...\n",
      "🗓️ Searching for date columns...\n",
      "   ✅ Found date column: 'Date' (%Y-%m-%d)\n",
      "   📅 Total date columns found: 1\n",
      "✅ Excel loaded: 5 rows, 6 columns\n",
      "   📊 Column names: ['ID', 'Name', 'Date', 'Amount', 'Category', 'Active']\n",
      "Large_Sheet loaded: (5, 6)\n",
      "\n",
      "✅ Multi-sheet Excel loading passed!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MULTI-SHEET EXCEL TEST ===\")\n",
    "try:\n",
    "    # Test auto-detection (should pick first or largest sheet)\n",
    "    df_auto = loader.load_excel(str(excel_file_multi))\n",
    "    print(f\"Auto-detected sheet loaded: {df_auto.shape}\")\n",
    "    \n",
    "    # Test specific sheet selection\n",
    "    df_small = loader.load_excel(str(excel_file_multi), sheet_name='Small_Sheet')\n",
    "    print(f\"Small_Sheet loaded: {df_small.shape}\")\n",
    "    \n",
    "    df_large = loader.load_excel(str(excel_file_multi), sheet_name='Large_Sheet')\n",
    "    print(f\"Large_Sheet loaded: {df_large.shape}\")\n",
    "    \n",
    "    # Verify different sheet sizes\n",
    "    assert len(df_small) == 3, f\"Expected 3 rows in small sheet, got {len(df_small)}\"\n",
    "    assert len(df_large) == 5, f\"Expected 5 rows in large sheet, got {len(df_large)}\"\n",
    "    \n",
    "    print(\"\\n✅ Multi-sheet Excel loading passed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f1db5",
   "metadata": {},
   "source": [
    "## 6. Test Universal Load Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90362b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNIVERSAL LOAD METHOD TEST ===\n",
      "🎯 Loading file: test_single_sheet.xlsx\n",
      "🔍 Format detected: excel\n",
      "📈 Loading Excel file...\n",
      "   📋 Available sheets: ['Sheet1']\n",
      "   ✅ Selected sheet: 'Sheet1'\n",
      "🗓️ Searching for date columns...\n",
      "   ✅ Found date column: 'Date' (%Y-%m-%d)\n",
      "   📅 Total date columns found: 1\n",
      "✅ Excel loaded: 5 rows, 6 columns\n",
      "   📊 Column names: ['ID', 'Name', 'Date', 'Amount', 'Category', 'Active']\n",
      "Universal load result: (5, 6)\n",
      "Columns: ['ID', 'Name', 'Date', 'Amount', 'Category', 'Active']\n",
      "📈 Loading Excel file...\n",
      "   📋 Available sheets: ['Sheet1']\n",
      "   ✅ Selected sheet: 'Sheet1'\n",
      "🗓️ Searching for date columns...\n",
      "   ✅ Found date column: 'Date' (%Y-%m-%d)\n",
      "   📅 Total date columns found: 1\n",
      "✅ Excel loaded: 5 rows, 6 columns\n",
      "   📊 Column names: ['ID', 'Name', 'Date', 'Amount', 'Category', 'Active']\n",
      "\n",
      "✅ Universal load method passed!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== UNIVERSAL LOAD METHOD TEST ===\")\n",
    "try:\n",
    "    # Test universal load method (should auto-delegate to load_excel)\n",
    "    df_universal = loader.load(str(excel_file_single))\n",
    "    \n",
    "    print(f\"Universal load result: {df_universal.shape}\")\n",
    "    print(f\"Columns: {list(df_universal.columns)}\")\n",
    "    \n",
    "    # Verify it works the same as direct Excel loading\n",
    "    df_direct = loader.load_excel(str(excel_file_single))\n",
    "    \n",
    "    assert df_universal.shape == df_direct.shape, \"Universal and direct loading should match\"\n",
    "    assert list(df_universal.columns) == list(df_direct.columns), \"Columns should match\"\n",
    "    \n",
    "    print(\"\\n✅ Universal load method passed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30997f5d",
   "metadata": {},
   "source": [
    "## 7. Test DateTime Detection and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57158cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATETIME DETECTION TEST ===\n",
      "📈 Loading Excel file...\n",
      "   📋 Available sheets: ['Sheet1']\n",
      "   ✅ Selected sheet: 'Sheet1'\n",
      "🗓️ Searching for date columns...\n",
      "   ✅ Found date column: 'ISO_Date' (%Y-%m-%d)\n",
      "   ✅ Found date column: 'EU_Date' (%d/%m/%Y)\n",
      "   ✅ Found date column: 'German_Date' (%d.%m.%Y)\n",
      "   📅 Total date columns found: 3\n",
      "✅ Excel loaded: 4 rows, 5 columns\n",
      "   📊 Column names: ['ID', 'ISO_Date', 'EU_Date', 'German_Date', 'Value']\n",
      "\n",
      "Loaded date test file:\n",
      "Shape: (4, 5)\n",
      "Data types: ID                      int64\n",
      "ISO_Date       datetime64[ns]\n",
      "EU_Date        datetime64[ns]\n",
      "German_Date    datetime64[ns]\n",
      "Value                   int64\n",
      "dtype: object\n",
      "\n",
      "Data preview:\n",
      "   ID   ISO_Date    EU_Date German_Date  Value\n",
      "0   1 2023-12-01 2023-12-01  2023-12-01     10\n",
      "1   2 2023-12-02 2023-12-02  2023-12-02     20\n",
      "2   3 2023-12-03 2023-12-03  2023-12-03     30\n",
      "3   4 2023-12-04 2023-12-04  2023-12-04     40\n",
      "🕒 Found 3 datetime columns: ['ISO_Date', 'EU_Date', 'German_Date']\n",
      "\n",
      "Detected time columns: ['ISO_Date', 'EU_Date', 'German_Date']\n",
      "Date columns converted: 3\n",
      "\n",
      "✅ DateTime detection test completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATETIME DETECTION TEST ===\")\n",
    "try:\n",
    "    df_dates_loaded = loader.load_excel(str(excel_file_dates))\n",
    "    \n",
    "    print(f\"\\nLoaded date test file:\")\n",
    "    print(f\"Shape: {df_dates_loaded.shape}\")\n",
    "    print(f\"Data types: {df_dates_loaded.dtypes}\")\n",
    "    print(f\"\\nData preview:\")\n",
    "    print(df_dates_loaded.head())\n",
    "    \n",
    "    # Check for detected time columns\n",
    "    time_columns = loader.detect_time_columns(df_dates_loaded)\n",
    "    print(f\"\\nDetected time columns: {time_columns}\")\n",
    "    \n",
    "    # Verify at least some date columns were detected\n",
    "    date_columns_count = sum(1 for col in df_dates_loaded.columns \n",
    "                           if 'datetime' in str(df_dates_loaded[col].dtype).lower())\n",
    "    print(f\"Date columns converted: {date_columns_count}\")\n",
    "    \n",
    "    print(\"\\n✅ DateTime detection test completed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be233a",
   "metadata": {},
   "source": [
    "## 8. Test Comprehensive Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a42270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE REPORTING TEST ===\n",
      "🎯 Loading file: test_single_sheet.xlsx\n",
      "🔍 Format detected: excel\n",
      "📈 Loading Excel file...\n",
      "   📋 Available sheets: ['Sheet1']\n",
      "   ✅ Selected sheet: 'Sheet1'\n",
      "🗓️ Searching for date columns...\n",
      "   ✅ Found date column: 'Date' (%Y-%m-%d)\n",
      "   📅 Total date columns found: 1\n",
      "✅ Excel loaded: 5 rows, 6 columns\n",
      "   📊 Column names: ['ID', 'Name', 'Date', 'Amount', 'Category', 'Active']\n",
      "🕒 Found 1 datetime columns: ['Date']\n",
      "🔍 Format detected: excel\n",
      "🔍 Format detected: excel\n",
      "🔍 Format detected: excel\n",
      "📊 Report generated for test_single_sheet.xlsx\n",
      "\n",
      "📊 Load Report:\n",
      "File: test_data/test_single_sheet.xlsx\n",
      "Size: 0.00 MB\n",
      "Format: excel\n",
      "Rows: 5\n",
      "Columns: 6\n",
      "Date columns: ['Date']\n",
      "Quality score: 100\n",
      "Success: True\n",
      "Loading time: 0.006s\n",
      "\n",
      "✅ Comprehensive reporting passed!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== COMPREHENSIVE REPORTING TEST ===\")\n",
    "try:\n",
    "    # Generate report for Excel file\n",
    "    report = loader.build_report(str(excel_file_single))\n",
    "    \n",
    "    print(f\"\\n📊 Load Report:\")\n",
    "    print(f\"File: {report.file_path}\")\n",
    "    print(f\"Size: {report.file_size_mb:.2f} MB\")\n",
    "    print(f\"Format: {report.detected_format}\")\n",
    "    print(f\"Rows: {report.total_rows}\")\n",
    "    print(f\"Columns: {report.total_columns}\")\n",
    "    print(f\"Date columns: {report.date_columns_found}\")\n",
    "    print(f\"Quality score: {report.quality_score}\")\n",
    "    print(f\"Success: {report.success}\")\n",
    "    print(f\"Loading time: {report.loading_time_seconds:.3f}s\")\n",
    "    \n",
    "    if report.errors:\n",
    "        print(f\"Errors: {report.errors}\")\n",
    "    if report.warnings:\n",
    "        print(f\"Warnings: {report.warnings}\")\n",
    "    \n",
    "    # Verify report completeness\n",
    "    assert report.detected_format == 'excel', f\"Expected 'excel', got '{report.detected_format}'\"\n",
    "    assert report.success == True, \"Report should indicate success\"\n",
    "    assert report.total_rows > 0, \"Should have rows\"\n",
    "    assert report.total_columns > 0, \"Should have columns\"\n",
    "    \n",
    "    print(\"\\n✅ Comprehensive reporting passed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec47ad2",
   "metadata": {},
   "source": [
    "## 9. Test Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ERROR HANDLING TEST ===\n",
      "📈 Loading Excel file...\n",
      "❌ Error loading Excel file: Excel file not found: nonexistent_file.xlsx\n",
      "✅ Correctly caught error for non-existent file: ValueError\n",
      "📈 Loading Excel file...\n",
      "❌ Error loading Excel file: Worksheet named 'NonExistentSheet' not found\n",
      "✅ Correctly caught error for non-existent sheet: ValueError\n",
      "\n",
      "✅ Error handling tests passed!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ERROR HANDLING TEST ===\")\n",
    "\n",
    "# Test non-existent file\n",
    "try:\n",
    "    loader.load_excel('nonexistent_file.xlsx')\n",
    "    print(\"❌ Should have raised an error for non-existent file\")\n",
    "except Exception as e:\n",
    "    print(f\"✅ Correctly caught error for non-existent file: {type(e).__name__}\")\n",
    "\n",
    "# Test invalid sheet name\n",
    "try:\n",
    "    loader.load_excel(str(excel_file_single), sheet_name='NonExistentSheet')\n",
    "    print(\"❌ Should have raised an error for non-existent sheet\")\n",
    "except Exception as e:\n",
    "    print(f\"✅ Correctly caught error for non-existent sheet: {type(e).__name__}\")\n",
    "\n",
    "print(\"\\n✅ Error handling tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988c0da",
   "metadata": {},
   "source": [
    "## 10. Performance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9328110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PERFORMANCE TEST ===\n",
      "💾 File size: 0.0MB, estimated memory: 0.0MB\n",
      "\n",
      "💾 Memory Estimation:\n",
      "File size: 0.005 MB\n",
      "Estimated memory: 0.012 MB\n",
      "\n",
      "✅ Performance test passed!\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PERFORMANCE TEST ===\")\n",
    "try:\n",
    "    # Test memory estimation\n",
    "    memory_estimate = loader.estimate_memory_usage(str(excel_file_single))\n",
    "    \n",
    "    print(f\"\\n💾 Memory Estimation:\")\n",
    "    print(f\"File size: {memory_estimate['file_size_mb']:.3f} MB\")\n",
    "    print(f\"Estimated memory: {memory_estimate['estimated_memory_mb']:.3f} MB\")\n",
    "    if memory_estimate['recommended_chunksize']:\n",
    "        print(f\"Recommended chunk size: {memory_estimate['recommended_chunksize']}\")\n",
    "    \n",
    "    # Verify estimation structure\n",
    "    assert 'file_size_mb' in memory_estimate, \"Missing file_size_mb\"\n",
    "    assert 'estimated_memory_mb' in memory_estimate, \"Missing estimated_memory_mb\"\n",
    "    assert memory_estimate['file_size_mb'] > 0, \"File size should be positive\"\n",
    "    \n",
    "    print(\"\\n✅ Performance test passed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6b012",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf227a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🎯 SMARTAUTODATALOADER EXCEL TESTING COMPLETE\n",
      "==================================================\n",
      "\n",
      "✅ All tests completed successfully!\n",
      "\n",
      "📋 Features tested:\n",
      "   • Format detection for Excel files\n",
      "   • Single sheet Excel loading\n",
      "   • Multi-sheet Excel handling\n",
      "   • Universal load method delegation\n",
      "   • DateTime detection and parsing\n",
      "   • Comprehensive reporting\n",
      "   • Error handling\n",
      "   • Performance estimation\n",
      "\n",
      "🎉 SmartAutoDataLoader Excel functionality is working correctly!\n",
      "\n",
      "🧹 Cleaned up test directory: test_data\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🎯 SMARTAUTODATALOADER EXCEL TESTING COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n✅ All tests completed successfully!\")\n",
    "print(\"\\n📋 Features tested:\")\n",
    "print(\"   • Format detection for Excel files\")\n",
    "print(\"   • Single sheet Excel loading\")\n",
    "print(\"   • Multi-sheet Excel handling\")\n",
    "print(\"   • Universal load method delegation\")\n",
    "print(\"   • DateTime detection and parsing\")\n",
    "print(\"   • Comprehensive reporting\")\n",
    "print(\"   • Error handling\")\n",
    "print(\"   • Performance estimation\")\n",
    "print(\"\\n🎉 SmartAutoDataLoader Excel functionality is working correctly!\")\n",
    "\n",
    "# Cleanup\n",
    "import shutil\n",
    "if test_dir.exists():\n",
    "    shutil.rmtree(test_dir)\n",
    "    print(f\"\\n🧹 Cleaned up test directory: {test_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
