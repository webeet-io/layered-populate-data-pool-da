{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Data Population Tutorial\n",
    "\n",
    "This notebook demonstrates the complete workflow for loading, processing, and populating data into a database using our custom utility classes.\n",
    "\n",
    "**The workflow consists of three main steps:**\n",
    "1.  **Load**: Read data from a source file using `SmartAutoDataLoader`.\n",
    "2.  **Process**: Clean and standardize the loaded data using `DataProcessor`.\n",
    "3.  **Populate**: Connect to a database and insert the processed data using `db_connector`.\n",
    "\n",
    "We will populate the same data into two different databases, NeonDB and AWS LayeredDB, to show the flexibility of the connector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, we import the necessary classes and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to process file: /Users/svitlanakovalivska/layered-populate-data-pool-da/db_population_utils/data/tutorial_customers.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Add project root to sys.path for imports if running from examples/ or project root\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "try:\n",
    "    from db_population_utils.data_loader.smart_auto_data_loader import SmartAutoDataLoader\n",
    "    from db_population_utils.data_processor.data_processor import DataProcessor\n",
    "    from db_population_utils.db_connector.smart_db_connector_enhanced_V3 import db_connector\n",
    "except ModuleNotFoundError:\n",
    "    # Fallback: try relative imports if running from project root\n",
    "    from data_loader.smart_auto_data_loader import SmartAutoDataLoader\n",
    "    from data_processor.data_processor import DataProcessor\n",
    "    from db_connector.smart_db_connector_enhanced_V3 import db_connector\n",
    "\n",
    "# Define the path to our sample data file (always relative to project root)\n",
    "project_data_dir = os.path.join(project_root, 'data')\n",
    "file_path = os.path.join(project_data_dir, 'tutorial_customers.csv')\n",
    "\n",
    "print(f\"Ready to process file: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data with `SmartAutoDataLoader`\n",
    "\n",
    "We start by loading the raw data from the CSV file. The `SmartAutoDataLoader` will automatically detect the file format, encoding, and any date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ SmartAutoDataLoader ready!\n",
      "ğŸ¯ Loading file: tutorial_customers.csv\n",
      "ğŸ” Format detected: csv\n",
      "ğŸ“Š Loading CSV file...\n",
      "ğŸ”¤ Encoding detected: utf-8\n",
      "ğŸ—“ï¸ Searching for date columns...\n",
      "   âœ… Found date column: 'joined_date' (%Y-%m-%d)\n",
      "   ğŸ“… Total date columns found: 1\n",
      "âœ… CSV loaded: 4 rows, 7 columns\n",
      "Raw data loaded successfully:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>joined_date</th>\n",
       "      <th>City</th>\n",
       "      <th>Has_Subscription</th>\n",
       "      <th>district_id</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>john</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>berlin</td>\n",
       "      <td>True</td>\n",
       "      <td>11001001</td>\n",
       "      <td>Berlin-Mitte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane</td>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>berlin</td>\n",
       "      <td>False</td>\n",
       "      <td>11002002</td>\n",
       "      <td>Berlin-Friedrichshain-Kreuzberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mikey</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>berlin</td>\n",
       "      <td>True</td>\n",
       "      <td>11008008</td>\n",
       "      <td>Berlin-NeukÃ¶lln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SARAH</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>berlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11004004</td>\n",
       "      <td>Berlin-Charlottenburg-Wilmersdorf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID First Name joined_date    City Has_Subscription  district_id  \\\n",
       "0           1       john  2023-04-15  berlin             True     11001001   \n",
       "1           2       Jane  2022-11-20  berlin            False     11002002   \n",
       "2           3      Mikey  2024-01-05  berlin             True     11008008   \n",
       "3           4      SARAH  2023-08-21  berlin              NaN     11004004   \n",
       "\n",
       "                            district  \n",
       "0                       Berlin-Mitte  \n",
       "1    Berlin-Friedrichshain-Kreuzberg  \n",
       "2                    Berlin-NeukÃ¶lln  \n",
       "3  Berlin-Charlottenburg-Wilmersdorf  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the loader\n",
    "loader = SmartAutoDataLoader(verbose=True)\n",
    "\n",
    "# Load the data from the file\n",
    "\n",
    "raw_df = loader.load(file_path)\n",
    "\n",
    "# Display the first few rows of the loaded data\n",
    "print(\"Raw data loaded successfully:\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process Data with `DataProcessor`\n",
    "\n",
    "Now that we have the data in a DataFrame, we need to clean it up. The `DataProcessor` will help us standardize column names, correct data types, and handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original column names: ['CustomerID', 'First Name', 'joined_date', 'City', 'Has_Subscription', 'district_id', 'district']\n",
      "Original data types: CustomerID                   int64\n",
      "First Name                  object\n",
      "joined_date         datetime64[ns]\n",
      "City                        object\n",
      "Has_Subscription            object\n",
      "district_id                  int64\n",
      "district                    object\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      8\u001b[39m type_hints = {\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcustomer_id\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mint\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhas_subscription\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mbool\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     11\u001b[39m }\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Preprocess the data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m processed_df = \u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess_loaded_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatetime_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjoined_date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_hints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtype_hints\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessed column names:\u001b[39m\u001b[33m\"\u001b[39m, processed_df.columns.tolist())\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessed data types:\u001b[39m\u001b[33m\"\u001b[39m, processed_df.dtypes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/layered-populate-data-pool-da/db_population_utils/data_processor/data_processor.py:109\u001b[39m, in \u001b[36mDataProcessor.preprocess_loaded_data\u001b[39m\u001b[34m(self, df, datetime_columns, type_hints)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess_loaded_data\u001b[39m(  \u001b[38;5;66;03m# NEW METHOD\u001b[39;00m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     95\u001b[39m     df: \u001b[33m\"\u001b[39m\u001b[33mpd.DataFrame\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     96\u001b[39m     datetime_columns: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     97\u001b[39m     type_hints: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     98\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mpd.DataFrame\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     99\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    Standard pipeline for DataLoader output:\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m    1. Column standardization\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m        type_hints: Override DataLoader's type inference\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Instantiate the processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "print(\"Original column names:\", raw_df.columns.tolist())\n",
    "print(\"Original data types:\", raw_df.dtypes)\n",
    "\n",
    "# Define processing rules\n",
    "type_hints = {\n",
    "    'customer_id': 'int',\n",
    "    'has_subscription': 'bool'\n",
    "}\n",
    "\n",
    "# Preprocess the data\n",
    "processed_df = processor.preprocess_loaded_data(\n",
    "    raw_df,\n",
    "    datetime_columns=['joined_date'],\n",
    "    type_hints=type_hints\n",
    ")\n",
    "\n",
    "print(\"Processed column names:\", processed_df.columns.tolist())\n",
    "print(\"Processed data types:\", processed_df.dtypes)\n",
    "print(\"Cleaned data ready for population:\")\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Populate Data into Databases\n",
    "\n",
    "With our data cleaned, we can now populate it into our databases. We will perform the same steps for both NeonDB and AWS LayeredDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Connect to NeonDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to NeonDB...\n",
      "ğŸŒŸ SMART DATABASE CONNECTOR V3 - INITIALIZING...\n",
      "============================================================\n",
      "ğŸ”— Using default NeonDB connection\n",
      "âœ… NeonDB configuration loaded\n",
      "   Default schema: test_berlin_data\n",
      "ğŸ”Œ Connecting to NeonDB...\n",
      "âœ… Connection successful!\n",
      "   Database: neondb\n",
      "   User: neondb_owner\n",
      "\n",
      "ğŸ” Auto-discovering database schemas...\n",
      "âœ… Connection successful!\n",
      "   Database: neondb\n",
      "   User: neondb_owner\n",
      "\n",
      "ğŸ” Auto-discovering database schemas...\n",
      "âœ… Discovered 4 schemas\n",
      "ğŸ¯ Auto-selected default schema: test_berlin_data\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š SMART DB CONNECTOR V3 - CONNECTION SUMMARY\n",
      "============================================================\n",
      "ğŸ”— Connection Type: NeonDB\n",
      "\n",
      "ğŸ—‚ï¸  Discovered 4 schemas:\n",
      "  ğŸ“ dependency_example: 5 tables\n",
      "       â””â”€ banks_test_kovalivska_aws (11 columns)\n",
      "       â””â”€ departments (2 columns)\n",
      "       â””â”€ districts (3 columns)\n",
      "       â””â”€ ... and 2 more tables\n",
      "  ğŸ“ nyc_schools: 27 tables\n",
      "       â””â”€ Audrey_sat_results (10 columns)\n",
      "       â””â”€ Colleges_Berlin (12 columns)\n",
      "       â””â”€ Levon_cleaned_sat_scores (8 columns)\n",
      "       â””â”€ ... and 24 more tables\n",
      "  ğŸ“ public: 15 tables\n",
      "       â””â”€ audrey_sat_results (10 columns)\n",
      "       â””â”€ cleaned_sat_results_peter_s (9 columns)\n",
      "       â””â”€ demo_users (6 columns)\n",
      "       â””â”€ ... and 12 more tables\n",
      "  ğŸ¯ [CURRENT] test_berlin_data: 66 tables\n",
      "       â””â”€ banks_constraints_test_1891_2329 (11 columns)\n",
      "       â””â”€ banks_constraints_test_3954_4574 (11 columns)\n",
      "       â””â”€ banks_fresh_test_573 (11 columns)\n",
      "       â””â”€ ... and 63 more tables\n",
      "\n",
      "ğŸ’¡ Quick Commands:\n",
      "   db.schemas          # List all schemas\n",
      "   db.use('schema')    # Switch to schema\n",
      "   db.tables           # List tables in current schema\n",
      "   db.query('sql')     # Execute query\n",
      "   db.populate(df, 'table')  # Insert DataFrame\n",
      "   db.health_check()   # Check connection status\n",
      "============================================================\n",
      "âœ… Discovered 4 schemas\n",
      "ğŸ¯ Auto-selected default schema: test_berlin_data\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š SMART DB CONNECTOR V3 - CONNECTION SUMMARY\n",
      "============================================================\n",
      "ğŸ”— Connection Type: NeonDB\n",
      "\n",
      "ğŸ—‚ï¸  Discovered 4 schemas:\n",
      "  ğŸ“ dependency_example: 5 tables\n",
      "       â””â”€ banks_test_kovalivska_aws (11 columns)\n",
      "       â””â”€ departments (2 columns)\n",
      "       â””â”€ districts (3 columns)\n",
      "       â””â”€ ... and 2 more tables\n",
      "  ğŸ“ nyc_schools: 27 tables\n",
      "       â””â”€ Audrey_sat_results (10 columns)\n",
      "       â””â”€ Colleges_Berlin (12 columns)\n",
      "       â””â”€ Levon_cleaned_sat_scores (8 columns)\n",
      "       â””â”€ ... and 24 more tables\n",
      "  ğŸ“ public: 15 tables\n",
      "       â””â”€ audrey_sat_results (10 columns)\n",
      "       â””â”€ cleaned_sat_results_peter_s (9 columns)\n",
      "       â””â”€ demo_users (6 columns)\n",
      "       â””â”€ ... and 12 more tables\n",
      "  ğŸ¯ [CURRENT] test_berlin_data: 66 tables\n",
      "       â””â”€ banks_constraints_test_1891_2329 (11 columns)\n",
      "       â””â”€ banks_constraints_test_3954_4574 (11 columns)\n",
      "       â””â”€ banks_fresh_test_573 (11 columns)\n",
      "       â””â”€ ... and 63 more tables\n",
      "\n",
      "ğŸ’¡ Quick Commands:\n",
      "   db.schemas          # List all schemas\n",
      "   db.use('schema')    # Switch to schema\n",
      "   db.tables           # List tables in current schema\n",
      "   db.query('sql')     # Execute query\n",
      "   db.populate(df, 'table')  # Insert DataFrame\n",
      "   db.health_check()   # Check connection status\n",
      "============================================================\n",
      "NeonDB connection status: healthy\n",
      "NeonDB connection status: healthy\n"
     ]
    }
   ],
   "source": [
    "print(\"Connecting to NeonDB...\")\n",
    "neon_db = db_connector() # Connects to NeonDB by default\n",
    "\n",
    "# Verify the connection\n",
    "health_status = neon_db.health_check()\n",
    "print(f\"NeonDB connection status: {health_status.get('status')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Create Table in NeonDB\n",
    "\n",
    "Before we can insert data, we must create a table in the database with the correct schema and constraints. We will execute a `CREATE TABLE` SQL command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped existing table: tutorial_customers_7dfd0f9b\n",
      "Creating table tutorial_customers_7dfd0f9b in schema test_berlin_data...\n",
      "Table created successfully.\n",
      "Table created successfully.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "# Use UUID to ensure unique table name\n",
    "unique_id = str(uuid.uuid4())[:8]\n",
    "table_name = f'tutorial_customers_{unique_id}'  # Unique table name\n",
    "\n",
    "schema_name = 'test_berlin_data' # Target schema in NeonDB\n",
    "\n",
    "# Create table SQL for NeonDB (uses district as foreign key)\n",
    "create_table_sql = f'''\n",
    "CREATE TABLE IF NOT EXISTS {schema_name}.{table_name} (\n",
    "    customer_id INTEGER PRIMARY KEY,\n",
    "    first_name VARCHAR(100) NOT NULL,\n",
    "    joined_date DATE,\n",
    "    city VARCHAR(100),\n",
    "    has_subscription BOOLEAN,\n",
    "    district_id INTEGER,\n",
    "    district VARCHAR(100)\n",
    "    -- Foreign key constraint for NeonDB (uncomment if districts table exists)\n",
    "    ,CONSTRAINT fk_district FOREIGN KEY (district) REFERENCES {schema_name}.districts(district)\n",
    ");\n",
    "'''\n",
    "\n",
    "# To be safe, let's drop the table first in case it exists from a previous run\n",
    "try:\n",
    "    neon_db.query(f'DROP TABLE IF EXISTS {schema_name}.{table_name};', show_info=False)\n",
    "    print(f\"Dropped existing table: {table_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Table {table_name} did not exist, which is fine.\")\n",
    "\n",
    "print(f\"Creating table {table_name} in schema {schema_name}...\")\n",
    "neon_db.query(create_table_sql, show_info=False)\n",
    "print(\"Table created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Populate into NeonDB\n",
    "\n",
    "Now we use the `populate` function with `mode='append'` to insert our processed DataFrame. Using 'append' ensures that we add data to the existing table without destroying its structure or constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“Š SMART POPULATE - PRE-POPULATION ANALYSIS\n",
      "============================================================\n",
      "ğŸ¯ Target: test_berlin_data.tutorial_customers_7dfd0f9b\n",
      "ğŸ“ Mode: APPEND\n",
      "ğŸ”— Connection: ConnectionType.NEON_DB\n",
      "\n",
      "ğŸ“‹ DATASET ANALYSIS:\n",
      "   Rows: 4\n",
      "   Columns: 7\n",
      "   Memory usage: 0.00 MB\n",
      "\n",
      "ğŸ” COLUMN ANALYSIS:\n",
      "   CustomerID: int64 | Nulls: 0 (0.0%) | Unique: 4\n",
      "   First Name: object | Nulls: 0 (0.0%) | Unique: 4\n",
      "   joined_date: datetime64[ns] | Nulls: 0 (0.0%) | Unique: 4\n",
      "   City: object | Nulls: 0 (0.0%) | Unique: 1\n",
      "   Has_Subscription: object | Nulls: 1 (25.0%) | Unique: 2\n",
      "   district_id: int64 | Nulls: 0 (0.0%) | Unique: 4\n",
      "   district: object | Nulls: 0 (0.0%) | Unique: 4\n",
      "\n",
      "âœ… DATA QUALITY CHECKS:\n",
      "   Total null values: 1\n",
      "   Duplicate rows: 0\n",
      "\n",
      "ğŸ—ï¸  TABLE STATUS:\n",
      "   Table exists: No\n",
      "============================================================\n",
      "ğŸ“ Inserting 4 rows Ã— 7 columns\n",
      "   Target: test_berlin_data.tutorial_customers_7dfd0f9b\n",
      "   Action: append\n",
      "âœ… Insert completed successfully\n",
      "âœ… Insert completed successfully\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ SMART POPULATE - OPERATION COMPLETED\n",
      "============================================================\n",
      "âœ… Status: SUCCESS\n",
      "ğŸ¯ Table: test_berlin_data.tutorial_customers_7dfd0f9b\n",
      "ğŸ“ Mode: APPEND\n",
      "â±ï¸  Execution time: 1.15 seconds\n",
      "ğŸ“Š Rows processed: 4\n",
      "âš¡ Performance: 3 rows/second\n",
      "============================================================\n",
      "\n",
      "NeonDB population status: success\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ SMART POPULATE - OPERATION COMPLETED\n",
      "============================================================\n",
      "âœ… Status: SUCCESS\n",
      "ğŸ¯ Table: test_berlin_data.tutorial_customers_7dfd0f9b\n",
      "ğŸ“ Mode: APPEND\n",
      "â±ï¸  Execution time: 1.15 seconds\n",
      "ğŸ“Š Rows processed: 4\n",
      "âš¡ Performance: 3 rows/second\n",
      "============================================================\n",
      "\n",
      "NeonDB population status: success\n"
     ]
    }
   ],
   "source": [
    "result_neon = neon_db.populate(\n",
    "    df=processed_df if 'processed_df' in locals() else raw_df,\n",
    "    table_name=table_name,\n",
    "    schema=schema_name,\n",
    "    mode='append',\n",
    "    show_report=True\n",
    ")\n",
    "\n",
    "print(f\"NeonDB population status: {result_neon['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Verify the Data in NeonDB\n",
    "\n",
    "Let's read the data back from the table to confirm it was inserted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying data in NeonDB...\n",
      "ğŸ” Executing query in schema: 'test_berlin_data'\n",
      "âœ… Query completed: 4 rows, 7 columns\n",
      "âœ… Query completed: 4 rows, 7 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>joined_date</th>\n",
       "      <th>City</th>\n",
       "      <th>Has_Subscription</th>\n",
       "      <th>district_id</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>john</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>berlin</td>\n",
       "      <td>True</td>\n",
       "      <td>11001001</td>\n",
       "      <td>Berlin-Mitte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane</td>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>berlin</td>\n",
       "      <td>False</td>\n",
       "      <td>11002002</td>\n",
       "      <td>Berlin-Friedrichshain-Kreuzberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mikey</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>berlin</td>\n",
       "      <td>True</td>\n",
       "      <td>11008008</td>\n",
       "      <td>Berlin-NeukÃ¶lln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SARAH</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>11004004</td>\n",
       "      <td>Berlin-Charlottenburg-Wilmersdorf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID First Name joined_date    City Has_Subscription  district_id  \\\n",
       "0           1       john  2023-04-15  berlin             True     11001001   \n",
       "1           2       Jane  2022-11-20  berlin            False     11002002   \n",
       "2           3      Mikey  2024-01-05  berlin             True     11008008   \n",
       "3           4      SARAH  2023-08-21  berlin             None     11004004   \n",
       "\n",
       "                            district  \n",
       "0                       Berlin-Mitte  \n",
       "1    Berlin-Friedrichshain-Kreuzberg  \n",
       "2                    Berlin-NeukÃ¶lln  \n",
       "3  Berlin-Charlottenburg-Wilmersdorf  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Verifying data in NeonDB...\")\n",
    "data_from_neon = neon_db.query(f\"SELECT * FROM {schema_name}.{table_name}\")\n",
    "data_from_neon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E: Populate into AWS LayeredDB\n",
    "\n",
    "Now, we repeat the process for AWS LayeredDB. This demonstrates how the connector can target different environments.\n",
    "\n",
    "**Note**: This step requires a running SSH tunnel to the AWS database and valid credentials. We will use placeholder credentials here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AWS LayeredDB...\n",
      "ğŸŒŸ SMART DATABASE CONNECTOR V3 - INITIALIZING...\n",
      "============================================================\n",
      "ğŸš‡ AWS LayeredDB connection requested\n",
      "ğŸš‡ Tunnel Status: Connected\n",
      "âœ… AWS LayeredDB configuration loaded\n",
      "   Tunnel: Tunnel is active on localhost:5433\n",
      "ğŸ”Œ Connecting to AWS LayeredDB...\n",
      "âœ… Connection successful!\n",
      "   Database: layereddb\n",
      "   User: svitlana_kovalivska\n",
      "\n",
      "ğŸ” Auto-discovering database schemas...\n",
      "âœ… Connection successful!\n",
      "   Database: layereddb\n",
      "   User: svitlana_kovalivska\n",
      "\n",
      "ğŸ” Auto-discovering database schemas...\n",
      "âœ… Discovered 2 schemas\n",
      "ğŸ¯ Auto-selected default schema: berlin_source_data\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š SMART DB CONNECTOR V3 - CONNECTION SUMMARY\n",
      "============================================================\n",
      "ğŸ”— Connection Type: AWS LayeredDB\n",
      "ğŸš‡ Tunnel Status: Connected (localhost:5433)\n",
      "\n",
      "ğŸ—‚ï¸  Discovered 2 schemas:\n",
      "  ğŸ¯ [CURRENT] berlin_source_data: 12 tables\n",
      "       â””â”€ banks_test_kovalivska_aws (11 columns)\n",
      "       â””â”€ crime_statistics (15 columns)\n",
      "       â””â”€ districts (3 columns)\n",
      "       â””â”€ ... and 9 more tables\n",
      "  ğŸ“ public: 22 tables\n",
      "       â””â”€ aws_test_customers_v3 (5 columns)\n",
      "       â””â”€ aws_test_products_v3 (6 columns)\n",
      "       â””â”€ aws_test_sales_v3 (6 columns)\n",
      "       â””â”€ ... and 19 more tables\n",
      "\n",
      "ğŸ’¡ Quick Commands:\n",
      "   db.schemas          # List all schemas\n",
      "   db.use('schema')    # Switch to schema\n",
      "   db.tables           # List tables in current schema\n",
      "   db.query('sql')     # Execute query\n",
      "   db.populate(df, 'table')  # Insert DataFrame\n",
      "   db.health_check()   # Check connection status\n",
      "============================================================\n",
      "AWS connection status: healthy\n",
      "âœ… Discovered 2 schemas\n",
      "ğŸ¯ Auto-selected default schema: berlin_source_data\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š SMART DB CONNECTOR V3 - CONNECTION SUMMARY\n",
      "============================================================\n",
      "ğŸ”— Connection Type: AWS LayeredDB\n",
      "ğŸš‡ Tunnel Status: Connected (localhost:5433)\n",
      "\n",
      "ğŸ—‚ï¸  Discovered 2 schemas:\n",
      "  ğŸ¯ [CURRENT] berlin_source_data: 12 tables\n",
      "       â””â”€ banks_test_kovalivska_aws (11 columns)\n",
      "       â””â”€ crime_statistics (15 columns)\n",
      "       â””â”€ districts (3 columns)\n",
      "       â””â”€ ... and 9 more tables\n",
      "  ğŸ“ public: 22 tables\n",
      "       â””â”€ aws_test_customers_v3 (5 columns)\n",
      "       â””â”€ aws_test_products_v3 (6 columns)\n",
      "       â””â”€ aws_test_sales_v3 (6 columns)\n",
      "       â””â”€ ... and 19 more tables\n",
      "\n",
      "ğŸ’¡ Quick Commands:\n",
      "   db.schemas          # List all schemas\n",
      "   db.use('schema')    # Switch to schema\n",
      "   db.tables           # List tables in current schema\n",
      "   db.query('sql')     # Execute query\n",
      "   db.populate(df, 'table')  # Insert DataFrame\n",
      "   db.health_check()   # Check connection status\n",
      "============================================================\n",
      "AWS connection status: healthy\n"
     ]
    }
   ],
   "source": [
    "print(\"Connecting to AWS LayeredDB...\")\n",
    "try:\n",
    "    # IMPORTANT: Replace with your actual username and password\n",
    "    aws_db = db_connector(\n",
    "        database='layereddb', \n",
    "        username='USERNAME',  # Replace with your AWS username\n",
    "        password='PASSWORD'  # Replace with your AWS password\n",
    "    )\n",
    "    aws_health = aws_db.health_check()\n",
    "    print(f\"AWS connection status: {aws_health.get('status')}\")\n",
    "    aws_connected = True\n",
    "except Exception as e:\n",
    "    print(f\"Could not connect to AWS LayeredDB: {e}\")\n",
    "    print(\"Skipping AWS population steps.\")\n",
    "    aws_connected = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped existing table if it existed: tutorial_customers_85f4fd8e\n",
      "Creating table tutorial_customers_85f4fd8e in AWS...\n",
      "Table created successfully in AWS.\n",
      "Populating data into AWS LayeredDB...\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š SMART POPULATE - PRE-POPULATION ANALYSIS\n",
      "============================================================\n",
      "ğŸ¯ Target: berlin_source_data.tutorial_customers_85f4fd8e\n",
      "ğŸ“ Mode: APPEND\n",
      "ğŸ”— Connection: ConnectionType.AWS_LAYERED_DB\n",
      "\n",
      "ğŸ“‹ DATASET ANALYSIS:\n",
      "   Rows: 4\n",
      "   Columns: 7\n",
      "   Memory usage: 0.00 MB\n",
      "\n",
      "ğŸ” COLUMN ANALYSIS:\n",
      "   CustomerID: int64 | Nulls: 0 (0.0%) | Unique: 4\n",
      "   First Name: object | Nulls: 0 (0.0%) | Unique: 4\n",
      "   joined_date: datetime64[ns] | Nulls: 0 (0.0%) | Unique: 4\n",
      "   City: object | Nulls: 0 (0.0%) | Unique: 1\n",
      "   Has_Subscription: object | Nulls: 1 (25.0%) | Unique: 2\n",
      "   district_id: int64 | Nulls: 0 (0.0%) | Unique: 4\n",
      "   district: object | Nulls: 0 (0.0%) | Unique: 4\n",
      "\n",
      "âœ… DATA QUALITY CHECKS:\n",
      "   Total null values: 1\n",
      "   Duplicate rows: 0\n",
      "\n",
      "ğŸ—ï¸  TABLE STATUS:\n",
      "   Table exists: No\n",
      "============================================================\n",
      "ğŸ“ Inserting 4 rows Ã— 7 columns\n",
      "   Target: berlin_source_data.tutorial_customers_85f4fd8e\n",
      "   Action: append\n",
      "âœ… Insert completed successfully\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ SMART POPULATE - OPERATION COMPLETED\n",
      "============================================================\n",
      "âœ… Status: SUCCESS\n",
      "ğŸ¯ Table: berlin_source_data.tutorial_customers_85f4fd8e\n",
      "ğŸ“ Mode: APPEND\n",
      "â±ï¸  Execution time: 0.27 seconds\n",
      "ğŸ“Š Rows processed: 4\n",
      "âš¡ Performance: 15 rows/second\n",
      "============================================================\n",
      "\n",
      "AWS population status: success\n",
      "Verifying data in AWS...\n",
      "ğŸ” Executing query in schema: 'berlin_source_data'\n",
      "âœ… Insert completed successfully\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ SMART POPULATE - OPERATION COMPLETED\n",
      "============================================================\n",
      "âœ… Status: SUCCESS\n",
      "ğŸ¯ Table: berlin_source_data.tutorial_customers_85f4fd8e\n",
      "ğŸ“ Mode: APPEND\n",
      "â±ï¸  Execution time: 0.27 seconds\n",
      "ğŸ“Š Rows processed: 4\n",
      "âš¡ Performance: 15 rows/second\n",
      "============================================================\n",
      "\n",
      "AWS population status: success\n",
      "Verifying data in AWS...\n",
      "ğŸ” Executing query in schema: 'berlin_source_data'\n",
      "âœ… Query completed: 4 rows, 7 columns\n",
      "âœ… Query completed: 4 rows, 7 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>joined_date</th>\n",
       "      <th>City</th>\n",
       "      <th>Has_Subscription</th>\n",
       "      <th>district_id</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>john</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>berlin</td>\n",
       "      <td>True</td>\n",
       "      <td>11001001</td>\n",
       "      <td>Berlin-Mitte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jane</td>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>berlin</td>\n",
       "      <td>False</td>\n",
       "      <td>11002002</td>\n",
       "      <td>Berlin-Friedrichshain-Kreuzberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mikey</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>berlin</td>\n",
       "      <td>True</td>\n",
       "      <td>11008008</td>\n",
       "      <td>Berlin-NeukÃ¶lln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SARAH</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>berlin</td>\n",
       "      <td>None</td>\n",
       "      <td>11004004</td>\n",
       "      <td>Berlin-Charlottenburg-Wilmersdorf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID First Name joined_date    City Has_Subscription  district_id  \\\n",
       "0           1       john  2023-04-15  berlin             True     11001001   \n",
       "1           2       Jane  2022-11-20  berlin            False     11002002   \n",
       "2           3      Mikey  2024-01-05  berlin             True     11008008   \n",
       "3           4      SARAH  2023-08-21  berlin             None     11004004   \n",
       "\n",
       "                            district  \n",
       "0                       Berlin-Mitte  \n",
       "1    Berlin-Friedrichshain-Kreuzberg  \n",
       "2                    Berlin-NeukÃ¶lln  \n",
       "3  Berlin-Charlottenburg-Wilmersdorf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "if aws_connected:\n",
    "    # Define schema and table for AWS\n",
    "    aws_schema_name = 'berlin_source_data'\n",
    "    \n",
    "\n",
    "    # Use UUID to ensure unique table name\n",
    "    unique_id = str(uuid.uuid4())[:8]\n",
    "    aws_table_name = f'tutorial_customers_{unique_id}'  # Unique table name\n",
    "    \n",
    "    # Create table SQL for LayeredDB - fix data type to match existing districts table\n",
    "    aws_create_sql = f'''\n",
    "    CREATE TABLE IF NOT EXISTS {aws_schema_name}.{aws_table_name} (\n",
    "        customer_id INTEGER PRIMARY KEY,\n",
    "        first_name VARCHAR(100) NOT NULL,\n",
    "        joined_date DATE,\n",
    "        city VARCHAR(100),\n",
    "        has_subscription BOOLEAN,\n",
    "        district_id VARCHAR(100),  -- Changed to VARCHAR to match districts table\n",
    "        district VARCHAR(100)\n",
    "        -- Foreign key constraint for LayeredDB (uncomment if districts table exists)\n",
    "        ,CONSTRAINT fk_district_id FOREIGN KEY (district_id) REFERENCES {aws_schema_name}.districts(district_id)\n",
    "    );\n",
    "    '''\n",
    "    try:\n",
    "        aws_db.query(f'DROP TABLE IF EXISTS {aws_schema_name}.{aws_table_name};', show_info=False)\n",
    "        print(f\"Dropped existing table if it existed: {aws_table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Table {aws_table_name} did not exist, which is fine.\")\n",
    "        \n",
    "    print(f\"Creating table {aws_table_name} in AWS...\")\n",
    "    aws_db.query(aws_create_sql, show_info=False)\n",
    "    print(\"Table created successfully in AWS.\")\n",
    "    \n",
    "    # Populate the table in AWS\n",
    "    print(\"Populating data into AWS LayeredDB...\")\n",
    "    result_aws = aws_db.populate(\n",
    "        df=processed_df if 'processed_df' in locals() else raw_df,\n",
    "        table_name=aws_table_name,\n",
    "        schema=aws_schema_name,\n",
    "        mode='append'\n",
    "    )\n",
    "    print(f\"AWS population status: {result_aws['status']}\")\n",
    "    \n",
    "    # Verify the data in AWS\n",
    "    print(\"Verifying data in AWS...\")\n",
    "    data_from_aws = aws_db.query(f\"SELECT * FROM {aws_schema_name}.{aws_table_name}\")\n",
    "    display(data_from_aws.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have successfully completed the entire data pipeline:\n",
    "\n",
    "1.  Loaded raw data from a CSV file using **SmartAutoDataLoader**.\n",
    "2.  Cleaned and standardized the data using **DataProcessor**.\n",
    "3.  Populated the clean data into two different databases (NeonDB and AWS LayeredDB) using the **db_connector**.\n",
    "\n",
    "This notebook provides a foundational template for building more complex data ingestion workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
