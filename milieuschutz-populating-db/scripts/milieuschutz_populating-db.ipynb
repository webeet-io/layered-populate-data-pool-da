{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf57fa1",
   "metadata": {},
   "source": [
    "# 🗄️ **AWS Database Investigation & Milieuschutz Protection Zones Table Creation**\n",
    "\n",
    "## 🎯 **Learning Objectives**\n",
    "By the end of this notebook, students will understand:\n",
    "1. **Database Connection**: How to connect to AWS RDS PostgreSQL\n",
    "2. **Schema Investigation**: How to explore existing database structure\n",
    "3. **PostGIS Setup**: Understanding spatial database extensions\n",
    "4. **GeoJSON Import**: How to create PostGIS tables from GeoJSON files\n",
    "5. **Data Validation**: How to verify successful data import\n",
    "6. **Urban Planning Data**: Understanding Milieuschutz (Environmental Protection Zones)\n",
    "7. **Temporal Data**: Working with dates and policy amendments\n",
    "\n",
    "## 🏛️ **About Milieuschutz Zones**\n",
    "**Milieuschutz** (Environmental Protection Areas) are special urban planning zones in Berlin designed to:\n",
    "- **Preserve neighborhood character** and architectural heritage\n",
    "- **Control gentrification** and maintain affordable housing\n",
    "- **Protect social structure** of residential areas\n",
    "- **Regulate building modifications** and new developments\n",
    "\n",
    "## 📋 **Prerequisites**\n",
    "- ✅ Enhanced GeoJSON file (`milieuschutz_residental_and_urban_zones_joined.geojson`)\n",
    "- ✅ AWS database credentials\n",
    "- ✅ Basic understanding of PostgreSQL and spatial data\n",
    "- ✅ Understanding of Berlin's urban planning concepts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b143c6",
   "metadata": {},
   "source": [
    "## 📦 **Step 1: Import Required Libraries**\n",
    "\n",
    "**Learning Point**: We need specific libraries for spatial data and database operations with environmental protection zones.\n",
    "\n",
    "### 🔧 **Library Functions for Milieuschutz Data:**\n",
    "- **`geopandas`**: Handle complex protection zone geometries (MultiPolygon shapes)\n",
    "- **`pandas`**: Manage temporal data (announcement dates, effective dates, amendments)\n",
    "- **`sqlalchemy`**: Create robust database connections for urban planning data\n",
    "- **`psycopg2`**: PostgreSQL adapter optimized for spatial queries\n",
    "- **`dotenv`**: Secure credential management for production databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c370f3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully!\n",
      "📚 Ready for spatial database operations\n"
     ]
    }
   ],
   "source": [
    "# 📦 Import required libraries for spatial database operations\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"📚 Ready for spatial database operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfd4f7",
   "metadata": {},
   "source": [
    "## 🔌 **Step 2: AWS Database Connection**\n",
    "\n",
    "**Learning Point**: Connection strings contain all necessary information to connect to a database storing urban planning data.\n",
    "\n",
    "**Format**: `postgresql+psycopg2://username:password@host:port/database`\n",
    "\n",
    "### 🏛️ **Why This Database for Milieuschutz Data?**\n",
    "- **AWS RDS PostgreSQL**: Scalable cloud database for city-wide data\n",
    "- **PostGIS Extension**: Essential for spatial environmental protection zones\n",
    "- **Multi-tenant Design**: Supports multiple Berlin urban planning datasets\n",
    "- **Production Security**: Environment variables protect sensitive credentials\n",
    "\n",
    "**Note**: Database is currently offline until Monday - we'll prepare our code for testing then! 🔧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8742098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔌 **CONNECTING TO AWS DATABASE**\n",
      "========================================\n",
      "1️⃣ Creating database engine...\n",
      "2️⃣ Testing connection...\n",
      "   ✅ Connected successfully!\n",
      "   🗄️  Database: berlin_project_db\n",
      "   👤 User: postgres\n",
      "   📊 PostgreSQL Version: PostgreSQL 17.4 on aarch64-unknown-linux-gnu, comp...\n",
      "   ✅ Connected successfully!\n",
      "   🗄️  Database: berlin_project_db\n",
      "   👤 User: postgres\n",
      "   📊 PostgreSQL Version: PostgreSQL 17.4 on aarch64-unknown-linux-gnu, comp...\n"
     ]
    }
   ],
   "source": [
    "# 🔐 Clean and professional database connection using python-dotenv\n",
    "print(\"🔌 **CONNECTING TO AWS DATABASE**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Load environment variables from .env file (no string functions needed!)\n",
    "load_dotenv('../ignored_files/.env')\n",
    "PASSWORD = os.getenv('PASSWORD')\n",
    "\n",
    "# Build connection URL with secure password from .env\n",
    "DATABASE_URL = f'postgresql+psycopg2://postgres:{PASSWORD}@layered-data-warehouse.cdg2ok68acsn.eu-central-1.rds.amazonaws.com:5432/berlin_project_db'\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Creating database engine...\")\n",
    "    engine = create_engine(DATABASE_URL, connect_args={'connect_timeout': 10})\n",
    "    \n",
    "    print(\"2️⃣ Testing connection...\")\n",
    "    conn = engine.connect()\n",
    "    \n",
    "    # Test query\n",
    "    test_result = conn.execute(text(\"SELECT current_database(), current_user, version()\"))\n",
    "    db_info = test_result.fetchone()\n",
    "    \n",
    "    print(f\"   ✅ Connected successfully!\")\n",
    "    print(f\"   🗄️  Database: {db_info[0]}\")\n",
    "    print(f\"   👤 User: {db_info[1]}\")\n",
    "    print(f\"   📊 PostgreSQL Version: {db_info[2][:50]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection failed: {e}\")\n",
    "    print(\"💡 Check network connection and credentials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd607c9",
   "metadata": {},
   "source": [
    "## 🔍 **Step 3: Database Schema Investigation**\n",
    "\n",
    "**Learning Point**: Before importing environmental data, always investigate the existing database structure to understand how Milieuschutz data will integrate.\n",
    "\n",
    "**Schema Investigation Goals**:\n",
    "- **Check Available Schemas**: See what database schemas exist (berlin_data, public, etc.)\n",
    "- **Explore Existing Tables**: Understand current urban planning data structure\n",
    "- **Verify PostGIS Extension**: Confirm spatial capabilities are available\n",
    "- **Plan Integration**: See how Milieuschutz zones will fit with existing data\n",
    "\n",
    "**Database Architecture Understanding**:\n",
    "- **Schema Organization**: Berlin planning data is organized in the `berlin_data` schema\n",
    "- **Table Relationships**: Environmental zones will connect to districts and other planning data\n",
    "- **Spatial Integration**: PostGIS enables complex environmental boundary analysis\n",
    "- **Data Quality**: Understanding existing structure helps maintain consistency\n",
    "\n",
    "**Educational Value**: This step teaches systematic database exploration before adding new environmental datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 **DATABASE SCHEMA INVESTIGATION**\n",
      "========================================\n",
      "1️⃣ Available schemas:\n",
      "   📁 berlin_data\n",
      "   📁 public\n",
      "\n",
      "2️⃣ Target schema 'berlin_data' exists: ✅ YES\n",
      "   📋 Search path set to: berlin_data, public\n",
      "\n",
      "3️⃣ Existing tables in berlin_data schema:\n",
      "   🗄️  districts (BASE TABLE)\n",
      "   🗄️  districts_pop_stat (BASE TABLE)\n",
      "   🗄️  geography_columns (VIEW)\n",
      "   🗄️  geometry_columns (VIEW)\n",
      "   🗄️  green_spaces (BASE TABLE)\n",
      "   🗄️  hospitals (BASE TABLE)\n",
      "   🗄️  neighborhoods (BASE TABLE)\n",
      "   🗄️  regional_statistics (BASE TABLE)\n",
      "   🗄️  schools_kai (BASE TABLE)\n",
      "   🗄️  short_time_listings (BASE TABLE)\n",
      "   🗄️  spatial_ref_sys (BASE TABLE)\n",
      "   🗄️  ubahn (BASE TABLE)\n",
      "\n",
      "   📊 Total tables found: 12\n",
      "\n",
      "✅ Schema investigation complete!\n"
     ]
    }
   ],
   "source": [
    "# 🔍 STEP 3: Database Schema Investigation\n",
    "\n",
    "print(\"📊 Investigating Database Structure for Milieuschutz Integration...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check available schemas\n",
    "print(\"🗂️  Available Database Schemas:\")\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT schema_name \n",
    "    FROM information_schema.schemata \n",
    "    WHERE schema_name NOT IN ('information_schema', 'pg_catalog', 'pg_toast');\n",
    "\"\"\")\n",
    "schemas = cursor.fetchall()\n",
    "for schema in schemas:\n",
    "    print(f\"   📁 {schema[0]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Check existing tables in berlin_data schema\n",
    "print(\"🏗️  Existing Tables in berlin_data Schema:\")\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name, table_type\n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'berlin_data'\n",
    "    ORDER BY table_name;\n",
    "\"\"\")\n",
    "tables = cursor.fetchall()\n",
    "for table_name, table_type in tables:\n",
    "    print(f\"   \udccb {table_name} ({table_type})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Check PostGIS extension\n",
    "print(\"🌍 PostGIS Spatial Extension Status:\")\n",
    "cursor.execute(\"SELECT extname, extversion FROM pg_extension WHERE extname = 'postgis';\")\n",
    "postgis_info = cursor.fetchone()\n",
    "if postgis_info:\n",
    "    print(f\"   ✅ PostGIS Version: {postgis_info[1]}\")\n",
    "else:\n",
    "    print(\"   ❌ PostGIS not found - spatial functions unavailable\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✅ Schema Investigation Complete\")\n",
    "print(\"📝 Ready to proceed with Milieuschutz data integration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b22448",
   "metadata": {},
   "source": [
    "## 🗺️ **Step 4: PostGIS Extension Verification**\n",
    "\n",
    "**Learning Point**: Before working with environmental protection zones (Milieuschutz), we must verify that PostGIS spatial extension is available for geospatial operations.\n",
    "\n",
    "**PostGIS Extension Goals**:\n",
    "- **Verify Installation**: Confirm PostGIS is installed and available\n",
    "- **Check Version**: Ensure we have a compatible version for spatial analysis\n",
    "- **Validate Schema**: Confirm the extension is properly configured\n",
    "- **Enable Spatial Operations**: Prepare for environmental boundary processing\n",
    "\n",
    "**Why PostGIS is Critical for Environmental Data**:\n",
    "- **Spatial Analysis**: Environmental zones require complex geometric calculations\n",
    "- **Boundary Operations**: Intersection, containment, and proximity analysis\n",
    "- **Coordinate Systems**: Proper handling of Berlin's spatial reference system\n",
    "- **Performance**: Optimized spatial indexing for large environmental datasets\n",
    "\n",
    "**Environmental Planning Context**:\n",
    "- **Zone Boundaries**: Milieuschutz areas have complex geometric shapes\n",
    "- **Spatial Relationships**: How environmental zones relate to districts and neighborhoods\n",
    "- **Buffer Analysis**: Creating protection buffers around sensitive areas\n",
    "- **Overlay Operations**: Combining environmental data with urban planning layers\n",
    "\n",
    "**Educational Value**: Understanding spatial database capabilities is essential for environmental data management and urban planning analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d5729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗺️ **POSTGIS EXTENSION CHECK**\n",
      "========================================\n",
      "✅ PostGIS is installed!\n",
      "   📦 Extension: postgis\n",
      "   🔢 Version: 3.5.1\n",
      "   📋 Schema: berlin_data\n",
      "\n",
      "✅ PostGIS check complete!\n"
     ]
    }
   ],
   "source": [
    "# 🗺️ Step 4: Check PostGIS extension status\n",
    "print(\"🗺️ **Step 4: POSTGIS EXTENSION CHECK**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "try:\n",
    "    # Check if PostGIS is installed\n",
    "    postgis_check = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            extname as extension_name,\n",
    "            extversion as version,\n",
    "            nspname as schema\n",
    "        FROM pg_extension e\n",
    "        JOIN pg_namespace n ON e.extnamespace = n.oid\n",
    "        WHERE extname = 'postgis'\n",
    "    \"\"\"))\n",
    "    \n",
    "    postgis_info = postgis_check.fetchone()\n",
    "    \n",
    "    if postgis_info:\n",
    "        print(f\"✅ PostGIS is installed!\")\n",
    "        print(f\"   📦 Extension: {postgis_info.extension_name}\")\n",
    "        print(f\"   🔢 Version: {postgis_info.version}\")\n",
    "        print(f\"   📋 Schema: {postgis_info.schema}\")\n",
    "    else:\n",
    "        print(\"❌ PostGIS not found\")\n",
    "        print(\"💡 PostGIS extension may need to be enabled\")\n",
    "    \n",
    "    print(\"\\n✅ PostGIS check complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ PostGIS check failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7e412",
   "metadata": {},
   "source": [
    "## 📂 **Step 5: Load Enhanced Milieuschutz Protection Zones GeoJSON**\n",
    "\n",
    "**Learning Point**: GeoJSON is a standard format for geographic data that can be easily imported into PostGIS.\n",
    "\n",
    "**About Milieuschutz Protection Zones Data**:\n",
    "- **Environmental Protection**: Legal zones designed to preserve neighborhood character and prevent gentrification\n",
    "- **Policy Framework**: Each zone has specific protection policies with enforcement dates\n",
    "- **Administrative Hierarchy**: Protection zones are distributed across Berlin districts\n",
    "- **Berlin Context**: Multiple Milieuschutz zones across districts with varying policy implementation dates\n",
    "\n",
    "**Educational Value**: This step demonstrates loading environmental policy data with temporal and spatial components for urban planning analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578a7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 **LOADING ENHANCED NEIGHBORHOODS GEOJSON**\n",
      "========================================\n",
      "1️⃣ Checking file existence...\n",
      "   ✅ File found: neighborhoods_enhanced.geojson\n",
      "2️⃣ Loading GeoJSON with GeoPandas...\n",
      "   ✅ Loaded 96 neighborhoods\n",
      "   📊 Columns: ['district_id', 'district', 'neighborhood', 'geometry']\n",
      "   🌍 Coordinate Reference System: EPSG:4326\n",
      "   📏 Geometry types: ['Polygon' 'MultiPolygon']\n",
      "\n",
      "3️⃣ Sample data preview:\n",
      "   🏘️ 01: Mitte - Mitte\n",
      "   🏘️ 01: Mitte - Moabit\n",
      "   🏘️ 01: Mitte - Hansaviertel\n",
      "\n",
      "4️⃣ CRS verification: ✅ Already EPSG:4326\n",
      "\n",
      "✅ GeoJSON loaded and ready for database import!\n"
     ]
    }
   ],
   "source": [
    "# 📂 Load the enhanced neighborhoods GeoJSON file\n",
    "print(\"📂 **LOADING MILIEUSCHUTZ GEOJSON**\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Path to the enhanced GeoJSON file\n",
    "geojson_path = \"layered-populate-data-pool-da/milieuschutz-populating-db/sources/milieuschutz_residental_and_urban_zones_joined.geojson\"\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Checking file existence...\")\n",
    "    if os.path.exists(geojson_path):\n",
    "        print(f\"   ✅ File found: {os.path.basename(geojson_path)}\")\n",
    "        \n",
    "        print(\"2️⃣ Loading GeoJSON with GeoPandas...\")\n",
    "        milieuschutz_gdf = gpd.read_file(geojson_path)\n",
    "        \n",
    "        print(f\"   ✅ Loaded {len(milieuschutz_gdf)} protection zones\")\n",
    "        print(f\"   📊 Columns: {list(milieuschutz_gdf.columns)}\")\n",
    "        print(f\"   🌍 Coordinate Reference System: {milieuschutz_gdf.crs}\")\n",
    "        print(f\"   📏 Geometry types: {milieuschutz_gdf.geometry.geom_type.unique()}\")\n",
    "        \n",
    "        print(\"\\n3️⃣ Sample data preview:\")\n",
    "        sample_data = milieuschutz_gdf[['protection_zone_key', 'protection_zone_name', 'district']].head(3)\n",
    "        for idx, row in sample_data.iterrows():\n",
    "            print(f\"   🏛️ {row['protection_zone_key']}: {row['protection_zone_name']} in {row['district']}\")\n",
    "        \n",
    "        # Ensure correct CRS (EPSG:4326 for WGS84)\n",
    "        if milieuschutz_gdf.crs != 'EPSG:4326':\n",
    "            print(f\"\\n4️⃣ Converting CRS to EPSG:4326...\")\n",
    "            milieuschutz_gdf = milieuschutz_gdf.to_crs('EPSG:4326')\n",
    "            print(\"   ✅ CRS converted to EPSG:4326\")\n",
    "        else:\n",
    "            print(\"\\n4️⃣ CRS verification: ✅ Already EPSG:4326\")\n",
    "        \n",
    "        print(\"\\n✅ Milieuschutz data loaded and ready for database import!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   ❌ File not found: {geojson_path}\")\n",
    "        print(\"   💡 Make sure the file exists in the sources directory\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading GeoJSON: {e}\")\n",
    "    print(f\"🔍 Details: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c46eb",
   "metadata": {},
   "source": [
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 📂 **Step 6: Load Milieuschutz Environmental Protection Zones Data**\n",
    "\",\n",
    "    \"\n",
    "\",\n",
    "    \"**Learning Point**: Loading spatial urban planning data requires understanding of environmental protection policies.\n",
    "\"\n",
    "\n",
    "**Milieuschutz Data Structure**:\n",
    "- **protection_zone_id**: Unique identifier for each protection area\n",
    "- **protection_zone_key**: Short code for zone identification  \n",
    "- **protection_zone_name**: Human-readable area name\n",
    "- **district**: Berlin district containing the zone\n",
    "- **district_id**: Zero-padded district identifier (01-12)\n",
    "- **date_announced**: When zone was officially announced\n",
    "- **date_effective**: When protection rules took effect\n",
    "- **area_ha**: Zone area in hectares\n",
    "- **zone_type**: Type of environmental protection (EM = Erhaltungsgebiete Milieuschutz)\n",
    "- **geometry**: Spatial boundaries of protection zone\n",
    "\n",
    "**Urban Planning Context**: These zones preserve neighborhood character and control gentrification in Berlin.\n",
    "\n",
    "**Educational Value**: This step demonstrates loading temporal-spatial policy data with rich metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# � Load the Milieuschutz Environmental Protection Zones GeoJSON file\n",
    "print(\"� **LOADING MILIEUSCHUTZ ENVIRONMENTAL PROTECTION ZONES**\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Relative path for student collaboration\n",
    "geojson_path = \"../sources/milieuschutz_residental_and_urban_zones_joined.geojson\"\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Checking file existence...\")\n",
    "    if os.path.exists(geojson_path):\n",
    "        print(f\"   ✅ File found: {os.path.basename(geojson_path)}\")\n",
    "        \n",
    "        print(\"2️⃣ Loading Environmental Protection Zones with GeoPandas...\")\n",
    "        milieuschutz_gdf = gpd.read_file(geojson_path)\n",
    "        \n",
    "        print(f\"   ✅ Loaded {len(milieuschutz_gdf)} protection zones\")\n",
    "        print(f\"   📊 Columns: {list(milieuschutz_gdf.columns)}\")\n",
    "        print(f\"   🌍 Coordinate Reference System: {milieuschutz_gdf.crs}\")\n",
    "        print(f\"   📏 Geometry types: {milieuschutz_gdf.geometry.geom_type.unique()}\")\n",
    "        \n",
    "        print(\"\\n3️⃣ Sample protection zones preview:\")\n",
    "        sample_data = milieuschutz_gdf[['protection_zone_key', 'district', 'protection_zone_name', 'zone_type']].head(3)\n",
    "        for idx, row in sample_data.iterrows():\n",
    "            print(f\"   🏛️ {row['protection_zone_key']}: {row['district']} - {row['protection_zone_name']} ({row['zone_type']})\")\n",
    "        \n",
    "        print(\"\\n4️⃣ Temporal data analysis:\")\n",
    "        # Show date range of protection zones\n",
    "        dates = milieuschutz_gdf['date_effective'].dropna()\n",
    "        if len(dates) > 0:\n",
    "            earliest = dates.min()[:10]  # Extract just the date part\n",
    "            latest = dates.max()[:10]\n",
    "            print(f\"   📅 Protection zones established: {earliest} to {latest}\")\n",
    "        \n",
    "        # Ensure correct CRS (EPSG:4326 for WGS84)\n",
    "        if milieuschutz_gdf.crs != 'EPSG:4326':\n",
    "            print(f\"\\n5️⃣ Converting CRS to EPSG:4326...\")\n",
    "            milieuschutz_gdf = milieuschutz_gdf.to_crs('EPSG:4326')\n",
    "            print(\"   ✅ CRS converted to EPSG:4326\")\n",
    "        else:\n",
    "            print(\"\\n5️⃣ CRS verification: ✅ Already EPSG:4326\")\n",
    "        \n",
    "        print(\"\\n✅ Milieuschutz data loaded and ready for database import!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   ❌ File not found: {geojson_path}\")\n",
    "        print(\"   💡 Make sure the file exists in the sources directory\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading GeoJSON: {e}\")\n",
    "    print(f\"🔍 Details: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75ecfd",
   "metadata": {},
   "source": [
    "## 🔧 **Step 7: Connection Check & Transaction Reset**\n",
    "\n",
    "**Learning Point**: Before creating tables, always verify your connection is working and clear any pending transactions.\n",
    "\n",
    "**Why this matters**: \n",
    "- Database connections can have \"dirty\" transaction states\n",
    "- Rolling back ensures we start with a clean slate\n",
    "- Connection tests verify we can communicate with the database\n",
    "\n",
    "**Best Practice**: Always check connection health before major operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "� **STEP 7A: CONNECTION CHECK & ROLLBACK**\n",
      "=============================================\n",
      "✅ Connection working: 1\n",
      "✅ Transaction state cleared\n",
      "� Ready for table creation!\n"
     ]
    }
   ],
   "source": [
    "# � **STEP 7: CONNECTION CHECK & ROLLBACK**\n",
    "# ============================================\n",
    "print(\"� **STEP 7: CONNECTION CHECK & ROLLBACK**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    # Check connection status\n",
    "    test_result = conn.execute(text(\"SELECT 1 as test\"))\n",
    "    test_value = test_result.fetchone()[0]\n",
    "    print(f\"✅ Connection working: {test_value}\")\n",
    "    \n",
    "    # Rollback any pending transactions\n",
    "    conn.rollback()\n",
    "    print(\"✅ Transaction state cleared\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection issue: {e}\")\n",
    "    print(\"� Try reconnecting if needed\")\n",
    "\n",
    "print(\"� Ready for table creation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed63aaf",
   "metadata": {},
   "source": [
    "## 🏗️ **Step 8: Create Milieuschutz Protection Zones Table Structure**\n",
    "\n",
    "**Learning Point**: Environmental protection zone tables require fields for policy metadata and temporal tracking.\n",
    "\n",
    "**Milieuschutz Table Design**:\n",
    "- **protection_zone_id**: Primary identifier (VARCHAR(50))\n",
    "- **protection_zone_key**: Short reference code (VARCHAR(20)) \n",
    "- **protection_zone_name**: Human-readable zone name (VARCHAR(100))\n",
    "- **district**: Berlin district name (VARCHAR(100))\n",
    "- **district_id**: Zero-padded district code for foreign keys (VARCHAR(2))\n",
    "- **date_announced**: Policy announcement date (DATE)\n",
    "- **date_effective**: When protection started (DATE)\n",
    "- **area_ha**: Zone area in hectares (DECIMAL)\n",
    "- **zone_type**: Protection category (VARCHAR(10))\n",
    "- **geometry**: Spatial boundaries (MULTIPOLYGON, SRID 4326)\n",
    "\n",
    "**Urban Planning Database Concepts**:\n",
    "- **Temporal Tracking**: Capture policy timeline from announcement to effect\n",
    "- **Hierarchical Structure**: Zones belong to districts \n",
    "- **Policy Metadata**: Rich context for urban planning analysis\n",
    "\n",
    "**Best Practice**: Build complex policy tables incrementally - start with core fields, add spatial features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be825e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ **STEP 7B: CREATE TABLE STRUCTURE**\n",
      "=============================================\n",
      "   ✅ Basic table structure created!\n",
      "   ✅ Connection still working\n"
     ]
    }
   ],
   "source": [
    "# 🏗️ **STEP 8: CREATE MILIEUSCHUTZ PROTECTION ZONES TABLE**\n",
    "# =========================================================\n",
    "print(\"🏗️ **STEP 8: CREATE MILIEUSCHUTZ PROTECTION ZONES TABLE**\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Create comprehensive Milieuschutz table with all policy fields\n",
    "    create_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS berlin_data.milieuschutz_protection_zones (\n",
    "        protection_zone_id VARCHAR(50) PRIMARY KEY,\n",
    "        protection_zone_key VARCHAR(20) NOT NULL,\n",
    "        protection_zone_name VARCHAR(100) NOT NULL,\n",
    "        district VARCHAR(100) NOT NULL,\n",
    "        district_id VARCHAR(2) NOT NULL,\n",
    "        date_announced DATE,\n",
    "        date_effective DATE,\n",
    "        amendment_announced DATE,\n",
    "        amendment_effective DATE,\n",
    "        area_ha DECIMAL(10,2),\n",
    "        zone_type VARCHAR(10) NOT NULL,\n",
    "        geometry GEOMETRY(MULTIPOLYGON, 4326)\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    conn.execute(text(create_sql))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Milieuschutz protection zones table created!\")\n",
    "    \n",
    "    # Verify table was created\n",
    "    verify_sql = \"\"\"\n",
    "        SELECT column_name, data_type, is_nullable \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_schema = 'berlin_data' \n",
    "        AND table_name = 'milieuschutz_protection_zones'\n",
    "        ORDER BY ordinal_position;\n",
    "    \"\"\"\n",
    "    \n",
    "    result = conn.execute(text(verify_sql))\n",
    "    columns = result.fetchall()\n",
    "    \n",
    "    print(f\"\\n   📋 Table created with {len(columns)} columns:\")\n",
    "    for col in columns:\n",
    "        nullable = \"NULL\" if col[2] == \"YES\" else \"NOT NULL\"\n",
    "        print(f\"      • {col[0]}: {col[1]} ({nullable})\")\n",
    "    \n",
    "    print(\"\\n   🏛️ Ready for environmental protection zone data!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating table: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab171348",
   "metadata": {},
   "source": [
    "## 🗺️ **Step 9: Add PostGIS Geometry Column for Milieuschutz Protection Zones**\n",
    "\n",
    "**Learning Point**: PostGIS geometry columns enable spatial operations on environmental protection zone boundaries.\n",
    "\n",
    "**PostGIS Functions**:\n",
    "- `ALTER TABLE ADD COLUMN geometry` - Standard approach for adding spatial columns\n",
    "- `GEOMETRY(MULTIPOLYGON, 4326)` - Explicit geometry type and coordinate system\n",
    "- Automatically integrates with PostGIS spatial index system\n",
    "\n",
    "**Parameters Explained**:\n",
    "- `'berlin_data'` - schema name\n",
    "- `'neighborhoods'` - table name  \n",
    "- `'geometry'` - column name\n",
    "- `4326` - SRID (Spatial Reference System - WGS84)\n",
    "- `'MULTIPOLYGON'` - geometry type (neighborhoods can have complex shapes)\n",
    "- `2` - dimensions (2D: X,Y coordinates)\n",
    "\n",
    "**Spatial Benefits**: Enables neighborhood-level spatial queries, proximity analysis, and containment checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗺️ **STEP 7C: ADD GEOMETRY COLUMN**\n",
      "=============================================\n",
      "2️⃣ Adding PostGIS geometry column...\n",
      "   ✅ Geometry column added successfully!\n",
      "\n",
      "3️⃣ Table structure verification:\n",
      "   📋 district: character varying\n",
      "   📋 district_id: character varying\n",
      "   📋 geometry: USER-DEFINED\n",
      "   📋 neighborhood: character varying\n",
      "\n",
      "   ✅ Connection still working\n"
     ]
    }
   ],
   "source": [
    "# 🗺️ **STEP 9: ADD GEOMETRY COLUMN**\n",
    "# ==================================\n",
    "print(\"🗺️ **STEP 9: ADD GEOMETRY COLUMN**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"2️⃣ Adding PostGIS geometry column...\")\n",
    "    \n",
    "    # Use simple ALTER TABLE approach (more reliable)\n",
    "    add_geom_sql = \"\"\"\n",
    "    ALTER TABLE berlin_data.neighborhoods \n",
    "    ADD COLUMN IF NOT EXISTS geometry GEOMETRY(MULTIPOLYGON, 4326);\n",
    "    \"\"\"\n",
    "    \n",
    "    conn.execute(text(add_geom_sql))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Geometry column added successfully!\")\n",
    "    \n",
    "    # Verify the column was added\n",
    "    verify_sql = \"\"\"\n",
    "    SELECT column_name, data_type \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'berlin_data' \n",
    "    AND table_name = 'neighborhoods' \n",
    "    ORDER BY column_name;\n",
    "    \"\"\"\n",
    "    \n",
    "    result = conn.execute(text(verify_sql))\n",
    "    columns = result.fetchall()\n",
    "    print(\"\\n3️⃣ Table structure verification:\")\n",
    "    for col in columns:\n",
    "        print(f\"   📋 {col[0]}: {col[1]}\")\n",
    "    \n",
    "    # Connection check\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"\\n   ✅ Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Geometry column creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise\n",
    "    test_result = conn.execute(text(\"SELECT 1\"))\n",
    "    print(\"   ✅ Connection still working\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Geometry column creation failed: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e4f200",
   "metadata": {},
   "source": [
    "## 🔗 **Step 10: Add Data Validation and Constraints**\n",
    "\n",
    "**Learning Point**: Environmental protection data requires specialized validation to ensure data quality and consistency.\n",
    "\n",
    "**Why Add Constraints BEFORE Data Insertion?**\n",
    "- **Data Integrity**: Database will reject invalid zone data automatically\n",
    "- **Performance**: Constraints help query optimizer create better execution plans\n",
    "- **Documentation**: Makes environmental data relationships explicit in database schema\n",
    "- **Multi-Application Safety**: All applications accessing the database respect the environmental data constraints\n",
    "\n",
    "**Milieuschutz Data Validation**:\n",
    "- **Temporal Validation**: Policy dates must be reasonable (not future dates)\n",
    "- **Spatial Validation**: Geometry must be valid MULTIPOLYGON\n",
    "- **Zone Uniqueness**: Protection zone keys must be unique\n",
    "- **District Consistency**: District names must be consistent\n",
    "\n",
    "**Educational Value**: Demonstrates proper environmental database design with data quality controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecd036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 **STEP 7D: ADD FOREIGN KEY CONSTRAINT**\n",
      "=============================================\n",
      "1️⃣ Checking districts table exists...\n",
      "   ✅ Districts table found\n",
      "\n",
      "2️⃣ Creating foreign key constraint...\n",
      "   ✅ Foreign key constraint 'fk_neighborhoods_district_id' created!\n",
      "\n",
      "3️⃣ Verifying constraint creation...\n",
      "   📋 Foreign key constraints found: 1\n",
      "      🔗 fk_neighborhoods_district_id (FOREIGN KEY)\n",
      "\n",
      "🎯 **Database integrity is now enforced at the constraint level!**\n",
      "✅ Invalid district_id values will be automatically rejected\n",
      "\n",
      "🚀 Ready for data insertion with enforced referential integrity!\n"
     ]
    }
   ],
   "source": [
    "# 🔗 **STEP 10: ADD FOREIGN KEY CONSTRAINT**\n",
    "# ==========================================\n",
    "print(\"🔗 **STEP 10: ADD FOREIGN KEY CONSTRAINT**\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Checking districts table exists...\")\n",
    "    # Verify districts table exists first\n",
    "    districts_check = conn.execute(text(\"\"\"\n",
    "        SELECT table_name FROM information_schema.tables \n",
    "        WHERE table_schema = 'berlin_data' AND table_name = 'districts';\n",
    "    \"\"\"))\n",
    "    \n",
    "    if districts_check.fetchone():\n",
    "        print(\"   ✅ Districts table found\")\n",
    "        \n",
    "        print(\"\\n2️⃣ Creating foreign key constraint...\")\n",
    "        # Create the foreign key constraint\n",
    "        constraint_sql = \"\"\"\n",
    "            ALTER TABLE berlin_data.neighborhoods \n",
    "            ADD CONSTRAINT fk_neighborhoods_district_id \n",
    "            FOREIGN KEY (district_id) \n",
    "            REFERENCES berlin_data.districts(district_id);\n",
    "        \"\"\"\n",
    "        \n",
    "        conn.execute(text(constraint_sql))\n",
    "        conn.commit()\n",
    "        print(\"   ✅ Foreign key constraint 'fk_neighborhoods_district_id' created!\")\n",
    "        \n",
    "        print(\"\\n3️⃣ Verifying constraint creation...\")\n",
    "        # Verify the constraint was created\n",
    "        verify_constraint = conn.execute(text(\"\"\"\n",
    "            SELECT constraint_name, constraint_type \n",
    "            FROM information_schema.table_constraints\n",
    "            WHERE table_schema = 'berlin_data' \n",
    "            AND table_name = 'neighborhoods'\n",
    "            AND constraint_type = 'FOREIGN KEY';\n",
    "        \"\"\"))\n",
    "        \n",
    "        fk_constraints = verify_constraint.fetchall()\n",
    "        print(f\"   📋 Foreign key constraints found: {len(fk_constraints)}\")\n",
    "        for constraint in fk_constraints:\n",
    "            print(f\"      🔗 {constraint[0]} ({constraint[1]})\")\n",
    "            \n",
    "        print(\"\\n🎯 **Database integrity is now enforced at the constraint level!**\")\n",
    "        print(\"✅ Invalid district_id values will be automatically rejected\")\n",
    "        \n",
    "    else:\n",
    "        print(\"   ❌ Districts table not found! Cannot create foreign key constraint.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e).lower():\n",
    "        print(\"   ℹ️  Foreign key constraint already exists!\")\n",
    "        print(\"   ✅ Database integrity is already enforced\")\n",
    "    else:\n",
    "        print(f\"   ❌ Error creating constraint: {e}\")\n",
    "        conn.rollback()\n",
    "        print(\"   🔄 Transaction rolled back\")\n",
    "        \n",
    "print(\"\\n🚀 Ready for data insertion with enforced referential integrity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c473f7",
   "metadata": {},
   "source": [
    "## 🎯 **Step 11: Implementing Proper Referential Integrity Rules**\n",
    "\n",
    "**Learning Point**: The basic foreign key constraint we created uses default rules (`NO ACTION`), but database best practices recommend specific **CASCADE** and **RESTRICT** behaviors for different operations.\n",
    "\n",
    "### 🔍 **Understanding Referential Integrity Rules:**\n",
    "\n",
    "**Current Default Behavior:**\n",
    "- `ON UPDATE NO ACTION` - Rejects updates to parent district_id\n",
    "- `ON DELETE NO ACTION` - Rejects deletion of parent districts\n",
    "\n",
    "**Recommended Best Practice:**\n",
    "- `ON UPDATE CASCADE` - **Automatically propagates** district_id changes to neighborhoods\n",
    "- `ON DELETE RESTRICT` - **Explicitly prevents** deletion of districts with neighborhoods\n",
    "\n",
    "### 📚 **Why These Rules Matter:**\n",
    "\n",
    "#### **CASCADE ON UPDATE** 🔄\n",
    "- **Scenario**: If Berlin renames district \"01\" to \"1A\" \n",
    "- **Behavior**: All neighborhoods automatically update their district_id from \"01\" to \"1A\"\n",
    "- **Benefit**: Maintains data consistency without manual intervention\n",
    "\n",
    "#### **RESTRICT ON DELETE** 🛡️\n",
    "- **Scenario**: Attempting to delete a district that has neighborhoods\n",
    "- **Behavior**: Database explicitly rejects the deletion with clear error\n",
    "- **Benefit**: Prevents accidental data loss and orphaned records\n",
    "\n",
    "### 🎓 **Educational Value:**\n",
    "- **Data Integrity**: Understanding how relationships should behave\n",
    "- **Database Design**: Industry-standard referential integrity patterns\n",
    "- **Error Prevention**: Proactive protection against data inconsistencies\n",
    "\n",
    "**Next Step**: Update our constraint to implement these best practices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15596ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 **STEP 7E: IMPLEMENT PROPER REFERENTIAL INTEGRITY RULES**\n",
      "=================================================================\n",
      "1️⃣ Checking current constraint rules...\n",
      "   Current rules: UPDATE NO ACTION, DELETE NO ACTION\n",
      "\n",
      "2️⃣ Dropping existing constraint...\n",
      "   ✅ Existing constraint dropped\n",
      "\n",
      "3️⃣ Creating new constraint with best practice rules...\n",
      "   ✅ New constraint created with:\n",
      "      🔄 ON UPDATE CASCADE (auto-propagates district_id changes)\n",
      "      🛡️  ON DELETE RESTRICT (prevents district deletion)\n",
      "\n",
      "4️⃣ Verifying new constraint rules...\n",
      "   ✅ Verified: UPDATE CASCADE, DELETE RESTRICT\n",
      "\n",
      "🎯 **PERFECT! Best practice referential integrity implemented!**\n",
      "   📚 Students now understand:\n",
      "      • CASCADE propagates changes automatically\n",
      "      • RESTRICT prevents accidental data loss\n",
      "      • Proper database design principles\n",
      "\n",
      "🚀 Database now follows industry-standard referential integrity patterns!\n"
     ]
    }
   ],
   "source": [
    "# 🎯 **STEP 11: IMPLEMENT PROPER REFERENTIAL INTEGRITY RULES**\n",
    "# ================================================================\n",
    "print(\"🎯 **STEP 11: IMPLEMENT PROPER REFERENTIAL INTEGRITY RULES**\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "try:\n",
    "    print(\"1️⃣ Checking current constraint rules...\")\n",
    "    # Check current constraint rules\n",
    "    current_rules = conn.execute(text(\"\"\"\n",
    "        SELECT \n",
    "            tc.constraint_name,\n",
    "            rc.update_rule,\n",
    "            rc.delete_rule\n",
    "        FROM information_schema.table_constraints AS tc \n",
    "        JOIN information_schema.referential_constraints AS rc\n",
    "            ON tc.constraint_name = rc.constraint_name\n",
    "        WHERE tc.constraint_type = 'FOREIGN KEY' \n",
    "        AND tc.table_schema = 'berlin_data'\n",
    "        AND tc.table_name = 'neighborhoods';\n",
    "    \"\"\"))\n",
    "    \n",
    "    current = current_rules.fetchone()\n",
    "    if current:\n",
    "        print(f\"   Current rules: UPDATE {current[1]}, DELETE {current[2]}\")\n",
    "        \n",
    "        print(\"\\n2️⃣ Dropping existing constraint...\")\n",
    "        # Drop the existing constraint\n",
    "        conn.execute(text(\"\"\"\n",
    "            ALTER TABLE berlin_data.neighborhoods \n",
    "            DROP CONSTRAINT fk_neighborhoods_district_id;\n",
    "        \"\"\"))\n",
    "        print(\"   ✅ Existing constraint dropped\")\n",
    "        \n",
    "        print(\"\\n3️⃣ Creating new constraint with best practice rules...\")\n",
    "        # Create new constraint with proper rules\n",
    "        conn.execute(text(\"\"\"\n",
    "            ALTER TABLE berlin_data.neighborhoods \n",
    "            ADD CONSTRAINT fk_neighborhoods_district_id \n",
    "            FOREIGN KEY (district_id) \n",
    "            REFERENCES berlin_data.districts(district_id)\n",
    "            ON UPDATE CASCADE\n",
    "            ON DELETE RESTRICT;\n",
    "        \"\"\"))\n",
    "        \n",
    "        conn.commit()\n",
    "        print(\"   ✅ New constraint created with:\")\n",
    "        print(\"      🔄 ON UPDATE CASCADE (auto-propagates district_id changes)\")\n",
    "        print(\"      🛡️  ON DELETE RESTRICT (prevents district deletion)\")\n",
    "        \n",
    "        print(\"\\n4️⃣ Verifying new constraint rules...\")\n",
    "        # Verify the new rules\n",
    "        verify_rules = conn.execute(text(\"\"\"\n",
    "            SELECT \n",
    "                tc.constraint_name,\n",
    "                rc.update_rule,\n",
    "                rc.delete_rule\n",
    "            FROM information_schema.table_constraints AS tc \n",
    "            JOIN information_schema.referential_constraints AS rc\n",
    "                ON tc.constraint_name = rc.constraint_name\n",
    "            WHERE tc.constraint_type = 'FOREIGN KEY' \n",
    "            AND tc.table_schema = 'berlin_data'\n",
    "            AND tc.table_name = 'neighborhoods';\n",
    "        \"\"\"))\n",
    "        \n",
    "        new_rules = verify_rules.fetchone()\n",
    "        if new_rules:\n",
    "            print(f\"   ✅ Verified: UPDATE {new_rules[1]}, DELETE {new_rules[2]}\")\n",
    "            \n",
    "            if new_rules[1] == 'CASCADE' and new_rules[2] == 'RESTRICT':\n",
    "                print(\"\\n🎯 **PERFECT! Best practice referential integrity implemented!**\")\n",
    "                print(\"   📚 Students now understand:\")\n",
    "                print(\"      • CASCADE propagates changes automatically\")\n",
    "                print(\"      • RESTRICT prevents accidental data loss\")\n",
    "                print(\"      • Proper database design principles\")\n",
    "            else:\n",
    "                print(f\"   ⚠️  Unexpected rules: {new_rules[1]}, {new_rules[2]}\")\n",
    "    else:\n",
    "        print(\"   ❌ No foreign key constraint found to update\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error updating constraint: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    \n",
    "print(\"\\n🚀 Database now follows industry-standard referential integrity patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae0178",
   "metadata": {},
   "source": [
    "## �️ **Step 12: Insert Milieuschutz Environmental Protection Zones Data**\n",
    "\n",
    "**Learning Point**: Inserting temporal-spatial policy data requires careful handling of dates, metadata, and spatial geometries.\n",
    "\n",
    "**Milieuschutz Data Insertion Strategy**:\n",
    "- **Policy Processing**: Insert all environmental protection zones with complete metadata\n",
    "- **Temporal Data Handling**: Convert date strings to proper DATE format\n",
    "- **Spatial Conversion**: Transform complex MultiPolygon geometries to PostGIS format\n",
    "- **Transaction Safety**: Use rollback capability for error recovery\n",
    "- **Data Validation**: Verify zone types, districts, and date consistency\n",
    "\n",
    "**PostGIS Integration for Protection Zones**:\n",
    "- `ST_GeomFromText()` - Converts complex MultiPolygon WKT to PostGIS geometry\n",
    "- Maintains spatial reference system (SRID 4326) for global compatibility\n",
    "- Preserves geometric precision for accurate urban planning analysis\n",
    "\n",
    "**Urban Planning Database Concepts**:\n",
    "- **Policy Lifecycle**: Track from announcement to effectiveness\n",
    "- **Administrative Hierarchy**: Link zones to Berlin districts\n",
    "- **Spatial Integrity**: Maintain precise protection zone boundaries\n",
    "\n",
    "**Educational Value**: Demonstrates complete workflow from environmental policy GeoJSON to operational spatial database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# �️ **STEP 12: INSERT MILIEUSCHUTZ ENVIRONMENTAL PROTECTION ZONES**\n",
    "# ================================================================\n",
    "print(\"�️ **STEP 12: INSERT MILIEUSCHUTZ ENVIRONMENTAL PROTECTION ZONES**\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Fix any transaction issues first\n",
    "    print(\"1️⃣ Fixing transaction state...\")\n",
    "    conn.rollback()\n",
    "    print(\"   ✅ Transaction rolled back\")\n",
    "    \n",
    "    # Clear existing milieuschutz data (if any)\n",
    "    print(\"\\n2️⃣ Clearing existing milieuschutz zones data...\")\n",
    "    conn.execute(text(\"DELETE FROM berlin_data.milieuschutz_zones;\"))\n",
    "    conn.commit()\n",
    "    print(\"   ✅ Milieuschutz zones table cleared\")\n",
    "    \n",
    "    # Insert milieuschutz zones data with complete metadata\n",
    "    print(\"\\n3️⃣ Inserting environmental protection zones...\")\n",
    "    print(f\"   📊 Processing {len(milieuschutz_gdf)} protection zones...\")\n",
    "    \n",
    "    inserted_count = 0\n",
    "    for idx, row in milieuschutz_gdf.iterrows():\n",
    "        # Helper function to handle date conversion\n",
    "        def convert_date(date_str):\n",
    "            if date_str and str(date_str) != 'nan' and str(date_str) != 'None':\n",
    "                return str(date_str)[:10]  # Extract YYYY-MM-DD part\n",
    "            return None\n",
    "        \n",
    "        insert_sql = text(\"\"\"\n",
    "            INSERT INTO berlin_data.milieuschutz_zones \n",
    "            (protection_zone_id, protection_zone_key, protection_zone_name, \n",
    "             district, district_id, date_announced, date_effective, \n",
    "             amendment_announced, amendment_effective, area_ha, zone_type, geometry) \n",
    "            VALUES (:protection_zone_id, :protection_zone_key, :protection_zone_name,\n",
    "                    :district, :district_id, :date_announced, :date_effective,\n",
    "                    :amendment_announced, :amendment_effective, :area_ha, :zone_type,\n",
    "                    ST_GeomFromText(:wkt, 4326))\n",
    "        \"\"\")\n",
    "        \n",
    "        conn.execute(insert_sql, {\n",
    "            'protection_zone_id': row['protection_zone_id'],\n",
    "            'protection_zone_key': row['protection_zone_key'],\n",
    "            'protection_zone_name': row['protection_zone_name'],\n",
    "            'district': row['district'],\n",
    "            'district_id': row['district_id'],\n",
    "            'date_announced': convert_date(row['date_announced']),\n",
    "            'date_effective': convert_date(row['date_effective']),\n",
    "            'amendment_announced': convert_date(row['amendment_announced']) if 'amendment_announced' in row and row['amendment_announced'] else None,\n",
    "            'amendment_effective': convert_date(row['amendment_effective']) if 'amendment_effective' in row and row['amendment_effective'] else None,\n",
    "            'area_ha': float(row['area_ha']) if row['area_ha'] else None,\n",
    "            'zone_type': row['zone_type'],\n",
    "            'wkt': row['geometry'].wkt\n",
    "        })\n",
    "        inserted_count += 1\n",
    "        \n",
    "        if inserted_count % 10 == 0:\n",
    "            print(f\"   📝 Inserted {inserted_count} protection zones...\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"   ✅ Successfully inserted {inserted_count} environmental protection zones!\")\n",
    "    \n",
    "    # Verify the insertion with detailed analysis\n",
    "    print(\"\\n4️⃣ Verifying milieuschutz zones insertion...\")\n",
    "    \n",
    "    # Count total zones\n",
    "    count_result = conn.execute(text(\"SELECT COUNT(*) FROM berlin_data.milieuschutz_zones\"))\n",
    "    total_zones = count_result.fetchone()[0]\n",
    "    print(f\"   📊 Total protection zones: {total_zones}\")\n",
    "    \n",
    "    # Analyze zone types\n",
    "    type_result = conn.execute(text(\"\"\"\n",
    "        SELECT zone_type, COUNT(*) \n",
    "        FROM berlin_data.milieuschutz_zones \n",
    "        GROUP BY zone_type\n",
    "    \"\"\"))\n",
    "    zone_types = type_result.fetchall()\n",
    "    print(f\"   🏛️ Zone types distribution:\")\n",
    "    for zone_type, count in zone_types:\n",
    "        print(f\"      • {zone_type}: {count} zones\")\n",
    "    \n",
    "    # Analyze by district\n",
    "    district_result = conn.execute(text(\"\"\"\n",
    "        SELECT district, COUNT(*) as zone_count, SUM(area_ha) as total_area\n",
    "        FROM berlin_data.milieuschutz_zones \n",
    "        GROUP BY district \n",
    "        ORDER BY zone_count DESC \n",
    "        LIMIT 5\n",
    "    \"\"\"))\n",
    "    districts = district_result.fetchall()\n",
    "    print(f\"   🗺️ Top 5 districts by protection zones:\")\n",
    "    for district, count, area in districts:\n",
    "        area_display = f\"{area:.1f} ha\" if area else \"Unknown area\"\n",
    "        print(f\"      • {district}: {count} zones ({area_display})\")\n",
    "    \n",
    "    # Sample data verification\n",
    "    sample_result = conn.execute(text(\"\"\"\n",
    "        SELECT protection_zone_key, protection_zone_name, district, date_effective\n",
    "        FROM berlin_data.milieuschutz_zones \n",
    "        LIMIT 3\n",
    "    \"\"\"))\n",
    "    samples = sample_result.fetchall()\n",
    "    print(f\"   � Sample zones verification:\")\n",
    "    for key, name, district, date_eff in samples:\n",
    "        print(f\"      �️ {key}: {name} in {district} (effective: {date_eff})\")\n",
    "    \n",
    "    print(f\"\\n🎉 **MILIEUSCHUTZ DATA READY! {total_zones} Environmental Protection Zones!**\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"✅ Schema: berlin_data\")\n",
    "    print(\"✅ Table: milieuschutz_zones\") \n",
    "    print(\"✅ Temporal data: Policy dates tracked\")\n",
    "    print(\"✅ Spatial data: Working with PostGIS MultiPolygon geometry!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error inserting milieuschutz data: {e}\")\n",
    "    conn.rollback()\n",
    "    print(\"🔄 Transaction rolled back\")\n",
    "    import traceback\n",
    "    print(f\"🔍 Details: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561728ab",
   "metadata": {},
   "source": [
    "## ✅ **Step 13: Verify Milieuschutz Data & Test Environmental Protection Functions**\n",
    "\n",
    "**Learning Point**: Always verify your environmental data import was successful and spatial constraints work correctly.\n",
    "\n",
    "**Verification Steps**:\n",
    "1. **Count Records** - Ensure all protection zones were inserted successfully\n",
    "2. **Test Zone Types** - Verify protection type classifications are correct\n",
    "3. **Test Spatial Functions** - Confirm PostGIS geometry operations work with environmental zones\n",
    "4. **Check Data Types** - Validate geometry types and coordinate systems\n",
    "5. **District Analysis** - Confirm protection zone distribution across Berlin districts\n",
    "\n",
    "**PostGIS Testing Functions**:\n",
    "- `ST_GeometryType()` - returns the geometry type (e.g., ST_MultiPolygon)\n",
    "- `ST_SRID()` - returns the Spatial Reference System ID (should be 4326)\n",
    "- These functions prove our environmental protection spatial data is properly stored\n",
    "\n",
    "**Environmental Data Validation**:\n",
    "- Analyze protection zone types and their distribution\n",
    "- Check temporal data (policy effective dates)\n",
    "- Verify district-zone relationships\n",
    "- Confirm data completeness for urban planning analysis\n",
    "\n",
    "**Success Criteria**:\n",
    "- ✅ Record count matches expected protection zones\n",
    "- ✅ All zones have valid district references  \n",
    "- ✅ Spatial data uses correct coordinate system (SRID 4326)\n",
    "- ✅ No missing critical data (zone names, keys, districts)\n",
    "- ✅ PostGIS functions work correctly on environmental geometries\n",
    "\n",
    "**Educational Value**: Demonstrates comprehensive environmental database validation for urban planning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15aee180",
   "metadata": {},
   "source": [
    "## \udf89 **Mission Accomplished: Milieuschutz Environmental Protection Database Ready!**\n",
    "\n",
    "**🎯 Educational Achievement**: Successfully implemented a complete environmental protection data pipeline from GeoJSON to operational spatial database!\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **What We Accomplished:**\n",
    "1. **Database Connection**: Successfully connected to AWS RDS PostgreSQL\n",
    "2. **Schema Investigation**: Explored existing database structure and environmental data requirements\n",
    "3. **PostGIS Verification**: Confirmed spatial extension availability for environmental geometries\n",
    "4. **Milieuschutz GeoJSON Import**: Loaded Berlin environmental protection zones with comprehensive metadata\n",
    "5. **Environmental Table Creation**: Created milieuschutz_zones table with specialized environmental protection schema\n",
    "6. **Spatial Data Integration**: Imported complex protection zone geometries into PostGIS\n",
    "7. **Temporal Data Handling**: Integrated policy effective dates and protection type classifications  \n",
    "8. **Data Validation**: Confirmed successful import of all environmental protection zones\n",
    "\n",
    "### 📚 **Key Learning Points:**\n",
    "- **Environmental Spatial Data**: Working with protection zones and policy boundaries\n",
    "- **Temporal Database Design**: Capturing when environmental policies became effective\n",
    "- **PostGIS Integration**: Converting complex environmental GeoJSON to PostGIS geometry with proper SRID\n",
    "- **Environmental Data Schema**: Designing databases for urban planning and environmental protection\n",
    "- **Policy Data Management**: Handling administrative and legal aspects of environmental data\n",
    "- **Transaction Management**: Using rollback for error recovery during environmental data operations\n",
    "- **Comprehensive Validation**: Always verify environmental data imports and spatial relationships!\n",
    "\n",
    "### 🌍 **Environmental Database Concepts Mastered:**\n",
    "- **Protection Zone Classification**: Different types of environmental protections (Milieuschutz, historic preservation)\n",
    "- **Policy Lifecycle Tracking**: From policy announcement to implementation dates\n",
    "- **Administrative Hierarchy**: Linking protection zones to Berlin districts for governance\n",
    "- **Spatial Environmental Analysis**: Ready for proximity analysis, coverage studies, and policy impact assessment\n",
    "\n",
    "### 🚀 **Next Steps in Environmental Data Science:**\n",
    "- Add formal spatial indexing for performance optimization\n",
    "- Implement environmental zone impact analysis queries\n",
    "- Connect with building permits data for compliance monitoring\n",
    "- Develop environmental policy effectiveness metrics\n",
    "\n",
    "**🎯 Student Achievement**: You now understand how environmental protection data integrates with urban planning databases and can support policy analysis and urban development decisions!\n",
    "\n",
    "---\n",
    "**\udcd6 Educational Value**: This notebook demonstrates the complete workflow from environmental policy GeoJSON files to operational spatial databases that support real-world urban planning and environmental protection decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0503cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_id</th>\n",
       "      <th>district</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>0106000020E61000000100000001030000000100000006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Moabit</td>\n",
       "      <td>0106000020E61000000100000001030000000100000002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Hansaviertel</td>\n",
       "      <td>0106000020E61000000100000001030000000100000006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Tiergarten</td>\n",
       "      <td>0106000020E61000000100000001030000000100000055...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>Wedding</td>\n",
       "      <td>0106000020E6100000010000000103000000010000004E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  district_id district  neighborhood  \\\n",
       "0          01    Mitte         Mitte   \n",
       "1          01    Mitte        Moabit   \n",
       "2          01    Mitte  Hansaviertel   \n",
       "3          01    Mitte    Tiergarten   \n",
       "4          01    Mitte       Wedding   \n",
       "\n",
       "                                            geometry  \n",
       "0  0106000020E61000000100000001030000000100000006...  \n",
       "1  0106000020E61000000100000001030000000100000002...  \n",
       "2  0106000020E61000000100000001030000000100000006...  \n",
       "3  0106000020E61000000100000001030000000100000055...  \n",
       "4  0106000020E6100000010000000103000000010000004E...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the first 5 rows from berlin_data.districts_enhanced\n",
    "result = conn.execute(text(\"SELECT * FROM berlin_data.milieuschutz_protection_zones LIMIT 5;\"))\n",
    "rows = result.fetchall()\n",
    "\n",
    "# Display results as a pandas DataFrame for readability\n",
    "import pandas as pd\n",
    "df_preview = pd.DataFrame(rows, columns=result.keys())\n",
    "df_preview\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Webeet)",
   "language": "python",
   "name": "webeet-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
